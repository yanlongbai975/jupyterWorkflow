{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf716cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d102a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   ## data analysis and manipulation\n",
    "import numpy as np    ## numerial computing\n",
    "import seaborn as sns ##  data visualization library based on matplotlib\n",
    "import tensorflow.keras as keras ## main deep learning API\n",
    "\n",
    "## additional functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d15d419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292a9d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EID</th>\n",
       "      <th>PID</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Eye</th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Scan.Type</th>\n",
       "      <th>Diameter..mm.</th>\n",
       "      <th>Diameter....</th>\n",
       "      <th>Fixed.in.mm</th>\n",
       "      <th>ExamDate</th>\n",
       "      <th>...</th>\n",
       "      <th>VF_OCT_BASELINE_DIFF</th>\n",
       "      <th>VF_OCT_FINAL_DIFF</th>\n",
       "      <th>MD_BASELINE</th>\n",
       "      <th>MD_FINAL</th>\n",
       "      <th>VFI_BASELINE</th>\n",
       "      <th>VFI_FINAL</th>\n",
       "      <th>Y_GRI</th>\n",
       "      <th>Y_MD</th>\n",
       "      <th>Y_VFI</th>\n",
       "      <th>Y_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10/24/1949</td>\n",
       "      <td>LE</td>\n",
       "      <td>282596.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.561944</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10/24/1949</td>\n",
       "      <td>RE</td>\n",
       "      <td>282593.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.561944</td>\n",
       "      <td>-7.73</td>\n",
       "      <td>-11.45</td>\n",
       "      <td>82</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8/7/1939</td>\n",
       "      <td>LE</td>\n",
       "      <td>239514.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.151951</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8/7/1939</td>\n",
       "      <td>RE</td>\n",
       "      <td>239512.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.151951</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.60</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5/20/1943</td>\n",
       "      <td>LE</td>\n",
       "      <td>238460.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7/9/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024641</td>\n",
       "      <td>6.266940</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>580</td>\n",
       "      <td>329</td>\n",
       "      <td>3/22/1952</td>\n",
       "      <td>RE</td>\n",
       "      <td>837.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5/5/2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.601643</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>98</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>581</td>\n",
       "      <td>330</td>\n",
       "      <td>5/15/1945</td>\n",
       "      <td>LE</td>\n",
       "      <td>243095.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12/17/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.941136</td>\n",
       "      <td>-8.97</td>\n",
       "      <td>-14.71</td>\n",
       "      <td>78</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>582</td>\n",
       "      <td>330</td>\n",
       "      <td>5/15/1945</td>\n",
       "      <td>RE</td>\n",
       "      <td>243093.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12/17/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.941136</td>\n",
       "      <td>-11.39</td>\n",
       "      <td>-11.37</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>583</td>\n",
       "      <td>331</td>\n",
       "      <td>5/31/1939</td>\n",
       "      <td>LE</td>\n",
       "      <td>109347.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/13/2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172485</td>\n",
       "      <td>6.193018</td>\n",
       "      <td>-3.48</td>\n",
       "      <td>-19.28</td>\n",
       "      <td>97</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>584</td>\n",
       "      <td>331</td>\n",
       "      <td>5/31/1939</td>\n",
       "      <td>RE</td>\n",
       "      <td>109343.2</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/13/2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172485</td>\n",
       "      <td>6.193018</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>-16.15</td>\n",
       "      <td>93</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EID  PID         DOB Eye   ImageID        Scan.Type  Diameter..mm.  \\\n",
       "0      1    1  10/24/1949  LE  282596.0  OCT Circle Scan            3.7   \n",
       "1      2    1  10/24/1949  RE  282593.0  OCT Circle Scan            3.7   \n",
       "2      3    2    8/7/1939  LE  239514.0  OCT Circle Scan            3.4   \n",
       "3      4    2    8/7/1939  RE  239512.0  OCT Circle Scan            3.4   \n",
       "4      5    3   5/20/1943  LE  238460.0  OCT Circle Scan            3.5   \n",
       "..   ...  ...         ...  ..       ...              ...            ...   \n",
       "579  580  329   3/22/1952  RE     837.0  OCT Circle Scan            3.7   \n",
       "580  581  330   5/15/1945  LE  243095.0  OCT Circle Scan            3.5   \n",
       "581  582  330   5/15/1945  RE  243093.0  OCT Circle Scan            3.7   \n",
       "582  583  331   5/31/1939  LE  109347.0  OCT Circle Scan            3.5   \n",
       "583  584  331   5/31/1939  RE  109343.2  OCT Circle Scan            3.5   \n",
       "\n",
       "     Diameter....  Fixed.in.mm    ExamDate  ... VF_OCT_BASELINE_DIFF  \\\n",
       "0            12.0            0   5/11/2017  ...             0.000000   \n",
       "1            12.0            0   5/11/2017  ...             0.000000   \n",
       "2            12.0            0   8/26/2014  ...             0.000000   \n",
       "3            12.0            0   8/26/2014  ...             0.000000   \n",
       "4            12.0            0    7/9/2014  ...             0.024641   \n",
       "..            ...          ...         ...  ...                  ...   \n",
       "579          12.0            0    5/5/2011  ...             0.000000   \n",
       "580          12.0            0  12/17/2014  ...             0.000000   \n",
       "581          12.0            0  12/17/2014  ...             0.000000   \n",
       "582          12.0            0   8/13/2013  ...             0.172485   \n",
       "583          12.0            0   8/13/2013  ...             0.172485   \n",
       "\n",
       "    VF_OCT_FINAL_DIFF  MD_BASELINE  MD_FINAL  VFI_BASELINE  VFI_FINAL  Y_GRI  \\\n",
       "0            3.561944        -2.15     -3.26            98         96      0   \n",
       "1            3.561944        -7.73    -11.45            82         73      1   \n",
       "2            6.151951        -1.28     -1.13            98         97      0   \n",
       "3            6.151951        -0.72      0.60            98         99      0   \n",
       "4            6.266940        -1.69     -0.51            99         99      0   \n",
       "..                ...          ...       ...           ...        ...    ...   \n",
       "579          9.601643         0.53     -2.51            98         93      1   \n",
       "580          5.941136        -8.97    -14.71            78         56      1   \n",
       "581          5.941136       -11.39    -11.37            70         67      1   \n",
       "582          6.193018        -3.48    -19.28            97         51      1   \n",
       "583          6.193018        -3.34    -16.15            93         47      1   \n",
       "\n",
       "     Y_MD  Y_VFI  Y_combined  \n",
       "0       0      0           0  \n",
       "1       0      0           1  \n",
       "2       0      0           0  \n",
       "3       0      0           0  \n",
       "4       0      0           0  \n",
       "..    ...    ...         ...  \n",
       "579     0      0           1  \n",
       "580     1      1           1  \n",
       "581     0      0           1  \n",
       "582     1      1           1  \n",
       "583     1      1           1  \n",
       "\n",
       "[584 rows x 815 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "df = pd.read_csv(\"/Users/a123456/Desktop/Fei's Project/Data/OCT_BASELINE_GRI__VF_6-3_FP-15_NO_PHI_CombinedProgression.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8339d0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 815)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter only circle scan data\n",
    "circle_scan = (df['Scan.Type'] == 'OCT Circle Scan')\n",
    "df = df[circle_scan]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a803e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a121a",
   "metadata": {},
   "source": [
    "## 1. GRI combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca65a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>RNFLT.1</th>\n",
       "      <th>RNFLT.2</th>\n",
       "      <th>RNFLT.3</th>\n",
       "      <th>RNFLT.4</th>\n",
       "      <th>RNFLT.5</th>\n",
       "      <th>RNFLT.6</th>\n",
       "      <th>RNFLT.7</th>\n",
       "      <th>RNFLT.8</th>\n",
       "      <th>RNFLT.9</th>\n",
       "      <th>...</th>\n",
       "      <th>RNFLT.761</th>\n",
       "      <th>RNFLT.762</th>\n",
       "      <th>RNFLT.763</th>\n",
       "      <th>RNFLT.764</th>\n",
       "      <th>RNFLT.765</th>\n",
       "      <th>RNFLT.766</th>\n",
       "      <th>RNFLT.767</th>\n",
       "      <th>RNFLT.768</th>\n",
       "      <th>GRI</th>\n",
       "      <th>Y_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-3.688171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.329429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.581343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>329</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-11.691467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>330</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-19.908699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>330</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-10.130481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>331</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-24.731627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>331</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-18.674765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PID  RNFLT.1  RNFLT.2  RNFLT.3  RNFLT.4  RNFLT.5  RNFLT.6  RNFLT.7  \\\n",
       "0      1     47.0     47.0     46.0     46.0     45.0     45.0     45.0   \n",
       "1      1     70.0     71.0     72.0     72.0     73.0     73.0     73.0   \n",
       "2      2     44.0     45.0     45.0     45.0     46.0     47.0     48.0   \n",
       "3      2     44.0     44.0     44.0     45.0     45.0     46.0     46.0   \n",
       "4      3     37.0     38.0     39.0     40.0     41.0     42.0     43.0   \n",
       "..   ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "579  329    100.0    103.0    106.0    108.0    111.0    112.0    113.0   \n",
       "580  330     52.0     52.0     53.0     54.0     55.0     56.0     57.0   \n",
       "581  330     62.0     63.0     64.0     65.0     66.0     67.0     68.0   \n",
       "582  331     47.0     47.0     48.0     48.0     49.0     49.0     50.0   \n",
       "583  331     31.0     31.0     32.0     33.0     33.0     34.0     35.0   \n",
       "\n",
       "     RNFLT.8  RNFLT.9  ...  RNFLT.761  RNFLT.762  RNFLT.763  RNFLT.764  \\\n",
       "0       45.0     45.0  ...       48.0       48.0       48.0       48.0   \n",
       "1       73.0     74.0  ...       60.0       61.0       62.0       63.0   \n",
       "2       50.0     51.0  ...       45.0       45.0       45.0       45.0   \n",
       "3       47.0     47.0  ...       43.0       43.0       43.0       43.0   \n",
       "4       44.0     46.0  ...       35.0       35.0       35.0       35.0   \n",
       "..       ...      ...  ...        ...        ...        ...        ...   \n",
       "579    113.0    113.0  ...       83.0       84.0       86.0       87.0   \n",
       "580     58.0     59.0  ...       47.0       47.0       48.0       48.0   \n",
       "581     68.0     68.0  ...       55.0       56.0       57.0       58.0   \n",
       "582     50.0     50.0  ...       47.0       46.0       46.0       45.0   \n",
       "583     36.0     37.0  ...       31.0       31.0       30.0       30.0   \n",
       "\n",
       "     RNFLT.765  RNFLT.766  RNFLT.767  RNFLT.768        GRI  Y_combined  \n",
       "0         48.0       48.0       48.0       47.0  -3.688171           0  \n",
       "1         65.0       66.0       67.0       69.0  -6.827438           1  \n",
       "2         45.0       45.0       45.0       44.0   0.329429           0  \n",
       "3         43.0       43.0       43.0       43.0   0.581343           0  \n",
       "4         35.0       35.0       36.0       36.0   0.000000           0  \n",
       "..         ...        ...        ...        ...        ...         ...  \n",
       "579       89.0       92.0       94.0       97.0 -11.691467           1  \n",
       "580       49.0       49.0       50.0       51.0 -19.908699           1  \n",
       "581       58.0       59.0       60.0       61.0 -10.130481           1  \n",
       "582       45.0       46.0       46.0       46.0 -24.731627           1  \n",
       "583       30.0       30.0       30.0       30.0 -18.674765           1  \n",
       "\n",
       "[580 rows x 771 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.iloc[:, np.r_[1, 28:797, 814]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "140f53df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 771)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop missing values\n",
    "df = df.dropna()\n",
    "df.isnull().values.sum()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db1849d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "579    1\n",
       "580    1\n",
       "581    1\n",
       "582    1\n",
       "583    1\n",
       "Name: Y_combined, Length: 575, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:, 770]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1886983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/applied-systems-biology/Dynamic_SPHARM/blob/master/SPHARM/classes/stratified_group_shuffle_split.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "class GroupShuffleSplitStratified(StratifiedShuffleSplit):\n",
    "\n",
    "    def __init__(self, n_splits=5, test_size=2, train_size=None, random_state=None):\n",
    "\n",
    "        super(GroupShuffleSplitStratified, self).__init__(\n",
    "            n_splits=n_splits,\n",
    "            test_size=test_size,\n",
    "            train_size=train_size,\n",
    "            random_state=random_state)\n",
    "\n",
    "    def _iter_indices(self, X, y, groups):\n",
    "        if groups is None:\n",
    "            raise ValueError(\"The 'groups' parameter should not be None.\")\n",
    "        groups = check_array(groups, ensure_2d=False, dtype=None)\n",
    "        groups_unique, group_indices = np.unique(groups, return_inverse=True)\n",
    "        classes = []\n",
    "        for gr in groups_unique:\n",
    "            classes.append(y[np.where(groups==gr)[0][0]])\n",
    "\n",
    "        for group_train, group_test in super(\n",
    "                GroupShuffleSplitStratified, self)._iter_indices(X=groups_unique, y=classes):\n",
    "            # these are the indices of classes in the partition\n",
    "            # invert them into data indices\n",
    "\n",
    "            train = np.flatnonzero(np.in1d(group_indices, group_train))\n",
    "            test = np.flatnonzero(np.in1d(group_indices, group_test))\n",
    "\n",
    "            yield train, test\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        return super(GroupShuffleSplitStratified, self).split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec75b0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(516, 771)\n",
      "(59, 771)\n"
     ]
    }
   ],
   "source": [
    "train_i,test_i = next(GroupShuffleSplitStratified(n_splits=2, test_size=0.1,\n",
    "                                        random_state=8).split(df,y, groups=df['PID']))\n",
    "TrainVal = df.iloc[train_i]\n",
    "TestSet = df.iloc[test_i]\n",
    "print(TrainVal.shape)\n",
    "print(TestSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e1083ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463, 771)\n",
      "(53, 771)\n"
     ]
    }
   ],
   "source": [
    "train_id,val_id = next(GroupShuffleSplitStratified(n_splits=2, test_size=0.1,\n",
    "                                        random_state=8).split(TrainVal,y.iloc[train_i], groups=TrainVal['PID']))\n",
    "TrainSet = TrainVal.iloc[train_id]\n",
    "ValSet = TrainVal.iloc[val_id]\n",
    "print(TrainSet.shape)\n",
    "print(ValSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6fa3d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(59, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNFLT.1</th>\n",
       "      <th>RNFLT.2</th>\n",
       "      <th>RNFLT.3</th>\n",
       "      <th>RNFLT.4</th>\n",
       "      <th>RNFLT.5</th>\n",
       "      <th>RNFLT.6</th>\n",
       "      <th>RNFLT.7</th>\n",
       "      <th>RNFLT.8</th>\n",
       "      <th>RNFLT.9</th>\n",
       "      <th>RNFLT.10</th>\n",
       "      <th>...</th>\n",
       "      <th>RNFLT.759</th>\n",
       "      <th>RNFLT.760</th>\n",
       "      <th>RNFLT.761</th>\n",
       "      <th>RNFLT.762</th>\n",
       "      <th>RNFLT.763</th>\n",
       "      <th>RNFLT.764</th>\n",
       "      <th>RNFLT.765</th>\n",
       "      <th>RNFLT.766</th>\n",
       "      <th>RNFLT.767</th>\n",
       "      <th>RNFLT.768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>85.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RNFLT.1  RNFLT.2  RNFLT.3  RNFLT.4  RNFLT.5  RNFLT.6  RNFLT.7  RNFLT.8  \\\n",
       "28     60.0     61.0     61.0     62.0     62.0     63.0     63.0     64.0   \n",
       "29    100.0    104.0    106.0    106.0    104.0    101.0     97.0     92.0   \n",
       "71     35.0     36.0     37.0     37.0     38.0     39.0     40.0     40.0   \n",
       "72     73.0     73.0     73.0     74.0     74.0     75.0     75.0     76.0   \n",
       "73     85.0     86.0     87.0     88.0     89.0     91.0     93.0     94.0   \n",
       "\n",
       "    RNFLT.9  RNFLT.10  ...  RNFLT.759  RNFLT.760  RNFLT.761  RNFLT.762  \\\n",
       "28     64.0      65.0  ...       53.0       54.0       54.0       55.0   \n",
       "29     88.0      84.0  ...       61.0       63.0       64.0       67.0   \n",
       "71     41.0      42.0  ...       30.0       30.0       30.0       31.0   \n",
       "72     77.0      77.0  ...       72.0       72.0       72.0       72.0   \n",
       "73     96.0      98.0  ...       74.0       75.0       76.0       77.0   \n",
       "\n",
       "    RNFLT.763  RNFLT.764  RNFLT.765  RNFLT.766  RNFLT.767  RNFLT.768  \n",
       "28       55.0       56.0       57.0       58.0       58.0       59.0  \n",
       "29       70.0       74.0       79.0       84.0       90.0       95.0  \n",
       "71       31.0       32.0       32.0       33.0       34.0       34.0  \n",
       "72       72.0       72.0       73.0       73.0       73.0       73.0  \n",
       "73       78.0       79.0       80.0       81.0       82.0       83.0  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.iloc[test_i, 1:769]\n",
    "print(x.isnull().values.sum())\n",
    "print(x.shape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d21afa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_test = scaled_x\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c5e7a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = TrainVal.iloc[train_id, 1:769]\n",
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_train = scaled_x\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b588be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = TrainVal.iloc[val_id, 1:769]\n",
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_val = scaled_x\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "519b6d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1\n",
      "1  0    394\n",
      "0  1    181\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1\n",
       "0    1  0\n",
       "1    0  1\n",
       "2    1  0\n",
       "3    1  0\n",
       "4    1  0\n",
       "..  .. ..\n",
       "579  0  1\n",
       "580  0  1\n",
       "581  0  1\n",
       "582  0  1\n",
       "583  0  1\n",
       "\n",
       "[575 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot-encoding our label\n",
    "y = pd.get_dummies(y)\n",
    "print(y.value_counts())\n",
    "y #The second column is 'progressor', The first column is 'non-progressor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffa769f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "0                 1           0\n",
       "1                 0           1\n",
       "2                 1           0\n",
       "3                 1           0\n",
       "4                 1           0\n",
       "..              ...         ...\n",
       "579               0           1\n",
       "580               0           1\n",
       "581               0           1\n",
       "582               0           1\n",
       "583               0           1\n",
       "\n",
       "[575 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.rename(columns={0: \"Non-Progressor\", 1: \"Progressor\"})\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eab6dd09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "28                1           0\n",
       "29                1           0\n",
       "71                0           1\n",
       "72                0           1\n",
       "73                0           1\n",
       "96                0           1\n",
       "97                1           0\n",
       "122               1           0\n",
       "123               0           1\n",
       "152               1           0\n",
       "153               1           0\n",
       "154               1           0\n",
       "155               0           1\n",
       "203               1           0\n",
       "204               1           0\n",
       "209               1           0\n",
       "210               1           0\n",
       "211               1           0\n",
       "212               0           1\n",
       "224               0           1\n",
       "225               0           1\n",
       "244               0           1\n",
       "254               0           1\n",
       "255               1           0\n",
       "256               1           0\n",
       "257               0           1\n",
       "258               1           0\n",
       "259               1           0\n",
       "265               1           0\n",
       "266               0           1\n",
       "267               1           0\n",
       "268               1           0\n",
       "281               1           0\n",
       "282               1           0\n",
       "320               1           0\n",
       "324               0           1\n",
       "325               1           0\n",
       "328               1           0\n",
       "329               1           0\n",
       "330               1           0\n",
       "331               1           0\n",
       "346               1           0\n",
       "347               1           0\n",
       "384               1           0\n",
       "451               1           0\n",
       "452               0           1\n",
       "453               0           1\n",
       "458               0           1\n",
       "459               1           0\n",
       "465               0           1\n",
       "466               0           1\n",
       "467               0           1\n",
       "468               1           0\n",
       "494               1           0\n",
       "495               1           0\n",
       "501               1           0\n",
       "520               1           0\n",
       "521               0           1\n",
       "570               1           0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y.iloc[test_i]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6f1d998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "0                 1           0\n",
       "1                 0           1\n",
       "2                 1           0\n",
       "3                 1           0\n",
       "4                 1           0\n",
       "..              ...         ...\n",
       "579               0           1\n",
       "580               0           1\n",
       "581               0           1\n",
       "582               0           1\n",
       "583               0           1\n",
       "\n",
       "[463 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y.iloc[train_i].iloc[train_id]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4e9e298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "12                0           1\n",
       "32                1           0\n",
       "33                1           0\n",
       "40                0           1\n",
       "49                0           1\n",
       "50                1           0\n",
       "102               0           1\n",
       "126               1           0\n",
       "127               1           0\n",
       "128               0           1\n",
       "133               0           1\n",
       "134               0           1\n",
       "160               1           0\n",
       "161               1           0\n",
       "162               1           0\n",
       "163               1           0\n",
       "221               1           0\n",
       "222               1           0\n",
       "228               1           0\n",
       "229               1           0\n",
       "230               1           0\n",
       "231               0           1\n",
       "238               0           1\n",
       "239               1           0\n",
       "283               1           0\n",
       "284               0           1\n",
       "285               1           0\n",
       "286               1           0\n",
       "291               1           0\n",
       "292               1           0\n",
       "293               1           0\n",
       "294               0           1\n",
       "305               1           0\n",
       "306               1           0\n",
       "334               0           1\n",
       "335               0           1\n",
       "364               1           0\n",
       "365               1           0\n",
       "370               1           0\n",
       "371               1           0\n",
       "398               1           0\n",
       "438               1           0\n",
       "439               1           0\n",
       "447               0           1\n",
       "448               0           1\n",
       "506               1           0\n",
       "507               0           1\n",
       "542               0           1\n",
       "543               1           0\n",
       "552               1           0\n",
       "553               1           0\n",
       "566               1           0\n",
       "567               0           1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = y.iloc[train_i].iloc[val_id]\n",
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aa36dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463, 768, 1)\n",
      "(59, 768, 1)\n",
      "(53, 768, 1)\n",
      "Non-Progressor  Progressor\n",
      "1               0             321\n",
      "0               1             142\n",
      "dtype: int64 \n",
      "\n",
      "Non-Progressor  Progressor\n",
      "1               0             35\n",
      "0               1             18\n",
      "dtype: int64 \n",
      "\n",
      "Non-Progressor  Progressor\n",
      "1               0             38\n",
      "0               1             21\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.value_counts(), '\\n')\n",
    "print(y_val.value_counts(), '\\n')\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e84aaf",
   "metadata": {},
   "source": [
    "### 1.1 No resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a51abe",
   "metadata": {},
   "source": [
    "#### 1.1.1 Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b80026ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=400,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f187398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 766, 64)           256       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 255, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 255, 64)           0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 16320)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                1044544   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,045,874\n",
      "Trainable params: 1,045,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model1\n",
    "model_111 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_111.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_111.add(MaxPooling1D(pool_size=3))\n",
    "# model_1.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_111.add(Dropout(0.5))\n",
    "# model_1.add(MaxPooling1D(pool_size=2))\n",
    "model_111.add(Flatten())\n",
    "model_111.add(Dense(64, activation='relu'))\n",
    "model_111.add(Dense(16, activation='relu'))\n",
    "model_111.add(Dense(2, activation='softmax'))\n",
    "model_111.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a379a1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6152 - accuracy: 0.6803 - val_loss: 0.6440 - val_accuracy: 0.6604\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.6098 - accuracy: 0.6933 - val_loss: 0.6165 - val_accuracy: 0.6604\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.6038 - accuracy: 0.6933 - val_loss: 0.6204 - val_accuracy: 0.6604\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.6003 - accuracy: 0.6933 - val_loss: 0.6116 - val_accuracy: 0.6604\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5993 - accuracy: 0.6933 - val_loss: 0.6123 - val_accuracy: 0.6604\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5953 - accuracy: 0.6933 - val_loss: 0.6075 - val_accuracy: 0.6604\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5976 - accuracy: 0.6933 - val_loss: 0.6067 - val_accuracy: 0.6604\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5924 - accuracy: 0.6933 - val_loss: 0.6072 - val_accuracy: 0.6604\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5937 - accuracy: 0.6911 - val_loss: 0.6021 - val_accuracy: 0.6604\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5940 - accuracy: 0.6933 - val_loss: 0.6077 - val_accuracy: 0.6604\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5915 - accuracy: 0.6955 - val_loss: 0.6000 - val_accuracy: 0.6604\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5869 - accuracy: 0.6933 - val_loss: 0.6021 - val_accuracy: 0.6604\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5843 - accuracy: 0.6955 - val_loss: 0.5978 - val_accuracy: 0.6604\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5871 - accuracy: 0.6955 - val_loss: 0.6006 - val_accuracy: 0.6604\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5832 - accuracy: 0.6955 - val_loss: 0.5980 - val_accuracy: 0.6604\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5828 - accuracy: 0.6976 - val_loss: 0.5977 - val_accuracy: 0.6604\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.5784 - accuracy: 0.6955 - val_loss: 0.5971 - val_accuracy: 0.6604\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5757 - accuracy: 0.7019 - val_loss: 0.5935 - val_accuracy: 0.6604\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5752 - accuracy: 0.6998 - val_loss: 0.5948 - val_accuracy: 0.6604\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5726 - accuracy: 0.7019 - val_loss: 0.5926 - val_accuracy: 0.6604\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5713 - accuracy: 0.7041 - val_loss: 0.5906 - val_accuracy: 0.6604\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5700 - accuracy: 0.7063 - val_loss: 0.5899 - val_accuracy: 0.6604\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5709 - accuracy: 0.7149 - val_loss: 0.5866 - val_accuracy: 0.6604\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.5667 - accuracy: 0.7127 - val_loss: 0.5837 - val_accuracy: 0.6604\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5605 - accuracy: 0.7235 - val_loss: 0.5793 - val_accuracy: 0.6792\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5607 - accuracy: 0.7063 - val_loss: 0.5828 - val_accuracy: 0.6792\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.5593 - accuracy: 0.7235 - val_loss: 0.5814 - val_accuracy: 0.6792\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5597 - accuracy: 0.7235 - val_loss: 0.5802 - val_accuracy: 0.6792\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5659 - accuracy: 0.7171 - val_loss: 0.5871 - val_accuracy: 0.6792\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5605 - accuracy: 0.7300 - val_loss: 0.5836 - val_accuracy: 0.6792\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5577 - accuracy: 0.7127 - val_loss: 0.5842 - val_accuracy: 0.6792\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5575 - accuracy: 0.7214 - val_loss: 0.5872 - val_accuracy: 0.6604\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5561 - accuracy: 0.7300 - val_loss: 0.5875 - val_accuracy: 0.6792\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5527 - accuracy: 0.7343 - val_loss: 0.5844 - val_accuracy: 0.6604\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5482 - accuracy: 0.7387 - val_loss: 0.5856 - val_accuracy: 0.6604\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5481 - accuracy: 0.7343 - val_loss: 0.5852 - val_accuracy: 0.6792\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5515 - accuracy: 0.7365 - val_loss: 0.5890 - val_accuracy: 0.6792\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5438 - accuracy: 0.7473 - val_loss: 0.5869 - val_accuracy: 0.6604\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5469 - accuracy: 0.7581 - val_loss: 0.5895 - val_accuracy: 0.6792\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5448 - accuracy: 0.7387 - val_loss: 0.5836 - val_accuracy: 0.6604\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5399 - accuracy: 0.7516 - val_loss: 0.5893 - val_accuracy: 0.6792\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5388 - accuracy: 0.7516 - val_loss: 0.5874 - val_accuracy: 0.6604\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5398 - accuracy: 0.7603 - val_loss: 0.5839 - val_accuracy: 0.6981\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.5373 - accuracy: 0.7581 - val_loss: 0.5893 - val_accuracy: 0.6604\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5412 - accuracy: 0.7365 - val_loss: 0.5861 - val_accuracy: 0.6604\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5389 - accuracy: 0.7495 - val_loss: 0.5889 - val_accuracy: 0.6792\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5301 - accuracy: 0.7581 - val_loss: 0.5875 - val_accuracy: 0.6415\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5320 - accuracy: 0.7667 - val_loss: 0.5876 - val_accuracy: 0.6415\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5282 - accuracy: 0.7624 - val_loss: 0.5897 - val_accuracy: 0.6604\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5320 - accuracy: 0.7473 - val_loss: 0.5888 - val_accuracy: 0.6415\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5283 - accuracy: 0.7732 - val_loss: 0.5910 - val_accuracy: 0.6415\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5279 - accuracy: 0.7646 - val_loss: 0.5908 - val_accuracy: 0.6415\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5202 - accuracy: 0.7711 - val_loss: 0.5844 - val_accuracy: 0.6415\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5260 - accuracy: 0.7624 - val_loss: 0.5877 - val_accuracy: 0.6226\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5170 - accuracy: 0.7732 - val_loss: 0.5879 - val_accuracy: 0.6226\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5212 - accuracy: 0.7667 - val_loss: 0.5902 - val_accuracy: 0.6038\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5189 - accuracy: 0.7624 - val_loss: 0.5888 - val_accuracy: 0.6415\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5202 - accuracy: 0.7624 - val_loss: 0.5912 - val_accuracy: 0.6038\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5266 - accuracy: 0.7775 - val_loss: 0.5924 - val_accuracy: 0.6226\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5132 - accuracy: 0.7667 - val_loss: 0.5916 - val_accuracy: 0.5849\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5146 - accuracy: 0.7667 - val_loss: 0.5934 - val_accuracy: 0.6038\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5127 - accuracy: 0.7797 - val_loss: 0.5900 - val_accuracy: 0.6415\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5176 - accuracy: 0.7603 - val_loss: 0.5937 - val_accuracy: 0.6038\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5173 - accuracy: 0.7732 - val_loss: 0.5960 - val_accuracy: 0.6415\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5080 - accuracy: 0.7797 - val_loss: 0.6002 - val_accuracy: 0.6415\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5069 - accuracy: 0.7797 - val_loss: 0.5919 - val_accuracy: 0.6226\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5094 - accuracy: 0.7667 - val_loss: 0.5980 - val_accuracy: 0.6415\n",
      "Epoch 68/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5104 - accuracy: 0.7797 - val_loss: 0.5957 - val_accuracy: 0.6038\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5062 - accuracy: 0.7732 - val_loss: 0.5961 - val_accuracy: 0.6038\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5076 - accuracy: 0.7797 - val_loss: 0.6005 - val_accuracy: 0.6415\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5036 - accuracy: 0.7603 - val_loss: 0.5992 - val_accuracy: 0.6226\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4989 - accuracy: 0.7819 - val_loss: 0.6011 - val_accuracy: 0.6038\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4962 - accuracy: 0.7819 - val_loss: 0.6056 - val_accuracy: 0.6226\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4966 - accuracy: 0.7732 - val_loss: 0.6001 - val_accuracy: 0.6226\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4917 - accuracy: 0.7883 - val_loss: 0.6024 - val_accuracy: 0.6226\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4990 - accuracy: 0.7840 - val_loss: 0.6015 - val_accuracy: 0.6038\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4896 - accuracy: 0.7840 - val_loss: 0.6047 - val_accuracy: 0.6226\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4924 - accuracy: 0.7667 - val_loss: 0.6066 - val_accuracy: 0.6226\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4966 - accuracy: 0.7819 - val_loss: 0.6071 - val_accuracy: 0.6415\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4889 - accuracy: 0.7840 - val_loss: 0.6080 - val_accuracy: 0.6415\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4829 - accuracy: 0.7883 - val_loss: 0.6075 - val_accuracy: 0.6415\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4830 - accuracy: 0.7840 - val_loss: 0.6108 - val_accuracy: 0.6415\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4828 - accuracy: 0.7927 - val_loss: 0.6117 - val_accuracy: 0.6415\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4811 - accuracy: 0.7862 - val_loss: 0.6104 - val_accuracy: 0.6226\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4848 - accuracy: 0.7840 - val_loss: 0.6133 - val_accuracy: 0.6226\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4856 - accuracy: 0.7948 - val_loss: 0.6156 - val_accuracy: 0.6226\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.4822 - accuracy: 0.7905 - val_loss: 0.6134 - val_accuracy: 0.6226\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4847 - accuracy: 0.7970 - val_loss: 0.6158 - val_accuracy: 0.6226\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4703 - accuracy: 0.7970 - val_loss: 0.6187 - val_accuracy: 0.6415\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4765 - accuracy: 0.7862 - val_loss: 0.6230 - val_accuracy: 0.6415\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4824 - accuracy: 0.8078 - val_loss: 0.6184 - val_accuracy: 0.6226\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4746 - accuracy: 0.8013 - val_loss: 0.6213 - val_accuracy: 0.6415\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4773 - accuracy: 0.7883 - val_loss: 0.6211 - val_accuracy: 0.6226\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4778 - accuracy: 0.7970 - val_loss: 0.6223 - val_accuracy: 0.6226\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4685 - accuracy: 0.8035 - val_loss: 0.6217 - val_accuracy: 0.6226\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4625 - accuracy: 0.8056 - val_loss: 0.6249 - val_accuracy: 0.6415\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4692 - accuracy: 0.8013 - val_loss: 0.6203 - val_accuracy: 0.6415\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4682 - accuracy: 0.8078 - val_loss: 0.6250 - val_accuracy: 0.6226\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4664 - accuracy: 0.7948 - val_loss: 0.6239 - val_accuracy: 0.6415\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4615 - accuracy: 0.8056 - val_loss: 0.6243 - val_accuracy: 0.6226\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4599 - accuracy: 0.8056 - val_loss: 0.6241 - val_accuracy: 0.6226\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4660 - accuracy: 0.7970 - val_loss: 0.6269 - val_accuracy: 0.6604\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4562 - accuracy: 0.8143 - val_loss: 0.6284 - val_accuracy: 0.6415\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4612 - accuracy: 0.8013 - val_loss: 0.6287 - val_accuracy: 0.6415\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4617 - accuracy: 0.8121 - val_loss: 0.6322 - val_accuracy: 0.6415\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4614 - accuracy: 0.8056 - val_loss: 0.6274 - val_accuracy: 0.6792\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4593 - accuracy: 0.8035 - val_loss: 0.6312 - val_accuracy: 0.6226\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4489 - accuracy: 0.8099 - val_loss: 0.6289 - val_accuracy: 0.6415\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4503 - accuracy: 0.8186 - val_loss: 0.6343 - val_accuracy: 0.6226\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4452 - accuracy: 0.8035 - val_loss: 0.6364 - val_accuracy: 0.6226\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4451 - accuracy: 0.7970 - val_loss: 0.6337 - val_accuracy: 0.6604\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4418 - accuracy: 0.8121 - val_loss: 0.6383 - val_accuracy: 0.6226\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4555 - accuracy: 0.8013 - val_loss: 0.6367 - val_accuracy: 0.6415\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4376 - accuracy: 0.8143 - val_loss: 0.6360 - val_accuracy: 0.6415\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4357 - accuracy: 0.8121 - val_loss: 0.6396 - val_accuracy: 0.6415\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4390 - accuracy: 0.8056 - val_loss: 0.6412 - val_accuracy: 0.6226\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4405 - accuracy: 0.8207 - val_loss: 0.6438 - val_accuracy: 0.6226\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4325 - accuracy: 0.8164 - val_loss: 0.6456 - val_accuracy: 0.6415\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4405 - accuracy: 0.8164 - val_loss: 0.6455 - val_accuracy: 0.6226\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4341 - accuracy: 0.8207 - val_loss: 0.6458 - val_accuracy: 0.6415\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4467 - accuracy: 0.8099 - val_loss: 0.6444 - val_accuracy: 0.6792\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4486 - accuracy: 0.7840 - val_loss: 0.6542 - val_accuracy: 0.6415\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4309 - accuracy: 0.8164 - val_loss: 0.6463 - val_accuracy: 0.6415\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4279 - accuracy: 0.8207 - val_loss: 0.6457 - val_accuracy: 0.6604\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4292 - accuracy: 0.8164 - val_loss: 0.6511 - val_accuracy: 0.6415\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4215 - accuracy: 0.8294 - val_loss: 0.6566 - val_accuracy: 0.6226\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4225 - accuracy: 0.8315 - val_loss: 0.6520 - val_accuracy: 0.6415\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4149 - accuracy: 0.8251 - val_loss: 0.6580 - val_accuracy: 0.6226\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4251 - accuracy: 0.8164 - val_loss: 0.6531 - val_accuracy: 0.6415\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4228 - accuracy: 0.8164 - val_loss: 0.6584 - val_accuracy: 0.6226\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4193 - accuracy: 0.8337 - val_loss: 0.6605 - val_accuracy: 0.6226\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4137 - accuracy: 0.8337 - val_loss: 0.6569 - val_accuracy: 0.6415\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4143 - accuracy: 0.8315 - val_loss: 0.6608 - val_accuracy: 0.6415\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4224 - accuracy: 0.8229 - val_loss: 0.6630 - val_accuracy: 0.6226\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4249 - accuracy: 0.8186 - val_loss: 0.6673 - val_accuracy: 0.6226\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.4149 - accuracy: 0.8251 - val_loss: 0.6619 - val_accuracy: 0.6415\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4104 - accuracy: 0.8251 - val_loss: 0.6793 - val_accuracy: 0.6226\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4159 - accuracy: 0.8186 - val_loss: 0.6693 - val_accuracy: 0.6226\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4109 - accuracy: 0.8272 - val_loss: 0.6703 - val_accuracy: 0.6226\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4180 - accuracy: 0.8423 - val_loss: 0.6698 - val_accuracy: 0.6226\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4146 - accuracy: 0.8315 - val_loss: 0.6735 - val_accuracy: 0.6038\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4131 - accuracy: 0.8186 - val_loss: 0.6713 - val_accuracy: 0.6226\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3997 - accuracy: 0.8251 - val_loss: 0.6723 - val_accuracy: 0.6604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89716a1d00>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_111.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_111.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecac5871",
   "metadata": {},
   "source": [
    "**For test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb538ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5662 - accuracy: 0.7288\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.6981\n"
     ]
    }
   ],
   "source": [
    "m1_eval_test = model_111.evaluate(X_test, y_test)\n",
    "m1_eval_val = model_111.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e64d8779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n",
      "roc auc score:  0.7393483709273183\n",
      "average precision score:  0.7548260536253177\n"
     ]
    }
   ],
   "source": [
    "pred = model_111.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "172851fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6e98670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5662 - accuracy: 0.7288\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_111.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e26fcf",
   "metadata": {},
   "source": [
    "**For validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e23110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n",
      "roc auc score:  0.7031746031746031\n",
      "average precision score:  0.6759629560349194\n"
     ]
    }
   ],
   "source": [
    "pred = model_111.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8997e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df6f7ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.6981\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels (validation set)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_111.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca205895",
   "metadata": {},
   "source": [
    "#### 1.1.2 Alvin's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2e61488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 766, 64)           256       \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 764, 32)           6176      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 24448)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 112)               2738288   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 226       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,744,946\n",
      "Trainable params: 2,744,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model1\n",
    "model_112 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_112.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_112.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_112.add(Flatten())\n",
    "model_112.add(Dense(112, activation='relu'))\n",
    "model_112.add(Dense(2, activation='softmax'))\n",
    "model_112.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c29824fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=400,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "facef235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 0.6344 - accuracy: 0.6631 - val_loss: 0.6316 - val_accuracy: 0.6604\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.6071 - accuracy: 0.6933 - val_loss: 0.6200 - val_accuracy: 0.6604\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6052 - accuracy: 0.6933 - val_loss: 0.6175 - val_accuracy: 0.6604\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.6034 - accuracy: 0.6933 - val_loss: 0.6184 - val_accuracy: 0.6604\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.6010 - accuracy: 0.6933 - val_loss: 0.6144 - val_accuracy: 0.6604\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5988 - accuracy: 0.6933 - val_loss: 0.6122 - val_accuracy: 0.6604\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5989 - accuracy: 0.6933 - val_loss: 0.6093 - val_accuracy: 0.6604\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5944 - accuracy: 0.6933 - val_loss: 0.6104 - val_accuracy: 0.6604\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5920 - accuracy: 0.6955 - val_loss: 0.6058 - val_accuracy: 0.6604\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5885 - accuracy: 0.6976 - val_loss: 0.6034 - val_accuracy: 0.6604\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5853 - accuracy: 0.6998 - val_loss: 0.6060 - val_accuracy: 0.6604\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5826 - accuracy: 0.6976 - val_loss: 0.6017 - val_accuracy: 0.6415\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.5800 - accuracy: 0.7019 - val_loss: 0.5995 - val_accuracy: 0.6415\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5756 - accuracy: 0.7041 - val_loss: 0.6003 - val_accuracy: 0.6415\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5694 - accuracy: 0.7084 - val_loss: 0.6005 - val_accuracy: 0.6415\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.5666 - accuracy: 0.7106 - val_loss: 0.5972 - val_accuracy: 0.6415\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5678 - accuracy: 0.7127 - val_loss: 0.5985 - val_accuracy: 0.6415\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5605 - accuracy: 0.7106 - val_loss: 0.5981 - val_accuracy: 0.6415\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5541 - accuracy: 0.7149 - val_loss: 0.5999 - val_accuracy: 0.6415\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5485 - accuracy: 0.7192 - val_loss: 0.5989 - val_accuracy: 0.6604\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5488 - accuracy: 0.7387 - val_loss: 0.6077 - val_accuracy: 0.6415\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5465 - accuracy: 0.7192 - val_loss: 0.6009 - val_accuracy: 0.6604\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5365 - accuracy: 0.7257 - val_loss: 0.6046 - val_accuracy: 0.6415\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.5341 - accuracy: 0.7300 - val_loss: 0.6025 - val_accuracy: 0.6604\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5281 - accuracy: 0.7279 - val_loss: 0.6092 - val_accuracy: 0.6604\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5281 - accuracy: 0.7127 - val_loss: 0.6062 - val_accuracy: 0.6792\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5234 - accuracy: 0.7343 - val_loss: 0.6046 - val_accuracy: 0.6792\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.5253 - accuracy: 0.7408 - val_loss: 0.6129 - val_accuracy: 0.6604\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.5159 - accuracy: 0.7430 - val_loss: 0.6083 - val_accuracy: 0.6604\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.5106 - accuracy: 0.7430 - val_loss: 0.6089 - val_accuracy: 0.6981\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.5020 - accuracy: 0.7581 - val_loss: 0.6139 - val_accuracy: 0.6604\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5014 - accuracy: 0.7516 - val_loss: 0.6105 - val_accuracy: 0.6981\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.4984 - accuracy: 0.7646 - val_loss: 0.6157 - val_accuracy: 0.6792\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.4932 - accuracy: 0.7581 - val_loss: 0.6151 - val_accuracy: 0.6604\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.4878 - accuracy: 0.7667 - val_loss: 0.6130 - val_accuracy: 0.6792\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.4850 - accuracy: 0.7775 - val_loss: 0.6168 - val_accuracy: 0.6981\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.4814 - accuracy: 0.7689 - val_loss: 0.6190 - val_accuracy: 0.6981\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.4755 - accuracy: 0.7797 - val_loss: 0.6364 - val_accuracy: 0.6604\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.4795 - accuracy: 0.7711 - val_loss: 0.6310 - val_accuracy: 0.6604\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4745 - accuracy: 0.7819 - val_loss: 0.6203 - val_accuracy: 0.7170\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.4682 - accuracy: 0.7948 - val_loss: 0.6248 - val_accuracy: 0.6792\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.4712 - accuracy: 0.7819 - val_loss: 0.6370 - val_accuracy: 0.6981\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4575 - accuracy: 0.7819 - val_loss: 0.6338 - val_accuracy: 0.6792\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.4598 - accuracy: 0.7775 - val_loss: 0.6344 - val_accuracy: 0.6226\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4511 - accuracy: 0.7991 - val_loss: 0.6364 - val_accuracy: 0.6981\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.4489 - accuracy: 0.7819 - val_loss: 0.6425 - val_accuracy: 0.6604\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.4435 - accuracy: 0.7991 - val_loss: 0.6455 - val_accuracy: 0.6981\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.4366 - accuracy: 0.7991 - val_loss: 0.6421 - val_accuracy: 0.6792\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.4338 - accuracy: 0.7927 - val_loss: 0.6425 - val_accuracy: 0.6792\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4379 - accuracy: 0.8078 - val_loss: 0.6449 - val_accuracy: 0.6792\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.4326 - accuracy: 0.8143 - val_loss: 0.6686 - val_accuracy: 0.6792\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.4237 - accuracy: 0.8078 - val_loss: 0.6552 - val_accuracy: 0.6792\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4147 - accuracy: 0.8056 - val_loss: 0.6696 - val_accuracy: 0.6792\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4296 - accuracy: 0.8078 - val_loss: 0.6628 - val_accuracy: 0.6226\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4192 - accuracy: 0.8186 - val_loss: 0.6664 - val_accuracy: 0.6792\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4087 - accuracy: 0.8207 - val_loss: 0.6967 - val_accuracy: 0.6981\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4125 - accuracy: 0.8035 - val_loss: 0.6810 - val_accuracy: 0.6415\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3988 - accuracy: 0.8251 - val_loss: 0.6731 - val_accuracy: 0.6604\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3967 - accuracy: 0.8251 - val_loss: 0.6844 - val_accuracy: 0.6792\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4043 - accuracy: 0.8402 - val_loss: 0.7129 - val_accuracy: 0.6604\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3899 - accuracy: 0.8251 - val_loss: 0.6824 - val_accuracy: 0.6604\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3832 - accuracy: 0.8423 - val_loss: 0.7134 - val_accuracy: 0.6415\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3926 - accuracy: 0.8315 - val_loss: 0.7088 - val_accuracy: 0.6415\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3856 - accuracy: 0.8488 - val_loss: 0.7008 - val_accuracy: 0.6604\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.3750 - accuracy: 0.8359 - val_loss: 0.6932 - val_accuracy: 0.6604\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3761 - accuracy: 0.8596 - val_loss: 0.6934 - val_accuracy: 0.6604\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3613 - accuracy: 0.8510 - val_loss: 0.7253 - val_accuracy: 0.6415\n",
      "Epoch 68/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3736 - accuracy: 0.8553 - val_loss: 0.7167 - val_accuracy: 0.6415\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.3584 - accuracy: 0.8510 - val_loss: 0.7168 - val_accuracy: 0.6415\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3546 - accuracy: 0.8618 - val_loss: 0.7111 - val_accuracy: 0.6604\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3451 - accuracy: 0.8726 - val_loss: 0.7138 - val_accuracy: 0.6604\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3417 - accuracy: 0.8618 - val_loss: 0.7394 - val_accuracy: 0.6792\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3552 - accuracy: 0.8575 - val_loss: 0.7571 - val_accuracy: 0.6792\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3328 - accuracy: 0.8747 - val_loss: 0.7297 - val_accuracy: 0.6604\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3320 - accuracy: 0.8769 - val_loss: 0.7499 - val_accuracy: 0.6604\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3191 - accuracy: 0.8790 - val_loss: 0.7333 - val_accuracy: 0.6604\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3350 - accuracy: 0.8790 - val_loss: 0.7384 - val_accuracy: 0.6415\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.3214 - accuracy: 0.8704 - val_loss: 0.7508 - val_accuracy: 0.6415\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3264 - accuracy: 0.8661 - val_loss: 0.7897 - val_accuracy: 0.6792\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3233 - accuracy: 0.8683 - val_loss: 0.7815 - val_accuracy: 0.6792\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.3100 - accuracy: 0.8769 - val_loss: 0.8245 - val_accuracy: 0.6604\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.3161 - accuracy: 0.8661 - val_loss: 0.7596 - val_accuracy: 0.6604\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.3066 - accuracy: 0.8877 - val_loss: 0.7561 - val_accuracy: 0.6038\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.2963 - accuracy: 0.8855 - val_loss: 0.7641 - val_accuracy: 0.6604\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.2870 - accuracy: 0.8877 - val_loss: 0.7828 - val_accuracy: 0.6415\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.3106 - accuracy: 0.8790 - val_loss: 0.7857 - val_accuracy: 0.5849\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2835 - accuracy: 0.8877 - val_loss: 0.7971 - val_accuracy: 0.6604\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2757 - accuracy: 0.9028 - val_loss: 0.8323 - val_accuracy: 0.6604\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2716 - accuracy: 0.8963 - val_loss: 0.8148 - val_accuracy: 0.5849\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2681 - accuracy: 0.8942 - val_loss: 0.8218 - val_accuracy: 0.6415\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.2660 - accuracy: 0.8985 - val_loss: 0.8176 - val_accuracy: 0.6415\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2610 - accuracy: 0.9028 - val_loss: 0.8250 - val_accuracy: 0.6226\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2513 - accuracy: 0.9136 - val_loss: 0.8473 - val_accuracy: 0.6226\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2550 - accuracy: 0.9071 - val_loss: 0.8471 - val_accuracy: 0.6604\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2494 - accuracy: 0.9201 - val_loss: 0.8483 - val_accuracy: 0.5849\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.2386 - accuracy: 0.9266 - val_loss: 0.8843 - val_accuracy: 0.6604\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2395 - accuracy: 0.9222 - val_loss: 0.8820 - val_accuracy: 0.6038\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2292 - accuracy: 0.9266 - val_loss: 0.8852 - val_accuracy: 0.6226\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.2297 - accuracy: 0.9266 - val_loss: 0.8967 - val_accuracy: 0.6415\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2419 - accuracy: 0.9093 - val_loss: 0.8997 - val_accuracy: 0.5849\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2216 - accuracy: 0.9266 - val_loss: 0.8881 - val_accuracy: 0.5849\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2165 - accuracy: 0.9438 - val_loss: 0.9663 - val_accuracy: 0.6415\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2182 - accuracy: 0.9330 - val_loss: 0.9370 - val_accuracy: 0.6226\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2065 - accuracy: 0.9374 - val_loss: 0.9183 - val_accuracy: 0.5849\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2108 - accuracy: 0.9330 - val_loss: 0.9286 - val_accuracy: 0.6038\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2095 - accuracy: 0.9309 - val_loss: 0.9518 - val_accuracy: 0.6038\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2111 - accuracy: 0.9309 - val_loss: 1.0205 - val_accuracy: 0.6038\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2344 - accuracy: 0.9179 - val_loss: 0.9295 - val_accuracy: 0.6226\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1958 - accuracy: 0.9374 - val_loss: 1.0066 - val_accuracy: 0.6226\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1938 - accuracy: 0.9395 - val_loss: 0.9843 - val_accuracy: 0.6415\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1822 - accuracy: 0.9417 - val_loss: 1.0049 - val_accuracy: 0.6226\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1944 - accuracy: 0.9374 - val_loss: 0.9835 - val_accuracy: 0.6226\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1755 - accuracy: 0.9438 - val_loss: 0.9873 - val_accuracy: 0.5660\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1745 - accuracy: 0.9503 - val_loss: 1.0017 - val_accuracy: 0.5849\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1733 - accuracy: 0.9525 - val_loss: 1.0471 - val_accuracy: 0.5849\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1683 - accuracy: 0.9590 - val_loss: 1.0474 - val_accuracy: 0.5849\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1592 - accuracy: 0.9525 - val_loss: 1.0460 - val_accuracy: 0.5660\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1622 - accuracy: 0.9525 - val_loss: 1.0959 - val_accuracy: 0.5660\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1580 - accuracy: 0.9546 - val_loss: 1.0883 - val_accuracy: 0.5660\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.1571 - accuracy: 0.9546 - val_loss: 1.0656 - val_accuracy: 0.5660\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1536 - accuracy: 0.9460 - val_loss: 1.0905 - val_accuracy: 0.5472\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1587 - accuracy: 0.9568 - val_loss: 1.0774 - val_accuracy: 0.5849\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1533 - accuracy: 0.9525 - val_loss: 1.1013 - val_accuracy: 0.5660\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1430 - accuracy: 0.9590 - val_loss: 1.0987 - val_accuracy: 0.5660\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.1391 - accuracy: 0.9633 - val_loss: 1.1224 - val_accuracy: 0.5472\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1311 - accuracy: 0.9654 - val_loss: 1.1576 - val_accuracy: 0.5660\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.1356 - accuracy: 0.9546 - val_loss: 1.1904 - val_accuracy: 0.5660\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.1356 - accuracy: 0.9633 - val_loss: 1.1377 - val_accuracy: 0.5660\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 0.1327 - accuracy: 0.9568 - val_loss: 1.1477 - val_accuracy: 0.6226\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.1265 - accuracy: 0.9762 - val_loss: 1.1585 - val_accuracy: 0.5849\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.1200 - accuracy: 0.9784 - val_loss: 1.1664 - val_accuracy: 0.5472\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.1194 - accuracy: 0.9741 - val_loss: 1.2089 - val_accuracy: 0.5849\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1205 - accuracy: 0.9611 - val_loss: 1.2086 - val_accuracy: 0.5849\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1137 - accuracy: 0.9676 - val_loss: 1.2436 - val_accuracy: 0.5472\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.1096 - accuracy: 0.9762 - val_loss: 1.2286 - val_accuracy: 0.5660\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1116 - accuracy: 0.9741 - val_loss: 1.2137 - val_accuracy: 0.5849\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1051 - accuracy: 0.9698 - val_loss: 1.2485 - val_accuracy: 0.5472\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.1286 - accuracy: 0.9525 - val_loss: 1.2857 - val_accuracy: 0.5849\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.1162 - accuracy: 0.9590 - val_loss: 1.2576 - val_accuracy: 0.5849\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1200 - accuracy: 0.9741 - val_loss: 1.2515 - val_accuracy: 0.5849\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.1012 - accuracy: 0.9719 - val_loss: 1.3231 - val_accuracy: 0.5849\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.1005 - accuracy: 0.9741 - val_loss: 1.3039 - val_accuracy: 0.5660\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0996 - accuracy: 0.9633 - val_loss: 1.3095 - val_accuracy: 0.6038\n",
      "Epoch 144/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0973 - accuracy: 0.9741 - val_loss: 1.3070 - val_accuracy: 0.6038\n",
      "Epoch 145/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0896 - accuracy: 0.9806 - val_loss: 1.3201 - val_accuracy: 0.5849\n",
      "Epoch 146/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0858 - accuracy: 0.9849 - val_loss: 1.3337 - val_accuracy: 0.5660\n",
      "Epoch 147/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0905 - accuracy: 0.9784 - val_loss: 1.3376 - val_accuracy: 0.5660\n",
      "Epoch 148/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0847 - accuracy: 0.9849 - val_loss: 1.3571 - val_accuracy: 0.5660\n",
      "Epoch 149/500\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.0853 - accuracy: 0.9806 - val_loss: 1.3831 - val_accuracy: 0.5660\n",
      "Epoch 150/500\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 0.0748 - accuracy: 0.9892 - val_loss: 1.3910 - val_accuracy: 0.5660\n",
      "Epoch 151/500\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.0756 - accuracy: 0.9892 - val_loss: 1.3703 - val_accuracy: 0.5660\n",
      "Epoch 152/500\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.0760 - accuracy: 0.9827 - val_loss: 1.4906 - val_accuracy: 0.5849\n",
      "Epoch 153/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0832 - accuracy: 0.9849 - val_loss: 1.4464 - val_accuracy: 0.6038\n",
      "Epoch 154/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0732 - accuracy: 0.9827 - val_loss: 1.4380 - val_accuracy: 0.5849\n",
      "Epoch 155/500\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.0724 - accuracy: 0.9849 - val_loss: 1.4477 - val_accuracy: 0.5849\n",
      "Epoch 156/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0708 - accuracy: 0.9827 - val_loss: 1.4728 - val_accuracy: 0.6038\n",
      "Epoch 157/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0688 - accuracy: 0.9870 - val_loss: 1.4941 - val_accuracy: 0.5849\n",
      "Epoch 158/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0660 - accuracy: 0.9827 - val_loss: 1.4757 - val_accuracy: 0.5660\n",
      "Epoch 159/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0643 - accuracy: 0.9892 - val_loss: 1.4977 - val_accuracy: 0.6226\n",
      "Epoch 160/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0649 - accuracy: 0.9892 - val_loss: 1.5465 - val_accuracy: 0.6038\n",
      "Epoch 161/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0710 - accuracy: 0.9827 - val_loss: 1.5240 - val_accuracy: 0.6226\n",
      "Epoch 162/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0582 - accuracy: 0.9892 - val_loss: 1.5401 - val_accuracy: 0.6226\n",
      "Epoch 163/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0576 - accuracy: 0.9914 - val_loss: 1.5738 - val_accuracy: 0.6038\n",
      "Epoch 164/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0584 - accuracy: 0.9892 - val_loss: 1.5992 - val_accuracy: 0.6038\n",
      "Epoch 165/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0647 - accuracy: 0.9849 - val_loss: 1.5941 - val_accuracy: 0.6226\n",
      "Epoch 166/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0518 - accuracy: 0.9892 - val_loss: 1.5754 - val_accuracy: 0.6038\n",
      "Epoch 167/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0507 - accuracy: 0.9914 - val_loss: 1.5900 - val_accuracy: 0.5849\n",
      "Epoch 168/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0648 - accuracy: 0.9806 - val_loss: 1.5739 - val_accuracy: 0.6226\n",
      "Epoch 169/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0532 - accuracy: 0.9827 - val_loss: 1.5695 - val_accuracy: 0.5849\n",
      "Epoch 170/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0619 - accuracy: 0.9849 - val_loss: 1.6307 - val_accuracy: 0.6038\n",
      "Epoch 171/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0471 - accuracy: 0.9914 - val_loss: 1.6208 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0454 - accuracy: 0.9914 - val_loss: 1.6506 - val_accuracy: 0.6038\n",
      "Epoch 173/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0492 - accuracy: 0.9892 - val_loss: 1.6400 - val_accuracy: 0.6226\n",
      "Epoch 174/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0519 - accuracy: 0.9892 - val_loss: 1.6586 - val_accuracy: 0.6226\n",
      "Epoch 175/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0441 - accuracy: 0.9914 - val_loss: 1.6633 - val_accuracy: 0.6038\n",
      "Epoch 176/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0417 - accuracy: 0.9935 - val_loss: 1.6763 - val_accuracy: 0.6038\n",
      "Epoch 177/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0408 - accuracy: 0.9957 - val_loss: 1.6680 - val_accuracy: 0.5849\n",
      "Epoch 178/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0417 - accuracy: 0.9957 - val_loss: 1.6828 - val_accuracy: 0.5849\n",
      "Epoch 179/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0410 - accuracy: 0.9914 - val_loss: 1.7022 - val_accuracy: 0.5849\n",
      "Epoch 180/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0445 - accuracy: 0.9935 - val_loss: 1.7385 - val_accuracy: 0.6226\n",
      "Epoch 181/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0375 - accuracy: 0.9935 - val_loss: 1.7013 - val_accuracy: 0.6038\n",
      "Epoch 182/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0364 - accuracy: 0.9957 - val_loss: 1.7423 - val_accuracy: 0.6415\n",
      "Epoch 183/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0465 - accuracy: 0.9870 - val_loss: 1.7606 - val_accuracy: 0.6038\n",
      "Epoch 184/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0327 - accuracy: 0.9935 - val_loss: 1.7526 - val_accuracy: 0.6038\n",
      "Epoch 185/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0312 - accuracy: 0.9957 - val_loss: 1.7573 - val_accuracy: 0.5849\n",
      "Epoch 186/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0324 - accuracy: 0.9957 - val_loss: 1.7720 - val_accuracy: 0.6038\n",
      "Epoch 187/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0326 - accuracy: 0.9978 - val_loss: 1.7875 - val_accuracy: 0.6038\n",
      "Epoch 188/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0346 - accuracy: 0.9957 - val_loss: 1.8191 - val_accuracy: 0.6226\n",
      "Epoch 189/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0332 - accuracy: 0.9914 - val_loss: 1.8194 - val_accuracy: 0.6226\n",
      "Epoch 190/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0300 - accuracy: 0.9935 - val_loss: 1.7916 - val_accuracy: 0.6038\n",
      "Epoch 191/500\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0298 - accuracy: 0.9957 - val_loss: 1.8238 - val_accuracy: 0.6038\n",
      "Epoch 192/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0311 - accuracy: 0.9935 - val_loss: 1.8330 - val_accuracy: 0.6226\n",
      "Epoch 193/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0397 - accuracy: 0.9914 - val_loss: 1.9257 - val_accuracy: 0.6226\n",
      "Epoch 194/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0427 - accuracy: 0.9870 - val_loss: 1.8263 - val_accuracy: 0.6226\n",
      "Epoch 195/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0285 - accuracy: 0.9957 - val_loss: 1.9532 - val_accuracy: 0.6226\n",
      "Epoch 196/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 1.8710 - val_accuracy: 0.5849\n",
      "Epoch 197/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0268 - accuracy: 0.9957 - val_loss: 1.8713 - val_accuracy: 0.6038\n",
      "Epoch 198/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0237 - accuracy: 0.9978 - val_loss: 1.8589 - val_accuracy: 0.6226\n",
      "Epoch 199/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.8943 - val_accuracy: 0.6038\n",
      "Epoch 200/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0214 - accuracy: 0.9978 - val_loss: 1.8645 - val_accuracy: 0.6226\n",
      "Epoch 201/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0234 - accuracy: 0.9957 - val_loss: 1.8990 - val_accuracy: 0.6038\n",
      "Epoch 202/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.9207 - val_accuracy: 0.6038\n",
      "Epoch 203/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0205 - accuracy: 0.9978 - val_loss: 1.9115 - val_accuracy: 0.6038\n",
      "Epoch 204/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0206 - accuracy: 0.9957 - val_loss: 1.9251 - val_accuracy: 0.5849\n",
      "Epoch 205/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0240 - accuracy: 0.9957 - val_loss: 1.9177 - val_accuracy: 0.6415\n",
      "Epoch 206/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0285 - accuracy: 0.9978 - val_loss: 1.9272 - val_accuracy: 0.5849\n",
      "Epoch 207/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0319 - accuracy: 0.9935 - val_loss: 1.9829 - val_accuracy: 0.6038\n",
      "Epoch 208/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0392 - accuracy: 0.9957 - val_loss: 1.9334 - val_accuracy: 0.6226\n",
      "Epoch 209/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 1.9345 - val_accuracy: 0.6415\n",
      "Epoch 210/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0171 - accuracy: 0.9978 - val_loss: 1.9575 - val_accuracy: 0.6038\n",
      "Epoch 211/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.9546 - val_accuracy: 0.5849\n",
      "Epoch 212/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.9654 - val_accuracy: 0.6415\n",
      "Epoch 213/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.9742 - val_accuracy: 0.6415\n",
      "Epoch 214/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.0048 - val_accuracy: 0.6038\n",
      "Epoch 215/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.0061 - val_accuracy: 0.6038\n",
      "Epoch 216/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.0037 - val_accuracy: 0.6415\n",
      "Epoch 217/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.0324 - val_accuracy: 0.6038\n",
      "Epoch 218/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.0339 - val_accuracy: 0.5849\n",
      "Epoch 219/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.0599 - val_accuracy: 0.6226\n",
      "Epoch 220/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.0332 - val_accuracy: 0.6604\n",
      "Epoch 221/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.0859 - val_accuracy: 0.5849\n",
      "Epoch 222/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.0715 - val_accuracy: 0.6415\n",
      "Epoch 223/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 2.0637 - val_accuracy: 0.6415\n",
      "Epoch 224/500\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.0989 - val_accuracy: 0.6038\n",
      "Epoch 225/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 2.1030 - val_accuracy: 0.6226\n",
      "Epoch 226/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.1334 - val_accuracy: 0.6038\n",
      "Epoch 227/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.1182 - val_accuracy: 0.6226\n",
      "Epoch 228/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.1418 - val_accuracy: 0.6604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.1537 - val_accuracy: 0.6415\n",
      "Epoch 230/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.1787 - val_accuracy: 0.5849\n",
      "Epoch 231/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.1465 - val_accuracy: 0.6226\n",
      "Epoch 232/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.1614 - val_accuracy: 0.6226\n",
      "Epoch 233/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.1706 - val_accuracy: 0.6604\n",
      "Epoch 234/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.1852 - val_accuracy: 0.6226\n",
      "Epoch 235/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.1762 - val_accuracy: 0.6226\n",
      "Epoch 236/500\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.2084 - val_accuracy: 0.6038\n",
      "Epoch 237/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.2021 - val_accuracy: 0.6226\n",
      "Epoch 238/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.2194 - val_accuracy: 0.6604\n",
      "Epoch 239/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.2400 - val_accuracy: 0.6226\n",
      "Epoch 240/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.2264 - val_accuracy: 0.6604\n",
      "Epoch 241/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.2427 - val_accuracy: 0.6604\n",
      "Epoch 242/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.2556 - val_accuracy: 0.6226\n",
      "Epoch 243/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0147 - accuracy: 0.9978 - val_loss: 2.2378 - val_accuracy: 0.6415\n",
      "Epoch 244/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0141 - accuracy: 0.9978 - val_loss: 2.2782 - val_accuracy: 0.6415\n",
      "Epoch 245/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.3199 - val_accuracy: 0.5849\n",
      "Epoch 246/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.3084 - val_accuracy: 0.6038\n",
      "Epoch 247/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.2525 - val_accuracy: 0.6226\n",
      "Epoch 248/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.3138 - val_accuracy: 0.6226\n",
      "Epoch 249/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.3111 - val_accuracy: 0.6226\n",
      "Epoch 250/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.3284 - val_accuracy: 0.6226\n",
      "Epoch 251/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.3059 - val_accuracy: 0.6604\n",
      "Epoch 252/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.3305 - val_accuracy: 0.6604\n",
      "Epoch 253/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.3329 - val_accuracy: 0.6415\n",
      "Epoch 254/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.3583 - val_accuracy: 0.6415\n",
      "Epoch 255/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.3441 - val_accuracy: 0.6415\n",
      "Epoch 256/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.3570 - val_accuracy: 0.6604\n",
      "Epoch 257/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.3911 - val_accuracy: 0.6038\n",
      "Epoch 258/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.3757 - val_accuracy: 0.6415\n",
      "Epoch 259/500\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.3738 - val_accuracy: 0.6226\n",
      "Epoch 260/500\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.3803 - val_accuracy: 0.6604\n",
      "Epoch 261/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.3895 - val_accuracy: 0.6415\n",
      "Epoch 262/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.4236 - val_accuracy: 0.6226\n",
      "Epoch 263/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.4077 - val_accuracy: 0.6415\n",
      "Epoch 264/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.4127 - val_accuracy: 0.6226\n",
      "Epoch 265/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.4216 - val_accuracy: 0.6226\n",
      "Epoch 266/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.4148 - val_accuracy: 0.6604\n",
      "Epoch 267/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.4425 - val_accuracy: 0.6226\n",
      "Epoch 268/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.4466 - val_accuracy: 0.6226\n",
      "Epoch 269/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.4518 - val_accuracy: 0.6415\n",
      "Epoch 270/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.4612 - val_accuracy: 0.6415\n",
      "Epoch 271/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.4772 - val_accuracy: 0.6415\n",
      "Epoch 272/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.4661 - val_accuracy: 0.6226\n",
      "Epoch 273/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.4769 - val_accuracy: 0.6226\n",
      "Epoch 274/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.4886 - val_accuracy: 0.6415\n",
      "Epoch 275/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.4917 - val_accuracy: 0.6415\n",
      "Epoch 276/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.5030 - val_accuracy: 0.6604\n",
      "Epoch 277/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.5154 - val_accuracy: 0.6226\n",
      "Epoch 278/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.5177 - val_accuracy: 0.6415\n",
      "Epoch 279/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.5275 - val_accuracy: 0.6415\n",
      "Epoch 280/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.5351 - val_accuracy: 0.6226\n",
      "Epoch 281/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.5335 - val_accuracy: 0.6415\n",
      "Epoch 282/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.5233 - val_accuracy: 0.6415\n",
      "Epoch 283/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.5335 - val_accuracy: 0.6415\n",
      "Epoch 284/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.5524 - val_accuracy: 0.6415\n",
      "Epoch 285/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.5544 - val_accuracy: 0.6415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.5764 - val_accuracy: 0.6226\n",
      "Epoch 287/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.5743 - val_accuracy: 0.6415\n",
      "Epoch 288/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.5817 - val_accuracy: 0.6415\n",
      "Epoch 289/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.5719 - val_accuracy: 0.6415\n",
      "Epoch 290/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.5923 - val_accuracy: 0.6226\n",
      "Epoch 291/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.5979 - val_accuracy: 0.6226\n",
      "Epoch 292/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.6065 - val_accuracy: 0.6415\n",
      "Epoch 293/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.6141 - val_accuracy: 0.6226\n",
      "Epoch 294/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.6143 - val_accuracy: 0.6226\n",
      "Epoch 295/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6244 - val_accuracy: 0.6415\n",
      "Epoch 296/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6304 - val_accuracy: 0.6226\n",
      "Epoch 297/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6349 - val_accuracy: 0.6226\n",
      "Epoch 298/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6329 - val_accuracy: 0.6415\n",
      "Epoch 299/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6614 - val_accuracy: 0.6226\n",
      "Epoch 300/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.6399 - val_accuracy: 0.6226\n",
      "Epoch 301/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.6474 - val_accuracy: 0.6226\n",
      "Epoch 302/500\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6761 - val_accuracy: 0.6415\n",
      "Epoch 303/500\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.6850 - val_accuracy: 0.6415\n",
      "Epoch 304/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.6888 - val_accuracy: 0.6415\n",
      "Epoch 305/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.7079 - val_accuracy: 0.6226\n",
      "Epoch 306/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7149 - val_accuracy: 0.6415\n",
      "Epoch 307/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7130 - val_accuracy: 0.6226\n",
      "Epoch 308/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.7137 - val_accuracy: 0.6226\n",
      "Epoch 309/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7143 - val_accuracy: 0.6415\n",
      "Epoch 310/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.7246 - val_accuracy: 0.6415\n",
      "Epoch 311/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.7374 - val_accuracy: 0.6415\n",
      "Epoch 312/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.7365 - val_accuracy: 0.6415\n",
      "Epoch 313/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.7478 - val_accuracy: 0.6415\n",
      "Epoch 314/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.7549 - val_accuracy: 0.6415\n",
      "Epoch 315/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.7622 - val_accuracy: 0.6415\n",
      "Epoch 316/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.7483 - val_accuracy: 0.6415\n",
      "Epoch 317/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.7618 - val_accuracy: 0.6415\n",
      "Epoch 318/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.7714 - val_accuracy: 0.6415\n",
      "Epoch 319/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.7825 - val_accuracy: 0.6415\n",
      "Epoch 320/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.7977 - val_accuracy: 0.6226\n",
      "Epoch 321/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.7789 - val_accuracy: 0.6415\n",
      "Epoch 322/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8082 - val_accuracy: 0.6415\n",
      "Epoch 323/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8031 - val_accuracy: 0.6415\n",
      "Epoch 324/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8026 - val_accuracy: 0.6415\n",
      "Epoch 325/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.8179 - val_accuracy: 0.6415\n",
      "Epoch 326/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8343 - val_accuracy: 0.6226\n",
      "Epoch 327/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8169 - val_accuracy: 0.6415\n",
      "Epoch 328/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.8306 - val_accuracy: 0.6226\n",
      "Epoch 329/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.8374 - val_accuracy: 0.6415\n",
      "Epoch 330/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.8454 - val_accuracy: 0.6415\n",
      "Epoch 331/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.8465 - val_accuracy: 0.6415\n",
      "Epoch 332/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.8528 - val_accuracy: 0.6415\n",
      "Epoch 333/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.8577 - val_accuracy: 0.6415\n",
      "Epoch 334/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8557 - val_accuracy: 0.6415\n",
      "Epoch 335/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.8645 - val_accuracy: 0.6415\n",
      "Epoch 336/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.8812 - val_accuracy: 0.6415\n",
      "Epoch 337/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.8810 - val_accuracy: 0.6226\n",
      "Epoch 338/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.8745 - val_accuracy: 0.6415\n",
      "Epoch 339/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.8881 - val_accuracy: 0.6415\n",
      "Epoch 340/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9071 - val_accuracy: 0.6415\n",
      "Epoch 341/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9105 - val_accuracy: 0.6415\n",
      "Epoch 342/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.9109 - val_accuracy: 0.6415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9147 - val_accuracy: 0.6415\n",
      "Epoch 344/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9162 - val_accuracy: 0.6415\n",
      "Epoch 345/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9436 - val_accuracy: 0.6415\n",
      "Epoch 346/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9401 - val_accuracy: 0.6415\n",
      "Epoch 347/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.9399 - val_accuracy: 0.6226\n",
      "Epoch 348/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.9497 - val_accuracy: 0.6415\n",
      "Epoch 349/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9495 - val_accuracy: 0.6415\n",
      "Epoch 350/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9573 - val_accuracy: 0.6415\n",
      "Epoch 351/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9648 - val_accuracy: 0.6415\n",
      "Epoch 352/500\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9614 - val_accuracy: 0.6415\n",
      "Epoch 353/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9766 - val_accuracy: 0.6226\n",
      "Epoch 354/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9822 - val_accuracy: 0.6415\n",
      "Epoch 355/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9735 - val_accuracy: 0.6415\n",
      "Epoch 356/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.9864 - val_accuracy: 0.6415\n",
      "Epoch 357/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0045 - val_accuracy: 0.6415\n",
      "Epoch 358/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9930 - val_accuracy: 0.6415\n",
      "Epoch 359/500\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0023 - val_accuracy: 0.6415\n",
      "Epoch 360/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 9.8395e-04 - accuracy: 1.0000 - val_loss: 3.0072 - val_accuracy: 0.6415\n",
      "Epoch 361/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 9.8291e-04 - accuracy: 1.0000 - val_loss: 3.0109 - val_accuracy: 0.6415\n",
      "Epoch 362/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 9.8044e-04 - accuracy: 1.0000 - val_loss: 3.0161 - val_accuracy: 0.6415\n",
      "Epoch 363/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 9.6416e-04 - accuracy: 1.0000 - val_loss: 3.0269 - val_accuracy: 0.6415\n",
      "Epoch 364/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 9.3752e-04 - accuracy: 1.0000 - val_loss: 3.0310 - val_accuracy: 0.6415\n",
      "Epoch 365/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 9.7060e-04 - accuracy: 1.0000 - val_loss: 3.0318 - val_accuracy: 0.6415\n",
      "Epoch 366/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 9.9741e-04 - accuracy: 1.0000 - val_loss: 3.0217 - val_accuracy: 0.6226\n",
      "Epoch 367/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 8.8610e-04 - accuracy: 1.0000 - val_loss: 3.0390 - val_accuracy: 0.6415\n",
      "Epoch 368/500\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0424 - val_accuracy: 0.6226\n",
      "Epoch 369/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0540 - val_accuracy: 0.6226\n",
      "Epoch 370/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 9.2940e-04 - accuracy: 1.0000 - val_loss: 3.0644 - val_accuracy: 0.6415\n",
      "Epoch 371/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 9.0149e-04 - accuracy: 1.0000 - val_loss: 3.0560 - val_accuracy: 0.6415\n",
      "Epoch 372/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 9.0254e-04 - accuracy: 1.0000 - val_loss: 3.0746 - val_accuracy: 0.6226\n",
      "Epoch 373/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 8.6240e-04 - accuracy: 1.0000 - val_loss: 3.0708 - val_accuracy: 0.6415\n",
      "Epoch 374/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 8.0320e-04 - accuracy: 1.0000 - val_loss: 3.0839 - val_accuracy: 0.6226\n",
      "Epoch 375/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 8.1659e-04 - accuracy: 1.0000 - val_loss: 3.0843 - val_accuracy: 0.6415\n",
      "Epoch 376/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 8.1164e-04 - accuracy: 1.0000 - val_loss: 3.0995 - val_accuracy: 0.6226\n",
      "Epoch 377/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 7.7447e-04 - accuracy: 1.0000 - val_loss: 3.0981 - val_accuracy: 0.6415\n",
      "Epoch 378/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 7.8297e-04 - accuracy: 1.0000 - val_loss: 3.0999 - val_accuracy: 0.6415\n",
      "Epoch 379/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 8.2051e-04 - accuracy: 1.0000 - val_loss: 3.1111 - val_accuracy: 0.6226\n",
      "Epoch 380/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 8.1151e-04 - accuracy: 1.0000 - val_loss: 3.1064 - val_accuracy: 0.6226\n",
      "Epoch 381/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 8.1976e-04 - accuracy: 1.0000 - val_loss: 3.1048 - val_accuracy: 0.6415\n",
      "Epoch 382/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 7.3178e-04 - accuracy: 1.0000 - val_loss: 3.1286 - val_accuracy: 0.6415\n",
      "Epoch 383/500\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 7.3181e-04 - accuracy: 1.0000 - val_loss: 3.1261 - val_accuracy: 0.6415\n",
      "Epoch 384/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 7.2395e-04 - accuracy: 1.0000 - val_loss: 3.1307 - val_accuracy: 0.6415\n",
      "Epoch 385/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 7.2183e-04 - accuracy: 1.0000 - val_loss: 3.1394 - val_accuracy: 0.6226\n",
      "Epoch 386/500\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 7.1187e-04 - accuracy: 1.0000 - val_loss: 3.1405 - val_accuracy: 0.6226\n",
      "Epoch 387/500\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 7.6705e-04 - accuracy: 1.0000 - val_loss: 3.1469 - val_accuracy: 0.6415\n",
      "Epoch 388/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 6.9048e-04 - accuracy: 1.0000 - val_loss: 3.1543 - val_accuracy: 0.6226\n",
      "Epoch 389/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 6.9179e-04 - accuracy: 1.0000 - val_loss: 3.1521 - val_accuracy: 0.6226\n",
      "Epoch 390/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 6.6013e-04 - accuracy: 1.0000 - val_loss: 3.1613 - val_accuracy: 0.6415\n",
      "Epoch 391/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 6.9761e-04 - accuracy: 1.0000 - val_loss: 3.1747 - val_accuracy: 0.6226\n",
      "Epoch 392/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 7.1951e-04 - accuracy: 1.0000 - val_loss: 3.1799 - val_accuracy: 0.6415\n",
      "Epoch 393/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 6.8377e-04 - accuracy: 1.0000 - val_loss: 3.1778 - val_accuracy: 0.6415\n",
      "Epoch 394/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 6.4553e-04 - accuracy: 1.0000 - val_loss: 3.1812 - val_accuracy: 0.6415\n",
      "Epoch 395/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 6.3229e-04 - accuracy: 1.0000 - val_loss: 3.1951 - val_accuracy: 0.6415\n",
      "Epoch 396/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 6.1490e-04 - accuracy: 1.0000 - val_loss: 3.1908 - val_accuracy: 0.6415\n",
      "Epoch 397/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 6.1931e-04 - accuracy: 1.0000 - val_loss: 3.2037 - val_accuracy: 0.6415\n",
      "Epoch 398/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 6.3557e-04 - accuracy: 1.0000 - val_loss: 3.1941 - val_accuracy: 0.6415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 5.9335e-04 - accuracy: 1.0000 - val_loss: 3.2077 - val_accuracy: 0.6226\n",
      "Epoch 400/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 5.9142e-04 - accuracy: 1.0000 - val_loss: 3.2113 - val_accuracy: 0.6415\n",
      "Epoch 401/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 5.9199e-04 - accuracy: 1.0000 - val_loss: 3.2160 - val_accuracy: 0.6226\n",
      "Epoch 402/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 5.7087e-04 - accuracy: 1.0000 - val_loss: 3.2172 - val_accuracy: 0.6415\n",
      "Epoch 403/500\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 5.8957e-04 - accuracy: 1.0000 - val_loss: 3.2176 - val_accuracy: 0.6415\n",
      "Epoch 404/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 5.6549e-04 - accuracy: 1.0000 - val_loss: 3.2330 - val_accuracy: 0.6226\n",
      "Epoch 405/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 5.7819e-04 - accuracy: 1.0000 - val_loss: 3.2328 - val_accuracy: 0.6415\n",
      "Epoch 406/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 5.5213e-04 - accuracy: 1.0000 - val_loss: 3.2363 - val_accuracy: 0.6226\n",
      "Epoch 407/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 5.3746e-04 - accuracy: 1.0000 - val_loss: 3.2426 - val_accuracy: 0.6415\n",
      "Epoch 408/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 5.4484e-04 - accuracy: 1.0000 - val_loss: 3.2447 - val_accuracy: 0.6415\n",
      "Epoch 409/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 5.3601e-04 - accuracy: 1.0000 - val_loss: 3.2547 - val_accuracy: 0.6226\n",
      "Epoch 410/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 5.3421e-04 - accuracy: 1.0000 - val_loss: 3.2563 - val_accuracy: 0.6415\n",
      "Epoch 411/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 5.3648e-04 - accuracy: 1.0000 - val_loss: 3.2692 - val_accuracy: 0.6226\n",
      "Epoch 412/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 5.1313e-04 - accuracy: 1.0000 - val_loss: 3.2622 - val_accuracy: 0.6415\n",
      "Epoch 413/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 5.1090e-04 - accuracy: 1.0000 - val_loss: 3.2756 - val_accuracy: 0.6415\n",
      "Epoch 414/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 4.9997e-04 - accuracy: 1.0000 - val_loss: 3.2719 - val_accuracy: 0.6226\n",
      "Epoch 415/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 4.9918e-04 - accuracy: 1.0000 - val_loss: 3.2839 - val_accuracy: 0.6226\n",
      "Epoch 416/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 4.8929e-04 - accuracy: 1.0000 - val_loss: 3.2809 - val_accuracy: 0.6415\n",
      "Epoch 417/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 5.1079e-04 - accuracy: 1.0000 - val_loss: 3.2968 - val_accuracy: 0.6226\n",
      "Epoch 418/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 6.6534e-04 - accuracy: 1.0000 - val_loss: 3.2741 - val_accuracy: 0.6226\n",
      "Epoch 419/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 5.1493e-04 - accuracy: 1.0000 - val_loss: 3.2898 - val_accuracy: 0.6415\n",
      "Epoch 420/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 4.7001e-04 - accuracy: 1.0000 - val_loss: 3.3009 - val_accuracy: 0.6226\n",
      "Epoch 421/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 4.8535e-04 - accuracy: 1.0000 - val_loss: 3.3070 - val_accuracy: 0.6415\n",
      "Epoch 422/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 4.5913e-04 - accuracy: 1.0000 - val_loss: 3.3037 - val_accuracy: 0.6415\n",
      "Epoch 423/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 4.4484e-04 - accuracy: 1.0000 - val_loss: 3.3105 - val_accuracy: 0.6226\n",
      "Epoch 424/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 4.6977e-04 - accuracy: 1.0000 - val_loss: 3.3142 - val_accuracy: 0.6415\n",
      "Epoch 425/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 4.3904e-04 - accuracy: 1.0000 - val_loss: 3.3221 - val_accuracy: 0.6226\n",
      "Epoch 426/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 4.3696e-04 - accuracy: 1.0000 - val_loss: 3.3312 - val_accuracy: 0.6415\n",
      "Epoch 427/500\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 4.2997e-04 - accuracy: 1.0000 - val_loss: 3.3275 - val_accuracy: 0.6226\n",
      "Epoch 428/500\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 4.6969e-04 - accuracy: 1.0000 - val_loss: 3.3410 - val_accuracy: 0.6415\n",
      "Epoch 429/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 4.1937e-04 - accuracy: 1.0000 - val_loss: 3.3445 - val_accuracy: 0.6415\n",
      "Epoch 430/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 4.1538e-04 - accuracy: 1.0000 - val_loss: 3.3462 - val_accuracy: 0.6226\n",
      "Epoch 431/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 4.1445e-04 - accuracy: 1.0000 - val_loss: 3.3524 - val_accuracy: 0.6415\n",
      "Epoch 432/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 4.4574e-04 - accuracy: 1.0000 - val_loss: 3.3583 - val_accuracy: 0.6226\n",
      "Epoch 433/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 3.9993e-04 - accuracy: 1.0000 - val_loss: 3.3543 - val_accuracy: 0.6415\n",
      "Epoch 434/500\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 3.8665e-04 - accuracy: 1.0000 - val_loss: 3.3736 - val_accuracy: 0.6226\n",
      "Epoch 435/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 4.1017e-04 - accuracy: 1.0000 - val_loss: 3.3683 - val_accuracy: 0.6415\n",
      "Epoch 436/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 3.9063e-04 - accuracy: 1.0000 - val_loss: 3.3792 - val_accuracy: 0.6226\n",
      "Epoch 437/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 4.0865e-04 - accuracy: 1.0000 - val_loss: 3.3781 - val_accuracy: 0.6415\n",
      "Epoch 438/500\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 3.9428e-04 - accuracy: 1.0000 - val_loss: 3.3742 - val_accuracy: 0.6226\n",
      "Epoch 439/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 3.7486e-04 - accuracy: 1.0000 - val_loss: 3.3872 - val_accuracy: 0.6226\n",
      "Epoch 440/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 3.7843e-04 - accuracy: 1.0000 - val_loss: 3.3945 - val_accuracy: 0.6415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f893853bd60>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_112.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_112.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd7ba5a",
   "metadata": {},
   "source": [
    "**For test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9447f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6041 - accuracy: 0.7458\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6203 - accuracy: 0.7170\n"
     ]
    }
   ],
   "source": [
    "m1_eval_test = model_112.evaluate(X_test, y_test)\n",
    "m1_eval_val = model_112.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc6a1674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step\n",
      "roc auc score:  0.736842105263158\n",
      "average precision score:  0.7303067765821403\n"
     ]
    }
   ],
   "source": [
    "pred = model_112.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7669ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3d0d317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8747175 , 0.12528254],\n",
       "       [0.8180357 , 0.18196426],\n",
       "       [0.7914583 , 0.20854168],\n",
       "       [0.38320255, 0.61679745],\n",
       "       [0.6376152 , 0.36238477],\n",
       "       [0.36459407, 0.6354059 ],\n",
       "       [0.596154  , 0.40384603],\n",
       "       [0.8739808 , 0.12601914],\n",
       "       [0.4501728 , 0.5498272 ],\n",
       "       [0.89649385, 0.10350617],\n",
       "       [0.8158654 , 0.18413465],\n",
       "       [0.8779641 , 0.12203592],\n",
       "       [0.6723586 , 0.32764137],\n",
       "       [0.7823606 , 0.21763942],\n",
       "       [0.69707394, 0.30292606],\n",
       "       [0.8950943 , 0.10490567],\n",
       "       [0.834851  , 0.16514897],\n",
       "       [0.8385638 , 0.16143626],\n",
       "       [0.50402296, 0.4959771 ],\n",
       "       [0.85551715, 0.14448285],\n",
       "       [0.92478365, 0.07521634],\n",
       "       [0.6203529 , 0.3796471 ],\n",
       "       [0.38867217, 0.6113278 ],\n",
       "       [0.93074137, 0.06925862],\n",
       "       [0.82283235, 0.1771676 ],\n",
       "       [0.8066713 , 0.19332868],\n",
       "       [0.81851715, 0.18148287],\n",
       "       [0.7501101 , 0.2498899 ],\n",
       "       [0.8147028 , 0.18529713],\n",
       "       [0.40159294, 0.5984071 ],\n",
       "       [0.8900772 , 0.1099228 ],\n",
       "       [0.87062985, 0.12937015],\n",
       "       [0.67074263, 0.32925734],\n",
       "       [0.60329854, 0.39670148],\n",
       "       [0.9377063 , 0.06229367],\n",
       "       [0.30046254, 0.6995375 ],\n",
       "       [0.82633084, 0.17366916],\n",
       "       [0.80361843, 0.19638157],\n",
       "       [0.83432585, 0.16567421],\n",
       "       [0.8380585 , 0.16194157],\n",
       "       [0.78458554, 0.2154145 ],\n",
       "       [0.4948335 , 0.5051665 ],\n",
       "       [0.6554162 , 0.34458384],\n",
       "       [0.52397984, 0.4760201 ],\n",
       "       [0.8565959 , 0.14340414],\n",
       "       [0.2565804 , 0.74341965],\n",
       "       [0.77484095, 0.22515899],\n",
       "       [0.7550856 , 0.24491446],\n",
       "       [0.83632374, 0.16367623],\n",
       "       [0.9838955 , 0.01610456],\n",
       "       [0.94093704, 0.05906298],\n",
       "       [0.74629736, 0.25370258],\n",
       "       [0.33090872, 0.6690913 ],\n",
       "       [0.9120593 , 0.08794073],\n",
       "       [0.8161951 , 0.18380491],\n",
       "       [0.7594552 , 0.24054484],\n",
       "       [0.8606578 , 0.13934222],\n",
       "       [0.04982071, 0.9501792 ],\n",
       "       [0.99251807, 0.00748196]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df3329ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6041 - accuracy: 0.7458\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_112.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee635a0d",
   "metadata": {},
   "source": [
    "**For validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e416dd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step\n",
      "roc auc score:  0.6857142857142857\n",
      "average precision score:  0.649773989842593\n"
     ]
    }
   ],
   "source": [
    "pred = model_112.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df061ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bda341d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6203 - accuracy: 0.7170\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAFACAYAAACRGuaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAue0lEQVR4nO3dd5xcVf3/8dd7k0AoCRAIGASCdCNKUFCKdL4IiCBFgS8gTSM2WlAEUUHwK6IgTSAgXQjgjyIgahAJoQmht4AoBEFCLykESMLn98c5m0yGLTO7c2fvZt/PfdzHzm3nnJm585kz5557riICMzMrn5aeLoCZmbXNAdrMrKQcoM3MSsoB2syspBygzcxKygHazKykShegJR0r6fc9XY4iSNpZ0vOSpktatxvpPC5p88aVrPkkbSLpqYLzmC5plQ7WT5a0dY1p7Sfpjhq37fIx3M19fyHp0K7sW5XORZJOyI87fJ8qt+1iXh2+Rz1N0o6Sruip/LscoCV9XtJdkt6W9IakOyWt38jC9QRJwySdL2mKpGmSnpR0nKTFGpD8r4HvRsTiEfFgVxOJiE9ExPgGlGc+ksZLCknrVC2/Li/fvMZ0QtJqHW0TEbdHxJpdL23n8uv8TC5TtwJJ2UkaCnwNGNPIdBv5PuXj6+tV6c99j3qapJXzsdu/dVlEXA+sLelTPVGmLgVoSYOBG4EzgCHAR4HjgPcaV7Tuk9Svzu2HAHcDiwAbRsQg4H+AJYFVG1Ck4cDjDUinSP8kfdABkLQ0sAHwaqMyqPwAWMPsB9wUETN7uiALoLHAqJ7IuKs16DUAImJsRMyJiJkRMS4iHmndQNIBkiZJelPSXyUNr1h3Wv6pP1XS/ZI2qUp/oKQrcw32gcoanaSP52/it/JP/R0r1l0k6WxJN0maAWyRf8YeIemRXNu/UtLAdp7X4cA0YO+ImJyf4/MRcUjrc5O0kaSJOa2JkjaqyH+8pOPzr4lpksZJWkbSwpKmA/2AhyX9O28/X02z6qflMpJuzM/zDUm3S2rJ6+b+NM9pnyrpxTydKmnhvG5zSS9IGi3plfyrYP9O3tvLgN0rvtz2BK4F3q8o52cl3Z3LNkXSmZIWyusm5M0ezj9fd68ox5GSXgIubF2W91k1P8dP5/nlJb3WVo1d0v6SbqiY/5ekqyrmn5c0svL1lTQK2Av4QS7TDRVJjqzx2KguR3eO4eUlXS3pVUnPSjq4nTwGSvq9pNfzaz1R0nLtFGk74LaKfSdJ2qFivn9+TVtf4z9Ieik/7wmSPtFOGea+T3l+3fx8pkm6EhhYsW6pfMy+qvS5v1HSCnndz4FNgDPze3BmXj73MyBpCUmX5P2fk3RMxTG/n6Q7JP06p/2spO3aeS3Ix9p/czmfkrRVXt4i6YeS/p1f16uUKmYArcfuW7mMG+b58cAX28urUBFR9wQMBl4HLiYdGEtVrf8y8C/g40B/4Bjgror1ewNL53WjgZeAgXndscAsYDdgAHAE8Gx+PCCnezSwELAlKaCumfe9CHgb2Jj05TMQmAzcCyxPqu1PAg5q53n9Aziug+c9BHgT2CeXfc88v3RePx74N+kLbJE8f2LF/gGs1sH8RcAJ+fEvgHMqnvcmgPK6ycDW+fHPcrmXBYYCdwHH53WbA7PzNgOA7YF3qt+vivzHA18HxgHb5WX3AhsCLwCb52WfIdWq+wMr59f00A6eV2s5fgksnF+bzYEXKrb5Rk5nUeCvwK/bKeMqwFv5/R0GPAf8t2Ldm0BLdTkqX9uKtOo5NvYD7mjAMdwC3A/8hHQMrwI8A3yhYt/f58ffBG7Ir0m//LoPbqd8rwLrV8z/BLisYv6LwJMV8wcAg/L7cSrwUDvH4dz3KZf3OeCw/Fx2y8+zddulgV1zeQcBfwCuqz6+qspd+R5dAvwx77sy6dfcgRWv/6x8nPQDvgW8SP5MVKW5JvA8sHyeXxlYNT8+lPR5WSE/9zHA2IrtAujfxuc+2nvti5y6vmMKvheRPrizgeuB5fK6P7e+sHm+hRQYhreT1pvAOhUH6D+q9p1CClCbkD4ILRXrxwLHVhxYl7TxIdy7Yv4k4Jx2yvE07XxA8/p9gHurlt0N7FdxAB5Tse7bwF/aOhjbmb+o4mD/WT5YV2ujHJOZF6D/DWxfse4LwOSKD9fMygMOeAXYoJ3nN54UoPfOr+uawD/zurkBuo39DgWu7eB5bU6qgQ+sWvZCVTrXA48CjwALd/A+PA98GtgDOJcUZNcC9geub6sctB+gaz029qMiQHfjGP4c8J+qfY8CLqzYtzVAH0D6wv1UDZ/HWcBaFfOrkSovi+b5y4CftLPvkvm1WqKN43Du+wRsSlVQzOU7oZ10RwJvVh9fVdtELms/UhPpiIp13wTGV7z+/6pYt2je9yNt5Lsa6TjfGhhQtW4SsFXF/LD82rVWNtoK0APy8pU6ex8aPXX5JGFETIqI/SJiBWBtUi3k1Lx6OHBa/ln2FvAGIFJbNfkn96T88+otYAlgmYrkn6/I5wNScFg+T8/nZa2ea023et8KL1U8fgdYvJ2n9TrpDWvP8jm/StX515pXZ35F+rUwTtIzkn5YY5mey8tavR4Rs+ss0zWkXyffAy6tXilpjfzz9SVJU4H/Y/73ry2vRsS7nWxzHulYOiMiOjqfcRspcGyaH48HNsvTbe3u1bYuvV/dOIaHA8u3fjbyvkcDbTVdXEr6NXGFUvPVSZIGtFOkN0k1z9Y8/0UKRl+StCiwI3B5Lns/SSfmn/lTSV9U0Pl7uDzp10pULJt77ElaVNKY3DwxldRksKRqOxe0DPNq6JVpt/nZioh38sMPvV/5uR9K+rJ7RdIVklo/E8OBayte+0nAHNp+/Vu1vq5v1fA8Gqoh3ewi4knSt+7aedHzwDcjYsmKaZGIuCu31R0JfJX0U3tJUrOEKpJcsfVBboNagfTN/SKwYmu7VLYS8N/K4nTjqfwN2Lkq/Uovkt7gStX51+MdUk2g1UdaH0TEtIgYHRGrAF8CDm9tR+ukTCvlZV2WD/4/k35GfihAA2cDTwKrR8RgUoBRG9vNl2xHKyUtTvqCPx84tqJdsC2tAXqT/Pg2Og/Q3TkuqsvanWP4eeDZqs/GoIjY/kMFjpgVEcdFxAhgI2AHKk7gVnmEfG6owlhSM9xOwBM5cAH8b162NemLZeXWonby1KcAH5VUud1KFY9Hk351fS4fF5tWpdvRe/AaqSZbfSx36bMVEZdHxOdzekFqXoP0+m9X9foPjIj/dlC+j5N+lU7tSlm6o6u9ONbKNYjWEwArkg6Ef+RNzgGOaj3xkBv/v5LXDSI1ibwK9Jf0E1KbdqXPSNpF6Wz/oaSfPv8A7gFmkE72DFA6ifQloFH9FE/JZblY+aSmpI9KOkWpm81NwBqS/jefdNkdGEHq0dIVDwH/m2s025ICDDnfHZROcAmYSvqWn9NGGmOBYyQNlbQMqe2xEf3IjwY2i3yytMqgXKbpktYiBfJKL5PaVutxGnB/RHwd+BPpGGrPbcAWwCIR8QJwO7AtqQ30wXb26UqZ2tOdY/heYGo+ibVIfu/XVhtdVCVtIemTuQY6lRTA2joGIB2bm1UtuwLYhvT+XF5V/vdIvxgXJf0CqsXd+XkfnI//XYDPVqU7k3SSbQjw06r9230PImIOcBXwc0mD8ufvcLpwLEtaU9KWSifL381lan3dzsl5tH6+h0raKa97FfigjTJuRqqwNF1Xa9DTSG1p9yj1lvgH8BjpG5SIuJb0jXVF/qnzGOlkIqSfbH8mnQB4jvQCVjdL/BHYnXkn5HbJtYn3ST/VtiN9454FfC3X4LstIt4g1VRm5ec2DbiFVDv6V0S8TqrFjCYd3D8AdoiI17qY5SGkL5i3SL0MrqtYtzqpRj+d9ME4K9ru+3wCcB+pBvUo8EBe1i0R8WJEtHdhxhGkWtg0UrPElVXrjyV9yb0l6aud5ZU/INsCB+VFhwOflrRXO2X7J+l1uT3PTyWdaLszf9Dbcj4wIpfpus7K1InuHMNzSO/5SNKJw9eA35FqstU+Avw/UnCeRPpiai9gXQJsL2mR1gURMYV07GzE/O/RJbnc/wWeYF7FqkP587cLqT34zfz8rqnY5FTSCeDXcpp/qUriNGA3pV4Yp7eRxfdIFbBngDtIXyoX1FK2KgsDJ+ZyvEQ6gX50RRmuJzUdTsvl/Fx+fu8APwfuzMfJBnmfPWlw//JatfYKMLNeTtL/Aa9ExKk9XZYFhaQvAftERKcVjULyd4A2Myun0o3FYWZmiQO0mVlJOUCbmZWUA7SZWUk5QJuZlZQDtJlZSTlAm5mVlAO0mVlJOUCbmZWUA7SZWUk5QJuZlZQDtJlZSTlAm5mVlAO0mVlJOUCbmZWUA7SZWUk5QJuZlZQDtJlZSTlAm5mVlAO0mVlJOUCbmZWUA7SZWUk5QJuZlZQDtJlZSTlAm5mVlAO0mVlJOUCbmZWUA7SZWUk5QJuZlZQDtJlZSTlAm5mVlAO0mVlJOUCbmZWUA7SZWUn17+kCtGeRdb8bPV0GK583J57Z00WwEhrYH3U3jXpizswHz+x2frUobYA2M2uqln49XYIPcYA2MwNQ+Vp8HaDNzADUlFaLupTvK8PMrCeopfapo2SkgZLulfSwpMclHZeXD5F0s6Sn8/+lOiuSA7SZGaQadK1Tx94DtoyIdYCRwLaSNgB+CNwSEasDt+T5DjlAm5lBw2rQkUzPswPyFMBOwMV5+cXAlzsrkgO0mRmkXhy1Tp2Q1E/SQ8ArwM0RcQ+wXERMAcj/l+20SN17RmZmC4g6mjgkjZJ0X8U0qjKpiJgTESOBFYDPSlq7K0VyLw4zM6irm11EnAucW8N2b0kaD2wLvCxpWERMkTSMVLvukGvQZmbQsJOEkoZKWjI/XgTYGngSuB7YN2+2L/DHzorkGrSZGTTyQpVhwMWS+pEqwVdFxI2S7gauknQg8B/gK50l5ABtZgYNC9AR8QiwbhvLXwe2qictB2gzM4B+HovDzKycSniptwO0mRl4sCQzs9JyDdrMrKRKWIMurESSWiRtVFT6ZmYN1cBLvRtWpKISjogPgJOLSt/MrKEaN5pdwxRdpx8naVephI07ZmaVGjSaXSMV3QZ9OLAYMEfSTECk0fgGF5yvmVl9SliPLDRAR8SgItM3M2uYEp4kLLwXh6QdgU3z7PiIuLHoPM3M6tbXArSkE4H1gcvyokMkfT4iOr3Vi5lZUzWxd0atiq5Bbw+MzD06kHQx8CA13IvLzKyp+lobdLYk8EZ+vEQT8jMzq19fa+IAfgE8KOlWUg+OTYGjCs7TzKx+fa0GHRFj8+1e1icF6CMj4qUi8zQz64oyXq5RaJ1e0sbA1Ii4HhgE/EDS8CLzNDPrCrWo5qlZim50ORt4R9I6wPeB54BLCs7TzKxuSnfrrmlqlqID9OyICGAn4PSIOI1UkzYzK5UyBuiiTxJOk3QUsDewab6J4oCC8zQzq1ufa4MGdgfeAw7MJwc/Cvyq4DzNzOrWJ2vQwGkRMUfSGsBawNiC8zQzq1/5KtCF16AnAAtL+ihwC7A/cFHBeZqZ1a2lpaXmqWllKjh9RcQ7wC7AGRGxM/CJgvM0M6tbX2zikKQNgb2AA/Oy8o1IYmZ9XhlPEhYdoA8lXdp9bUQ8LmkV4NaC8zQzq1/54nPhl3rfBtwmabE8/wxwcJF5mpl1RRlr0EVf6r2hpCeASXl+HUlnFZmnmVlXlLENuuiThKcCXwBeB4iIh5l3dxUzs9Io41gchY8HHRHPV33jzCk6TzOzepWxiaPoAP28pI2AkLQQqf15UsF5mpnVrS8G6IOA00iXeL8AjAO+U3CeZmZ161MBOg+MdGpE7FVUHmZmjdKoAC1pRdKwyh8BPgDOjYjTJB0LfAN4NW96dETc1FFahQXoPP7GUEkLRcT7ReVjZtYIDTz5NxsYHREPSBoE3C/p5rzuNxHx61oTKrqJYzJwp6TrgRmtCyPilILzNTOrS6Nq0BExBZiSH0+TNInUzFu3orvZvQjcmPMZVDGZmZVKPf2gJY2SdF/FNKqdNFcG1gXuyYu+K+kRSRdIWqqzMhV9JeFxRaZvZtYwdVSgI+Jc4NwOk5MWB64GDo2IqZLOBo4HIv8/GTigozQKDdCSbsiFqfQ2cB8wJiLeLTL/3mjhhfrzt/MPZaGF+tO/Xz+u/duDnHDOTeyy9br86KDtWetjy7HJPr/mgSf+09NFtR40Z84c9vzqriy73HKcedaYni7OAqGRvTgkDSAF58si4hqAiHi5Yv15pNaFDhXdBv0MMJR5g/TvDrwMrAGcB+xTcP69znvvz2bbUaczY+b79O/fwt8vOJxxdz7B4/9+kT1Gn8eZx+zZ00W0Erjs0ktYZZVVmT5jek8XZYHRwF4cAs4HJlWeb5M0LLdPA+wMPNZZWkUH6HUjovLS7hskTYiITSU9XnDevdaMmanTy4D+/ejfvx8RwVPPvtzJXtZXvPzSS9w+YTxfH3UQl15yUU8XZ4HRwIH4NyZVPh+V9FBedjSwp6SRpFaFycA3O0uo6AA9VNJKEfEfAEkrAcvkde56146WFnHX5Uey6opDGXPlBCY+9lxPF8lK5KQT/4/DRn+fGTNmdL6x1a5BLRwRcUc7qXXY57ktRffiGA3cIelWSeOB24Hv5+FHL67euPLM6OzX+m4F+4MPgg32OJHVvnAM6609nBGrDuvpIllJ3Db+VoYMGcKIT6zd00VZ4JRxNLuie3HcJGl10s1iBTxZcWLw1Da2n3tmdJF1v1t9crHPeXv6TCbc9zTbbDSCJ/49pfMdbIH30IMPMH7837nj9gm89957zJgxnaOOPIJf/LLmax+sHX3qUm+Yeybzm8wbYnS8pDERMavIfHuzZZZanFmz5vD29JkMXHgAW35uTU6+6G89XSwriUMOG80hh40GYOK993DxRRc4ODdICeNz4W3QZwMDgNZB+vfJy75ecL691keWGcx5P9uHfi0ttLSIq29+gD/f/hg7bvEpTjnyKyyz1OJcc/pBPPLUf9nxO7/t6eKaLTDKWINWRHEtCZIejoh1OlvWFjdxWFvenHhmTxfBSmhg/+6f4lvzyL/WHHOe+uUXmhLNiz5JOEfSqq0z+aaxHrDfzEpHqn1qlqKbOI4AbpX0DOkk4XBg/4LzNDOrW0sTb2VVq6LHg14HWB1Yk3m9ON4rKk8zs64qYRN0cU0cETEH2DEi3ouIRyLiYQdnMyurPtcPGrhL0pnAlcw/HvQDBedrZlaXPtXEkW2U//+sYlkAWxacr5lZXcrYza7oAP2ViHit4DzMzLqthPG5mDZoSV+S9CrwiKQXJG3U6U5mZj2ojG3QRZ0k/DmwSUQsD+wK/KKgfMzMGqIv9YOeHRFPAkTEPfnOtmZmpdWX2qCXlXR4e/O+q7eZlU1f6sVxHvPfvbt63sysVEpYgS4mQPtu3mbW25SxiaPowZLmkuSLU8ystPrSScK2lO/rycwsK2MNupkB+k9NzMvMrC4ljM/NC9ARcUyz8jIzq1cZe3EU2gYtaRdJT0t6W9JUSdMkTS0yTzOzrijjlYRF16BPAr4UEZMKzsfMrFvK2AbdaQ1a0kmSBksaIOkWSa9J2rvG9F92cDaz3qC39uLYJiJ+IGln4AXgK8CtwO9r2Pc+SVcC1wFzB+uPiGu6UFYzs8KUsQZdS4AekP9vD4yNiDfqeCKDgXeAbSqWBeAAbWalUsaThLUE6BskPQnMBL4taSjwbi2JR4RvEGtmvUIJK9Cdt0FHxA+BDYH1ImIWqUa8Uy2JS1pB0rWSXpH0sqSrJa3QvSKbmTVei1Tz1LQydbaBpEWB7wBn50XLA+vVmP6FwPV5n48CN+RlZmalUsaThLX0g74QeJ959xd8ATihxvSHRsSFETE7TxcBQ+svpplZscrYD7qWAL1qRJwEzAKIiJnUPq7Ga5L2ltQvT3sDr3exrGZmhWlR7VNHJK0o6VZJkyQ9LumQvHyIpJvzxXs3S1qq0zLVUO73JS1C6n2BpFWp6DLXiQOArwIvAVOA3fIyM7NSaWlRzVMnZgOjI+LjwAbAdySNAH4I3BIRqwO35PkO1dKL46fAX4AVJV0GbAzsV8N+RMR/gB1r2dbMrCepQQNuRsQUUoWUiJgmaRLpHNxOwOZ5s4uB8cCRHaXVaYCOiJvzWM4bkJo2DomI1zraR9JPOk4yju8sXzOzZqqnG7SkUcCoikXnRsS5bWy3MrAucA+wXA7eRMQUSct2lk+nAVrSpvnhtPx/hCQiYkIHu81oY9liwIHA0oADtJmVSj0n/3Iw/lBArkpvceBq4NCImNqVk4u1NHF8v+LxQOCzwP3Alu3tEBEnVxRyEHAIsD9wBXBye/uZmfWURnbOkDSAFJwvqxja4mVJw3LteRjwSmfp1NLE8aWqjFckjVLXWQGHAIcDe5HaWz4dEW92tp+ZWU/o16BLvZWqyucDkyLilIpV1wP7Aifm/3/sLK2uDDf6ArB2JwX8FbAL6SfAJyNiehfyMTNrmgb2b94Y2Ad4VNJDednRpMB8laQDgf+QBp7rUC1t0GeQu9iRuuWNBB7uZLfRpK54xwA/qnjiIp0kHNxZvmZmzdSo+BwRd9D+tSJb1ZNWLTXo+yoezyaNaHdnRztERNPuFm5m1gjNHGOjVrW0QV/cjIKYmfWk8oXnDgK0pEeZ17Qx3ypSM8WnCiuVmVmT9bYB+3doWinMzHpYo3pxNFK7AToinmtmQczMelIJK9A1jQe9gaSJkqZLel/SHElTm1E4M7NmKeNwo7X04jgT2AP4A2mg/q8BqxVZKDOzZithC0dtF6pExL8k9YuIOcCFku4quFxmZk3V204StnpH0kLAQ5JOIg2jt1ixxTIza67yhecO2qAltd53cJ+83XdJo9StCOxafNHMzJqnX4tqnpqloxr0eXm4vLHAFRHxBHBcc4plZtZcZWziaLcGHRHrkvpCzwH+n6SHJB0paXjTSmdm1iS97q7eEfFURBwXESNIw+MtCfxdUodjcZiZ9TYtUs1Ts9TUi0NSC7AssBzpBOGrRRbKzKzZStjC0XGAlrQJsCfwZeAx0h1RDouIt4su2M1X+a5Y9mGvTK31hvLWl6w0ZOFup9GvhBG6o8GSnicNKn0FcFxEvNy0UpmZNVkZTxJ2VIP+vMfjMLO+olddSejgbGZ9Sa8K0GZmfUlva+IwM+szelUNuupmsR8SEQcXUiIzsx7QqwbsZ/6bxZqZLdDKeKfrjk4S+maxZtZnlLAJuvM2aElDgSOBEcDA1uURsWWB5TIza6pmXsJdq1pq9ZcBk4CPkUazmwxMLLBMZmZN1+sGS8qWjojzgVkRcVtEHABsUHC5zMyaqkW1T81SSze7Wfn/FElfBF4EViiuSGZmzdfbenG0OkHSEsBo4AxgMHBYoaUyM2uyEsbnzgN0RNyYH74NbFFscczMeoZKeFfCWnpxXEgbF6zktmgzswVCr6xBAzdWPB4I7ExqhzYzW2D0ygAdEVdXzksaC/ytsBKZmfWARp4klHQB6Z6ur0TE2nnZscA3mHdHqqMj4qaO0unK1Y2rAyt1YT8zs9JqcD/oi4Bt21j+m4gYmacOgzPU1gY9jfnboF8iXVloZrbAaOSVhBExQdLK3U2nliaOQd3NxMys7JrUBv1dSV8jDUY3OiLe7LBMnaUm6ZZalpmZ9Wb1NHFIGiXpvoppVA1ZnA2sCowEpgAnd7ZDR+NBDwQWBZaRtBTM7SQ4GFi+hsKYmfUaLXX0g46Ic4Fz60m/8sbbks5j/h5ybeqoieObwKGkYHw/8wL0VOC39RTMzKzs+hU8ILSkYRExJc/uDDzW2T4djQd9GnCapO9FxBkNKqOZWSk18iRh7o68OakF4gXgp8DmkkaSOl1MJlWCO1TLhSofSFoyIt7KGS8F7BkRZ3Wp5GZmJdTIYUQjYs82Fp9fbzq1VOq/0Rqcc8Zvkjpbm5ktMFqkmqdmqaUG3SJJEREAkvoBCxVbLDOz5irhDVVqCtB/Ba6SdA6p7eQg4C+FlsrMrMl61U1jKxwJjAK+RerJMQ44r8hCmZk1W6+8J2FEfBAR50TEbhGxK/A4aeB+M7MFRhnboGuq1UsaKemXkiYDxwNP1rBPP0m/72b5zMyaQnVMzdLRlYRrAHsAewKvA1cCioia7qoSEXMkDZW0UES835DSmpkVpIQtHB22QT8J3A58KSL+BSCp3nsRTgbulHQ9MKN1YUScUmc6ZmaFUgkjdEcBeldSDfpWSX8BrqD+2v2LeWoBPCqemZVWv94UoCPiWuBaSYsBXybdyXs5SWcD10bEuM4Sj4jjACQNSrMxvSGlNjNrsPKF59p6ccyIiMsiYgdgBeAh4Ie1JC5pbUkPkgYFeVzS/ZI+0Z0Cm5kVQVLNU7PU1Tc7It6IiDERsWWNu5wLHB4RwyNiODAa96E2sxJqqWNqllouVOmOxSLi1taZiBifm0zMzEqlt50kbIRnJP0YuDTP7w08W3CeZmZ1K194Lr62fgAwFLgGuBZYBti/4DzNzOrWT6p5apZCa9B5aNKDYe4oeItFxNQi8zQz64oStnAUW4OWdLmkwbnd+XHgKUnfLzJPM7OuUB1/zVJ0E8eIXGP+MnATsBKwT8F5mpnVrZ67ejdL0QF6gKQBpAD9x4iYRRpT2sysVFpQzVOzFN2LYwxpPI6HgQmShpPuCm5mViotJRyxv+iThKcDp1csek5STaPhmZk1UzPblmtV9EnCQ/JJQkk6X9IDQK1XIZqZNU2Lap+aVqaC0z8gnyTchtQfen/gxILzNDOrWxl7cRTdBt36TLYHLoyIh1XG6ynNrM8rY2QqOkDfL2kc8DHgqDzs6AcF59mrXXDqCTwy8U4GLbEUx591OQAT77iF6y//HVOen8wxp1zAyqt/vIdLaT3p+eee5YQf/2Du/Ev/fYF9v/FtdtnDPVi7o4xt0EUH6AOBkcAzEfGOpKXxpd4d2njrL7LVDrvxu1N+NnfZR4evwneOPpFLznTrkMGKwz/GmEv+AMCcOXPYc8et2XizrXq4VL1fGQfsL7oNOoAR5Mu9gcWAgQXn2autufa6LDZo8HzLll/xY3xkheE9VCIrswfvu4dhH12R5YYt39NF6fX64oUqZwEbkm48CzAN+G3BeZr1GeNv/gtb/M92PV2MBUIZ7+pddID+XER8B3gX5g6etFDBeZr1CbNmzeLuO8az2Vbb9HRRFggtUs1T08pUcPqz8ih2ASBpKB2cJJQ0StJ9ku67/oqLCi6aWe828e47WG3Nj7PUkKV7uigLhDLWoIs+SXg6aRzoZSX9HNgNOKa9jSPiXNJtsrjj6Tc9ZodZB269+c9u3mik8p0jRBHFxEFJLcAGwBvAVqSnf0tETKpl/74aoMec9GOeevQBpk99i8FLDmGnvb7BYosP5vIxJzPt7bdYdPHFWfFja3D48af1dFF7xEpLL9rTRSiFd9+dyf/utA2XXn0Tiy0+qKeL0+NWGrJwt8Prvc+8XXPM+ewqS3SYn6QLgB2AVyJi7bxsCHAlsDJpjKKv5mbf9tMpKkDnAt0dERt2Zd++GqCtYw7Q1pZGBOiJdQTo9TsP0JsC04FLKgL0ScAbEXGipB8CS0XEkR2lU3Qb9DhJu/rqQTMrvQY2QkfEBFLrQaWdgIvz44tJwzB3qOg26MNJfZ9nS3qX9NQiIgZ3vJuZWXM14UrC5SJiCkBETJG0bGc7FD3cqBvHzKxXqOd3vqRRwKiKRefmTg4NVWiAlvTpNha/DTwXEbOLzNvMrB71BOjKHmd1eFnSsFx7Hga80tkORTdxnAV8Gng0z3+SdHeVpSUdFBHjCs7fzKwmTWjiuB7YlzTk8r7AHzvboeiThJOBdSPiMxHxGdLASY8BWwMnFZy3mVnNGjkWh6SxwN3AmpJekHQgKTD/j6Sngf+hhrHxi65BrxURj7fORMQTktaNiGfcscPMyqSRESki9mxnVV3DDhYdoJ+SdDZwRZ7fHfinpIWBWQXnbWZWuxLWGYsO0PsB3wYOJT39O4AjSMHZN481s9LocwP2R8RMSWcA40gDJj0VEa015+lF5m1mVo9m3gy2VkV3s9ucdMXMZFINekVJ++arbMzMyqOvBWjgZGCbiHgKQNIawFjgMwXna2ZWlz7XxAEMaA3OABHxT0kDCs7TzKxuZexY1oy7ep8PXJrn9wLuLzhPM7O6lTA+Fx6gDwK+Q7pprIAJpKsLzczKpYQRurAAnQfsvz+PhXpKUfmYmTVCM+81WKvCLvWOiA+AhyWtVFQeZmaN0hfvSTgMeFzSvcCM1oURsWPB+ZqZ1ad8FejCA/RxBadvZtYQfaabnaSBpBOEq5GGGj3f4z+bWZmVsAm6sBr0xaTxNm4HtgNGAIcUlJeZWbf1pQA9IiI+CZD7Qd9bUD5mZg3RZ5o4qBhKNCJme+xnMyu7MoapogL0OpKm5scCFsnzvqu3mZVSCeNzMQE6IvoVka6ZWWFKGKGL7mZnZtYr9KU2aDOzXqXPDdhvZtZb9KWThGZmvUz5IrQDtJkZrkGbmZVWCeOzA7SZGbgGbWZWWmW84tkB2swMN3GYmZVWCSvQDtBmZuArCc3Myqt88dkB2swMfKm3mVlpuYnDzKykGnmSUNJkYBowB5gdEet1JR0HaDOzYmwREa91JwEHaDMzytnNrqWnC2BmVgaq508aJem+imlUVXIBjJN0fxvrauYatJkZ9fXiiIhzgXM72GTjiHhR0rLAzZKejIgJdZep3h3MzBZIqmPqRES8mP+/AlwLfLYrRXKANjOjviaODtORFpM0qPUxsA3wWFfK5CYOMzMaepJwOeDaPDpef+DyiPhLVxJygDYzo3FXekfEM8A6jUjLAdrMDDwWh5lZWbWUsCO0IqKny2CdkDQqd+sxm8vHxYLPvTh6hy53dLcFmo+LBZwDtJlZSTlAm5mVlAN07+B2RmuLj4sFnE8SmpmVlGvQZmYl5QBtZlZSDtBVJIWkkyvmj5B0bIPSPlbSfyU9JOkxSTs2Il0rH0lzKt7nP0hatKfLZL2PA/SHvQfsImmZgtL/TUSMBL4CXCBpvvdAUreu7uzu/nXm1a9ZefVCMyNiZESsDbwPHFS5shGvXbNe/2YeUzY/B+gPm006O35Y9QpJwyXdIumR/H+lvPwiSadLukvSM5J26yyTiJiU81pG0nhJ/yfpNuAQSVtJelDSo5IukLRwzmd7SU9KuiPnd2NefqykcyWNAy6RNFTS1ZIm5mnjvN1muVb3UE5/kKRhkiZU1PY2ydvumfN/TNIvK16D6ZJ+JukeYMNuvtZ9xe3AapI2l3SrpMuBRyUNlHRhfp0flLQFgKRFJV2Vj7MrJd0jab28br7XX9Leku7N798YSf3ydFF+7x6VdFje92BJT+R0r8jLhki6Li/7h6RP5eXzHVM98aIZEBGeKiZgOjAYmAwsARwBHJvX3QDsmx8fAFyXH18E/IH0hTcC+Fc7aR8LHJEffw54kTREy3jgrLx8IPA8sEaevwQ4tGL5x/LyscCNFeneDyyS5y8HPp8frwRMqij/xvnx4qSxWEYDP8rL+gGDgOWB/wBD8zZ/B76ctwngqz39PpV9Aqbn//2BPwLfAjYHZlS8h6OBC/PjtfJrPjAfc2Py8rVJX+TrVb/+wMfzezogz58FfA34DHBzRVmWzP9fBBauWnYG8NP8eEvgobaOKU89M7kG3YaImEoKjAdXrdqQFPwALgU+X7Huuoj4ICKeII0H257DJD0E/BrYPfKnAbgy/18TeDYi/pnnLwY2JX2An4mIZ/PysVXpXh8RM/PjrYEzcz7XA4PzAOJ3AqdIOpj0AZ0NTAT2z+3sn4yIacD6wPiIeDVvc1kuA6TbyF/dwfOzZJH8+t9HCrzn5+X3VryHnycdR0TEk8BzwBp5+RV5+WPAIxXpVr7+W5GC8cSc11bAKsAzwCqSzpC0LTA1b/8IcJmkvUlBv7oMfweWlrREXld5TFkPcNtS+04FHgAu7GCbyk7k71U8FoCknwNfBIjU7gypDfrXbaQ1o3LfNnQ21NaMisctwIZtfLhOlPQnYHvgH5K2jogJkjbN5bxU0q+Y94Fuy7sRMaeTslhug65coDRaWuX71JX3uvL1F3BxRBz1oQSkdYAvAN8Bvkr6xfdF0hftjsCPJX2inbxaj+sZbayzJnINuh0R8QZwFXBgxeK7gD3y472AOzpJ40eRThSNrCPrJ4GVJa2W5/cBbsvLV5G0cl6+ewdpjAO+2zojaWT+v2pEPBoRvyTV7NaSNBx4JSLOI9XyPg3cA2wmaZl8ImrPXAZrrAmk4whJa5Cao54iHVdfzctHAJ9sZ/9bgN2Ubkza2p48PJ/gbomIq4EfA5/OJ6NXjIhbgR8AS5KauSrLsDnwWv4FaSXgGnTHTqYi0JGaPC6Q9H3gVWD/RmcYEe9K2h/4Qz57PhE4JyLek/Rt4C+SXgPu7SCZg4HfSnqE9B5PIPUiODSfiJoDPAH8mfSF831Js0jt71+LiCmSjgJuJdWwboqIPzb6uRpnAedIepTU5LBffp/PAi7O79+DpKaJt6t3jognJB0DjMsBeBapxjwTuFDzeggdRTq/8PvcfCHSL7m3ctPWhTmvd4B9C3y+Vidf6t2LSFo8IqYr/Vb+LfB0RPymp8tljZV/tQzIX9arkmrKa0TE+z1cNGsy16B7l29I2hdYiFSzGtPD5bFiLArcKmkAqbb7LQfnvsk1aDOzkvJJQjOzknKANjMrKQdoM7OScoA2MyspB2gzs5JygDYzKykHaDOzknKANjMrKQdoM7OScoA2MyspB2gzs5JygDYzKykHaDOzknKANjMrKQdom4+kOZIekvSYpD9IWrQbaV0kabf8+Hf59k3tbbu5pI26kMfkfIun6ny/WbXsy5JuqqWsZmXhAG3VZub7KK4NvE+6VdZc+W4fdYuIr+c7nrdnc6DuAN2Oscy7d2SrPfjwndDNSs0B2jpyO7Bart3eKuly4FFJ/ST9StJESY+01laVnCnpiXz38GVbE5I0XtJ6+fG2kh6Q9LCkW/KNcA8CDsu1900kDZV0dc5joqSN875LSxon6UFJY2j7rtR/I90Qd1jeZ1Fga+A6ST/J6T0m6dx8+7D5VNbKJa0naXx+vJikC/L+D0raKS//hKR7c9kfkbR6I158Mwdoa1O+Ye12wKN50WeBH0XECNKdzt+OiPWB9Um34voYsDOwJuku1N+gjRqxpKHAecCuEbEO8JWImAycQ7qR6ciIuB04Lc+vD+wK/C4n8VPgjohYF7iedCfs+UTEHOAa8p2xgR2BWyNiGnBmRKyffyEsAuxQx8vyI+DvuUxbAL+StBjpy+W0fPf29YAX6kjTrF2+J6FVW0TSQ/nx7cD5pEB7b0Q8m5dvA3yqos12CWB1YFNgbA6QL0r6exvpbwBMaE0rIt5opxxbAyMqKriDJQ3KeeyS9/2TpDfb2X8s8CtSoN8DuCQv30LSD0j3/RsCPA7c0E4a1bYBdpR0RJ4fSPqCuBv4kaQVgGsi4uka0zPrkAO0VZuZa4Jz5SA5o3IR8L2I+GvVdtsDnd3kUjVsA+nX3YYRMbONstSy/53AMEnrkL5g9pA0EDgLWC8inpd0LCnIVpvNvF+XletFqvk/VbX9JEn3AF8E/irp6xHR1peTWV3cxGFd8VfgW/mu00haI//Un0AKhP1y++8Wbex7N7BZbhJB0pC8fBowqGK7ccB3W2ckjcwPJwB75WXbAUu1VcBId0O+CrgYuCki3mVesH1N0uJAe702JgOfyY93rXre32ttt5a0bv6/CvBMRJxOanb5VDvpmtXFAdq64nfAE8ADkh4DxpB+jV0LPE1qtz4buK16x4h4FRgFXCPpYeDKvOoGYOfWk4TAwcB6+aTbE8zrTXIcsKmkB0hNDv/poJxjgXWAK3Leb5Havx8FrgMmtrPfccBpkm4H5lQsPx4YADySn/fxefnuwGO5aWgt5jWnmHWLUkXDzMzKxjVoM7OScoA2MyspB2gzs5JygDYzKykHaDOzknKANjMrKQdoM7OScoA2Myup/w9yZj2WIlpDewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels (validation set)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_112.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9916494b",
   "metadata": {},
   "source": [
    "**Model saving:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "64c171b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5161c780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_111_json = model_111.to_json()\n",
    "with open(\"model_111.json\", \"w\") as json_file:\n",
    "    json_file.write(model_111_json)\n",
    "# serialize weights to HDF5\n",
    "model_111.save_weights(\"model_111.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79ff6854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_112_json = model_112.to_json()\n",
    "with open(\"model_112.json\", \"w\") as json_file:\n",
    "    json_file.write(model_112_json)\n",
    "# serialize weights to HDF5\n",
    "model_112.save_weights(\"model_112.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72679f09",
   "metadata": {},
   "source": [
    "### 1.2 With resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7979d0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1], dtype=uint8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_progressor = np.array(y_train)[:,1]\n",
    "y_progressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "896215a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_progressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8076f711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463, 768, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4353a669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463, 768)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2d = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]))\n",
    "X_train_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12d3ae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(642, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy = 'minority')\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train_2d, y_progressor)\n",
    "print(X_train_over.shape)\n",
    "y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7fd42c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>642 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1\n",
       "0    1  0\n",
       "1    0  1\n",
       "2    1  0\n",
       "3    1  0\n",
       "4    1  0\n",
       "..  .. ..\n",
       "637  0  1\n",
       "638  0  1\n",
       "639  0  1\n",
       "640  0  1\n",
       "641  0  1\n",
       "\n",
       "[642 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_over = pd.get_dummies(y_train_over)\n",
    "y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7abbebd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Progressor  Progressor\n",
      "0               1             321\n",
      "1               0             321\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_over=y_train_over.rename(columns={0: \"Non-Progressor\", 1: \"Progressor\"})\n",
    "print(y_train_over.value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "271f06d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Progressor  Progressor\n",
      "1               0             321\n",
      "0               1             142\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "06046f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>642 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "0                 1           0\n",
       "1                 0           1\n",
       "2                 1           0\n",
       "3                 1           0\n",
       "4                 1           0\n",
       "..              ...         ...\n",
       "637               0           1\n",
       "638               0           1\n",
       "639               0           1\n",
       "640               0           1\n",
       "641               0           1\n",
       "\n",
       "[642 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eb578e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 768)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b666d79e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.12335958],\n",
       "        [0.12335958],\n",
       "        [0.12073491],\n",
       "        ...,\n",
       "        [0.12598425],\n",
       "        [0.12598425],\n",
       "        [0.12335958]],\n",
       "\n",
       "       [[0.18372703],\n",
       "        [0.18635171],\n",
       "        [0.18897638],\n",
       "        ...,\n",
       "        [0.17322835],\n",
       "        [0.17585302],\n",
       "        [0.18110236]],\n",
       "\n",
       "       [[0.11548556],\n",
       "        [0.11811024],\n",
       "        [0.11811024],\n",
       "        ...,\n",
       "        [0.11811024],\n",
       "        [0.11811024],\n",
       "        [0.11548556]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.16535433],\n",
       "        [0.167979  ],\n",
       "        [0.167979  ],\n",
       "        ...,\n",
       "        [0.16272966],\n",
       "        [0.16272966],\n",
       "        [0.16535433]],\n",
       "\n",
       "       [[0.02624672],\n",
       "        [0.03149606],\n",
       "        [0.03937008],\n",
       "        ...,\n",
       "        [0.01049869],\n",
       "        [0.01574803],\n",
       "        [0.02099738]],\n",
       "\n",
       "       [[0.11811024],\n",
       "        [0.12073491],\n",
       "        [0.12335958],\n",
       "        ...,\n",
       "        [0.11286089],\n",
       "        [0.11548556],\n",
       "        [0.11548556]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over = np.reshape(X_train_over, (X_train_over.shape[0], X_train_over.shape[1], 1))\n",
    "X_train_over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e09db5",
   "metadata": {},
   "source": [
    "#### 1.2.1 Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52453979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_10 (Conv1D)          (None, 766, 64)           256       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 255, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 255, 64)           0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 16320)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                1044544   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,045,874\n",
      "Trainable params: 1,045,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model2\n",
    "model_121 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_121.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_121.add(MaxPooling1D(pool_size=3))\n",
    "# model_1.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_121.add(Dropout(0.5))\n",
    "# model_1.add(MaxPooling1D(pool_size=2))\n",
    "model_121.add(Flatten())\n",
    "model_121.add(Dense(64, activation='relu'))\n",
    "model_121.add(Dense(16, activation='relu'))\n",
    "model_121.add(Dense(2, activation='softmax'))\n",
    "model_121.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d5c8c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=400,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86585316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.6951 - accuracy: 0.4984 - val_loss: 0.6903 - val_accuracy: 0.6792\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6911 - accuracy: 0.5140 - val_loss: 0.6689 - val_accuracy: 0.6604\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6900 - accuracy: 0.5078 - val_loss: 0.6750 - val_accuracy: 0.6604\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.6857 - accuracy: 0.5592 - val_loss: 0.6600 - val_accuracy: 0.6792\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6795 - accuracy: 0.5467 - val_loss: 0.6991 - val_accuracy: 0.4717\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6798 - accuracy: 0.5779 - val_loss: 0.6597 - val_accuracy: 0.7170\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.6744 - accuracy: 0.5903 - val_loss: 0.6801 - val_accuracy: 0.5849\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.6619 - accuracy: 0.6262 - val_loss: 0.6447 - val_accuracy: 0.6981\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6626 - accuracy: 0.6277 - val_loss: 0.6326 - val_accuracy: 0.6981\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.6561 - accuracy: 0.6246 - val_loss: 0.6368 - val_accuracy: 0.6981\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6492 - accuracy: 0.6293 - val_loss: 0.6212 - val_accuracy: 0.7358\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6480 - accuracy: 0.6355 - val_loss: 0.6240 - val_accuracy: 0.6981\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.6463 - accuracy: 0.6526 - val_loss: 0.6271 - val_accuracy: 0.6792\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.6444 - accuracy: 0.6386 - val_loss: 0.6526 - val_accuracy: 0.6792\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.6421 - accuracy: 0.6324 - val_loss: 0.6211 - val_accuracy: 0.6792\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.6421 - accuracy: 0.6480 - val_loss: 0.6153 - val_accuracy: 0.6981\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6341 - accuracy: 0.6558 - val_loss: 0.6396 - val_accuracy: 0.6604\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.6409 - accuracy: 0.6340 - val_loss: 0.6038 - val_accuracy: 0.7358\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.6283 - accuracy: 0.6558 - val_loss: 0.6549 - val_accuracy: 0.6226\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6324 - accuracy: 0.6511 - val_loss: 0.6233 - val_accuracy: 0.6792\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.6244 - accuracy: 0.6636 - val_loss: 0.5940 - val_accuracy: 0.6981\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.6243 - accuracy: 0.6417 - val_loss: 0.6674 - val_accuracy: 0.6415\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.6262 - accuracy: 0.6386 - val_loss: 0.5988 - val_accuracy: 0.7170\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.6248 - accuracy: 0.6402 - val_loss: 0.6214 - val_accuracy: 0.6604\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6242 - accuracy: 0.6340 - val_loss: 0.6036 - val_accuracy: 0.7170\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.6183 - accuracy: 0.6760 - val_loss: 0.6285 - val_accuracy: 0.6604\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6158 - accuracy: 0.6511 - val_loss: 0.6402 - val_accuracy: 0.6792\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.6159 - accuracy: 0.6495 - val_loss: 0.6399 - val_accuracy: 0.6792\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6133 - accuracy: 0.6651 - val_loss: 0.6121 - val_accuracy: 0.6415\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.6053 - accuracy: 0.6698 - val_loss: 0.6501 - val_accuracy: 0.6604\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.6179 - accuracy: 0.6573 - val_loss: 0.6043 - val_accuracy: 0.6792\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6074 - accuracy: 0.6760 - val_loss: 0.6340 - val_accuracy: 0.6792\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5986 - accuracy: 0.6791 - val_loss: 0.6289 - val_accuracy: 0.6792\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5934 - accuracy: 0.6916 - val_loss: 0.6192 - val_accuracy: 0.6792\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5890 - accuracy: 0.6854 - val_loss: 0.6251 - val_accuracy: 0.6604\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5927 - accuracy: 0.6745 - val_loss: 0.6195 - val_accuracy: 0.6604\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5832 - accuracy: 0.7056 - val_loss: 0.6731 - val_accuracy: 0.6604\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5852 - accuracy: 0.6916 - val_loss: 0.6260 - val_accuracy: 0.6792\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5751 - accuracy: 0.7040 - val_loss: 0.6224 - val_accuracy: 0.6792\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.5843 - accuracy: 0.7087 - val_loss: 0.7026 - val_accuracy: 0.6226\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5900 - accuracy: 0.6854 - val_loss: 0.6428 - val_accuracy: 0.6226\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.5736 - accuracy: 0.7040 - val_loss: 0.6222 - val_accuracy: 0.6792\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5710 - accuracy: 0.7040 - val_loss: 0.6233 - val_accuracy: 0.6792\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5577 - accuracy: 0.7103 - val_loss: 0.6507 - val_accuracy: 0.6226\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5614 - accuracy: 0.7040 - val_loss: 0.6577 - val_accuracy: 0.6226\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.5582 - accuracy: 0.7227 - val_loss: 0.6887 - val_accuracy: 0.6604\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.5575 - accuracy: 0.7134 - val_loss: 0.6260 - val_accuracy: 0.6792\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.5564 - accuracy: 0.7196 - val_loss: 0.6251 - val_accuracy: 0.6981\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5572 - accuracy: 0.7368 - val_loss: 0.6563 - val_accuracy: 0.6038\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5553 - accuracy: 0.7305 - val_loss: 0.6569 - val_accuracy: 0.6226\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5500 - accuracy: 0.7414 - val_loss: 0.6199 - val_accuracy: 0.6981\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5503 - accuracy: 0.7227 - val_loss: 0.6636 - val_accuracy: 0.6226\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5413 - accuracy: 0.7243 - val_loss: 0.6298 - val_accuracy: 0.6792\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.5460 - accuracy: 0.7383 - val_loss: 0.6760 - val_accuracy: 0.6226\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5307 - accuracy: 0.7336 - val_loss: 0.6644 - val_accuracy: 0.6415\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5358 - accuracy: 0.7274 - val_loss: 0.6533 - val_accuracy: 0.6226\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5279 - accuracy: 0.7399 - val_loss: 0.6520 - val_accuracy: 0.6604\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 27ms/step - loss: 0.5232 - accuracy: 0.7477 - val_loss: 0.6381 - val_accuracy: 0.6792\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.5219 - accuracy: 0.7477 - val_loss: 0.6588 - val_accuracy: 0.6415\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5194 - accuracy: 0.7648 - val_loss: 0.6556 - val_accuracy: 0.6226\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5153 - accuracy: 0.7383 - val_loss: 0.6313 - val_accuracy: 0.6792\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.5179 - accuracy: 0.7679 - val_loss: 0.6895 - val_accuracy: 0.6226\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.5054 - accuracy: 0.7461 - val_loss: 0.6508 - val_accuracy: 0.6604\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5117 - accuracy: 0.7570 - val_loss: 0.6494 - val_accuracy: 0.6604\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5123 - accuracy: 0.7430 - val_loss: 0.6687 - val_accuracy: 0.6226\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5155 - accuracy: 0.7508 - val_loss: 0.6371 - val_accuracy: 0.6415\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.5065 - accuracy: 0.7648 - val_loss: 0.6690 - val_accuracy: 0.6038\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4938 - accuracy: 0.7679 - val_loss: 0.6360 - val_accuracy: 0.6604\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5023 - accuracy: 0.7757 - val_loss: 0.6563 - val_accuracy: 0.6604\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5051 - accuracy: 0.7617 - val_loss: 0.6613 - val_accuracy: 0.6415\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.4846 - accuracy: 0.7726 - val_loss: 0.6637 - val_accuracy: 0.6415\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4892 - accuracy: 0.7648 - val_loss: 0.6679 - val_accuracy: 0.6415\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4922 - accuracy: 0.7773 - val_loss: 0.6752 - val_accuracy: 0.6415\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.4843 - accuracy: 0.7835 - val_loss: 0.6772 - val_accuracy: 0.6415\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4789 - accuracy: 0.7835 - val_loss: 0.6673 - val_accuracy: 0.6415\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.4895 - accuracy: 0.7804 - val_loss: 0.6608 - val_accuracy: 0.6604\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.4726 - accuracy: 0.7819 - val_loss: 0.6660 - val_accuracy: 0.6226\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4710 - accuracy: 0.7944 - val_loss: 0.7054 - val_accuracy: 0.6038\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.4661 - accuracy: 0.7773 - val_loss: 0.6706 - val_accuracy: 0.6038\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4849 - accuracy: 0.7617 - val_loss: 0.6716 - val_accuracy: 0.6226\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4753 - accuracy: 0.7928 - val_loss: 0.7032 - val_accuracy: 0.6226\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.4677 - accuracy: 0.7882 - val_loss: 0.7170 - val_accuracy: 0.5660\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4660 - accuracy: 0.8037 - val_loss: 0.6733 - val_accuracy: 0.6038\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.4586 - accuracy: 0.7960 - val_loss: 0.7279 - val_accuracy: 0.6038\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4633 - accuracy: 0.7835 - val_loss: 0.6723 - val_accuracy: 0.6415\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4639 - accuracy: 0.7866 - val_loss: 0.6840 - val_accuracy: 0.6038\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4572 - accuracy: 0.7897 - val_loss: 0.6944 - val_accuracy: 0.5849\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4591 - accuracy: 0.7897 - val_loss: 0.7168 - val_accuracy: 0.5849\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.4713 - accuracy: 0.7710 - val_loss: 0.7089 - val_accuracy: 0.6226\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.4451 - accuracy: 0.8131 - val_loss: 0.7227 - val_accuracy: 0.6226\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4460 - accuracy: 0.8022 - val_loss: 0.6831 - val_accuracy: 0.6415\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4528 - accuracy: 0.8084 - val_loss: 0.7185 - val_accuracy: 0.6038\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4343 - accuracy: 0.8162 - val_loss: 0.6982 - val_accuracy: 0.6226\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4381 - accuracy: 0.7960 - val_loss: 0.7106 - val_accuracy: 0.6038\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.4449 - accuracy: 0.8053 - val_loss: 0.6990 - val_accuracy: 0.6226\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4394 - accuracy: 0.8069 - val_loss: 0.7033 - val_accuracy: 0.6226\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4365 - accuracy: 0.8271 - val_loss: 0.6899 - val_accuracy: 0.6226\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4252 - accuracy: 0.8209 - val_loss: 0.7152 - val_accuracy: 0.6038\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4233 - accuracy: 0.8178 - val_loss: 0.7218 - val_accuracy: 0.6038\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4300 - accuracy: 0.8146 - val_loss: 0.7042 - val_accuracy: 0.6226\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4178 - accuracy: 0.8349 - val_loss: 0.7113 - val_accuracy: 0.6038\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4168 - accuracy: 0.8396 - val_loss: 0.7259 - val_accuracy: 0.6226\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4132 - accuracy: 0.8255 - val_loss: 0.7659 - val_accuracy: 0.5660\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4141 - accuracy: 0.8302 - val_loss: 0.7422 - val_accuracy: 0.6226\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4114 - accuracy: 0.8380 - val_loss: 0.7403 - val_accuracy: 0.6038\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4217 - accuracy: 0.8162 - val_loss: 0.7584 - val_accuracy: 0.6038\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4100 - accuracy: 0.8224 - val_loss: 0.7720 - val_accuracy: 0.5849\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4016 - accuracy: 0.8255 - val_loss: 0.7648 - val_accuracy: 0.5849\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4089 - accuracy: 0.8178 - val_loss: 0.7554 - val_accuracy: 0.6038\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4019 - accuracy: 0.8318 - val_loss: 0.7486 - val_accuracy: 0.5849\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.4078 - accuracy: 0.8349 - val_loss: 0.7731 - val_accuracy: 0.5849\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4111 - accuracy: 0.8224 - val_loss: 0.7660 - val_accuracy: 0.5849\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.3901 - accuracy: 0.8427 - val_loss: 0.7553 - val_accuracy: 0.6038\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.3949 - accuracy: 0.8380 - val_loss: 0.7605 - val_accuracy: 0.6226\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3886 - accuracy: 0.8551 - val_loss: 0.7596 - val_accuracy: 0.6038\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4272 - accuracy: 0.8100 - val_loss: 0.7635 - val_accuracy: 0.5849\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4007 - accuracy: 0.8333 - val_loss: 0.7914 - val_accuracy: 0.5660\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3890 - accuracy: 0.8536 - val_loss: 0.7709 - val_accuracy: 0.6038\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3952 - accuracy: 0.8318 - val_loss: 0.7679 - val_accuracy: 0.6038\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3933 - accuracy: 0.8489 - val_loss: 0.8076 - val_accuracy: 0.5660\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3819 - accuracy: 0.8474 - val_loss: 0.7575 - val_accuracy: 0.5849\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3813 - accuracy: 0.8505 - val_loss: 0.7638 - val_accuracy: 0.5849\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.3931 - accuracy: 0.8442 - val_loss: 0.7923 - val_accuracy: 0.5849\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3892 - accuracy: 0.8505 - val_loss: 0.8039 - val_accuracy: 0.5283\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.3895 - accuracy: 0.8520 - val_loss: 0.7693 - val_accuracy: 0.5849\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.3734 - accuracy: 0.8583 - val_loss: 0.7932 - val_accuracy: 0.6038\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3675 - accuracy: 0.8614 - val_loss: 0.7901 - val_accuracy: 0.5849\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3626 - accuracy: 0.8567 - val_loss: 0.7854 - val_accuracy: 0.5849\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3673 - accuracy: 0.8614 - val_loss: 0.7925 - val_accuracy: 0.6038\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3647 - accuracy: 0.8520 - val_loss: 0.8150 - val_accuracy: 0.5849\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3642 - accuracy: 0.8645 - val_loss: 0.7935 - val_accuracy: 0.5849\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3799 - accuracy: 0.8442 - val_loss: 0.8061 - val_accuracy: 0.5849\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.3595 - accuracy: 0.8614 - val_loss: 0.8006 - val_accuracy: 0.5849\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3560 - accuracy: 0.8551 - val_loss: 0.8160 - val_accuracy: 0.5849\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.3659 - accuracy: 0.8505 - val_loss: 0.7926 - val_accuracy: 0.5849\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3704 - accuracy: 0.8427 - val_loss: 0.8282 - val_accuracy: 0.5660\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3532 - accuracy: 0.8676 - val_loss: 0.8064 - val_accuracy: 0.5849\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3488 - accuracy: 0.8676 - val_loss: 0.8021 - val_accuracy: 0.5849\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3496 - accuracy: 0.8614 - val_loss: 0.8081 - val_accuracy: 0.5849\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3379 - accuracy: 0.8769 - val_loss: 0.8360 - val_accuracy: 0.5660\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.3457 - accuracy: 0.8723 - val_loss: 0.8114 - val_accuracy: 0.5849\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3357 - accuracy: 0.8754 - val_loss: 0.8167 - val_accuracy: 0.5849\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3339 - accuracy: 0.8769 - val_loss: 0.8292 - val_accuracy: 0.6038\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3338 - accuracy: 0.8832 - val_loss: 0.8433 - val_accuracy: 0.5849\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3376 - accuracy: 0.8801 - val_loss: 0.8260 - val_accuracy: 0.5849\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3429 - accuracy: 0.8816 - val_loss: 0.8236 - val_accuracy: 0.6038\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.3349 - accuracy: 0.8785 - val_loss: 0.8531 - val_accuracy: 0.5849\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3351 - accuracy: 0.8738 - val_loss: 0.8368 - val_accuracy: 0.5849\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3476 - accuracy: 0.8660 - val_loss: 0.8696 - val_accuracy: 0.5283\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3329 - accuracy: 0.8847 - val_loss: 0.8643 - val_accuracy: 0.5283\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.3239 - accuracy: 0.8832 - val_loss: 0.8339 - val_accuracy: 0.5849\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.3187 - accuracy: 0.8769 - val_loss: 0.8416 - val_accuracy: 0.5849\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3323 - accuracy: 0.8816 - val_loss: 0.8236 - val_accuracy: 0.6038\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.3365 - accuracy: 0.8738 - val_loss: 0.8610 - val_accuracy: 0.5660\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.3189 - accuracy: 0.8863 - val_loss: 0.8622 - val_accuracy: 0.5849\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3156 - accuracy: 0.8941 - val_loss: 0.8338 - val_accuracy: 0.6226\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3245 - accuracy: 0.8863 - val_loss: 0.8505 - val_accuracy: 0.5660\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3162 - accuracy: 0.8879 - val_loss: 0.8382 - val_accuracy: 0.5660\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3187 - accuracy: 0.8816 - val_loss: 0.8357 - val_accuracy: 0.6038\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3292 - accuracy: 0.9003 - val_loss: 0.8476 - val_accuracy: 0.5283\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.3140 - accuracy: 0.8956 - val_loss: 0.8665 - val_accuracy: 0.5660\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.3059 - accuracy: 0.8956 - val_loss: 0.8568 - val_accuracy: 0.5472\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2986 - accuracy: 0.8847 - val_loss: 0.8729 - val_accuracy: 0.5849\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.2987 - accuracy: 0.8941 - val_loss: 0.8744 - val_accuracy: 0.6038\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3042 - accuracy: 0.8847 - val_loss: 0.8662 - val_accuracy: 0.5849\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.3011 - accuracy: 0.8972 - val_loss: 0.8883 - val_accuracy: 0.5660\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.2980 - accuracy: 0.8988 - val_loss: 0.8748 - val_accuracy: 0.5660\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3021 - accuracy: 0.8972 - val_loss: 0.8486 - val_accuracy: 0.5849\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2998 - accuracy: 0.9034 - val_loss: 0.8499 - val_accuracy: 0.5660\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.2948 - accuracy: 0.9097 - val_loss: 0.8906 - val_accuracy: 0.5283\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3015 - accuracy: 0.8894 - val_loss: 0.8749 - val_accuracy: 0.5849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.2963 - accuracy: 0.9050 - val_loss: 0.8670 - val_accuracy: 0.5660\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.2807 - accuracy: 0.9081 - val_loss: 0.8726 - val_accuracy: 0.5660\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.2821 - accuracy: 0.9050 - val_loss: 0.8922 - val_accuracy: 0.5660\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 1s 23ms/step - loss: 0.2906 - accuracy: 0.9112 - val_loss: 0.8747 - val_accuracy: 0.5849\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.2846 - accuracy: 0.9081 - val_loss: 0.8919 - val_accuracy: 0.5660\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.2945 - accuracy: 0.8988 - val_loss: 0.8782 - val_accuracy: 0.5849\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.2616 - accuracy: 0.9252 - val_loss: 0.8685 - val_accuracy: 0.5849\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.2789 - accuracy: 0.9097 - val_loss: 0.8935 - val_accuracy: 0.5472\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2712 - accuracy: 0.9237 - val_loss: 0.8948 - val_accuracy: 0.5283\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.2716 - accuracy: 0.9237 - val_loss: 0.8905 - val_accuracy: 0.5849\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2677 - accuracy: 0.9097 - val_loss: 0.9031 - val_accuracy: 0.5660\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2750 - accuracy: 0.9065 - val_loss: 0.8987 - val_accuracy: 0.5660\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.2703 - accuracy: 0.8988 - val_loss: 0.8867 - val_accuracy: 0.5849\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2559 - accuracy: 0.9128 - val_loss: 0.9130 - val_accuracy: 0.5849\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2560 - accuracy: 0.9174 - val_loss: 0.8940 - val_accuracy: 0.5849\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.2668 - accuracy: 0.9034 - val_loss: 0.9025 - val_accuracy: 0.5472\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.2820 - accuracy: 0.9003 - val_loss: 0.8589 - val_accuracy: 0.5472\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2627 - accuracy: 0.9003 - val_loss: 0.8937 - val_accuracy: 0.5660\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.2988 - accuracy: 0.8801 - val_loss: 0.9759 - val_accuracy: 0.5472\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.2922 - accuracy: 0.8925 - val_loss: 0.9188 - val_accuracy: 0.5660\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2859 - accuracy: 0.8832 - val_loss: 0.8578 - val_accuracy: 0.5849\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.2709 - accuracy: 0.9065 - val_loss: 0.8852 - val_accuracy: 0.5660\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2507 - accuracy: 0.9206 - val_loss: 0.8913 - val_accuracy: 0.5472\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.2474 - accuracy: 0.9299 - val_loss: 0.8873 - val_accuracy: 0.5472\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.2539 - accuracy: 0.9159 - val_loss: 0.8860 - val_accuracy: 0.5660\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2445 - accuracy: 0.9330 - val_loss: 0.9086 - val_accuracy: 0.5660\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2550 - accuracy: 0.9159 - val_loss: 0.9402 - val_accuracy: 0.5660\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2590 - accuracy: 0.9190 - val_loss: 0.9065 - val_accuracy: 0.5660\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2491 - accuracy: 0.9143 - val_loss: 0.9217 - val_accuracy: 0.5849\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2344 - accuracy: 0.9299 - val_loss: 0.9144 - val_accuracy: 0.5849\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2299 - accuracy: 0.9377 - val_loss: 0.9265 - val_accuracy: 0.5660\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2328 - accuracy: 0.9299 - val_loss: 0.9150 - val_accuracy: 0.5660\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2341 - accuracy: 0.9268 - val_loss: 0.9291 - val_accuracy: 0.5472\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.2267 - accuracy: 0.9330 - val_loss: 0.9283 - val_accuracy: 0.5849\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2413 - accuracy: 0.9299 - val_loss: 0.9162 - val_accuracy: 0.5849\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.2318 - accuracy: 0.9237 - val_loss: 0.9361 - val_accuracy: 0.5472\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2303 - accuracy: 0.9315 - val_loss: 0.9469 - val_accuracy: 0.5849\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.2378 - accuracy: 0.9299 - val_loss: 0.9502 - val_accuracy: 0.5849\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.2311 - accuracy: 0.9315 - val_loss: 0.9334 - val_accuracy: 0.5849\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2168 - accuracy: 0.9268 - val_loss: 0.9380 - val_accuracy: 0.5660\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2221 - accuracy: 0.9346 - val_loss: 0.9250 - val_accuracy: 0.5472\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.2207 - accuracy: 0.9315 - val_loss: 0.9545 - val_accuracy: 0.5849\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2207 - accuracy: 0.9268 - val_loss: 0.9442 - val_accuracy: 0.5660\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2291 - accuracy: 0.9330 - val_loss: 0.9753 - val_accuracy: 0.5660\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2186 - accuracy: 0.9268 - val_loss: 0.9341 - val_accuracy: 0.5660\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.2114 - accuracy: 0.9393 - val_loss: 0.9509 - val_accuracy: 0.5660\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.2174 - accuracy: 0.9268 - val_loss: 0.9477 - val_accuracy: 0.5849\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2035 - accuracy: 0.9330 - val_loss: 0.9641 - val_accuracy: 0.5660\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2042 - accuracy: 0.9330 - val_loss: 0.9689 - val_accuracy: 0.5849\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.2216 - accuracy: 0.9299 - val_loss: 0.9632 - val_accuracy: 0.5472\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2130 - accuracy: 0.9393 - val_loss: 0.9805 - val_accuracy: 0.5660\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2065 - accuracy: 0.9283 - val_loss: 0.9763 - val_accuracy: 0.5660\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2093 - accuracy: 0.9361 - val_loss: 0.9763 - val_accuracy: 0.5849\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.2124 - accuracy: 0.9361 - val_loss: 0.9808 - val_accuracy: 0.5472\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.2060 - accuracy: 0.9393 - val_loss: 0.9845 - val_accuracy: 0.5849\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2076 - accuracy: 0.9408 - val_loss: 0.9880 - val_accuracy: 0.6038\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2115 - accuracy: 0.9346 - val_loss: 1.0299 - val_accuracy: 0.5472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1946 - accuracy: 0.9393 - val_loss: 1.0073 - val_accuracy: 0.5660\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1980 - accuracy: 0.9346 - val_loss: 1.0222 - val_accuracy: 0.5472\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1954 - accuracy: 0.9377 - val_loss: 0.9930 - val_accuracy: 0.5472\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.2051 - accuracy: 0.9424 - val_loss: 1.0191 - val_accuracy: 0.5660\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1985 - accuracy: 0.9346 - val_loss: 1.0272 - val_accuracy: 0.5660\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1947 - accuracy: 0.9377 - val_loss: 1.0287 - val_accuracy: 0.5472\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1931 - accuracy: 0.9439 - val_loss: 0.9903 - val_accuracy: 0.5472\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1907 - accuracy: 0.9470 - val_loss: 1.0233 - val_accuracy: 0.5849\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1813 - accuracy: 0.9533 - val_loss: 1.0202 - val_accuracy: 0.5660\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1898 - accuracy: 0.9424 - val_loss: 1.0294 - val_accuracy: 0.5660\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1872 - accuracy: 0.9424 - val_loss: 1.0305 - val_accuracy: 0.5849\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.1738 - accuracy: 0.9533 - val_loss: 1.0063 - val_accuracy: 0.5660\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1864 - accuracy: 0.9502 - val_loss: 1.0211 - val_accuracy: 0.5472\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1718 - accuracy: 0.9517 - val_loss: 1.0570 - val_accuracy: 0.5472\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1891 - accuracy: 0.9237 - val_loss: 1.0118 - val_accuracy: 0.5660\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1844 - accuracy: 0.9330 - val_loss: 1.0184 - val_accuracy: 0.5283\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2007 - accuracy: 0.9361 - val_loss: 1.0036 - val_accuracy: 0.5849\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1732 - accuracy: 0.9470 - val_loss: 1.0204 - val_accuracy: 0.5472\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.1752 - accuracy: 0.9517 - val_loss: 1.0236 - val_accuracy: 0.5660\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.1737 - accuracy: 0.9502 - val_loss: 1.0357 - val_accuracy: 0.6038\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.1729 - accuracy: 0.9439 - val_loss: 1.0630 - val_accuracy: 0.5849\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1794 - accuracy: 0.9377 - val_loss: 1.0236 - val_accuracy: 0.5849\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.1631 - accuracy: 0.9502 - val_loss: 1.0095 - val_accuracy: 0.5660\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1750 - accuracy: 0.9455 - val_loss: 1.0154 - val_accuracy: 0.5660\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1626 - accuracy: 0.9595 - val_loss: 1.0431 - val_accuracy: 0.5849\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1739 - accuracy: 0.9346 - val_loss: 1.0519 - val_accuracy: 0.5472\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1672 - accuracy: 0.9502 - val_loss: 1.0748 - val_accuracy: 0.5660\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1615 - accuracy: 0.9486 - val_loss: 1.0156 - val_accuracy: 0.6038\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1590 - accuracy: 0.9502 - val_loss: 1.0362 - val_accuracy: 0.5849\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1671 - accuracy: 0.9424 - val_loss: 1.0655 - val_accuracy: 0.5849\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1645 - accuracy: 0.9470 - val_loss: 1.0476 - val_accuracy: 0.5849\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1615 - accuracy: 0.9502 - val_loss: 1.0864 - val_accuracy: 0.5849\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1625 - accuracy: 0.9517 - val_loss: 1.0996 - val_accuracy: 0.5283\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.1534 - accuracy: 0.9486 - val_loss: 1.0896 - val_accuracy: 0.5849\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1520 - accuracy: 0.9564 - val_loss: 1.1030 - val_accuracy: 0.5283\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1742 - accuracy: 0.9486 - val_loss: 1.1050 - val_accuracy: 0.5849\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1562 - accuracy: 0.9408 - val_loss: 1.0938 - val_accuracy: 0.5472\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1494 - accuracy: 0.9548 - val_loss: 1.0616 - val_accuracy: 0.5849\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1617 - accuracy: 0.9455 - val_loss: 1.0359 - val_accuracy: 0.5660\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1645 - accuracy: 0.9408 - val_loss: 1.0642 - val_accuracy: 0.5283\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1550 - accuracy: 0.9533 - val_loss: 1.0530 - val_accuracy: 0.5849\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1452 - accuracy: 0.9595 - val_loss: 1.0645 - val_accuracy: 0.5849\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1415 - accuracy: 0.9611 - val_loss: 1.0804 - val_accuracy: 0.5660\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1506 - accuracy: 0.9470 - val_loss: 1.0667 - val_accuracy: 0.6038\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1381 - accuracy: 0.9657 - val_loss: 1.1206 - val_accuracy: 0.5660\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1433 - accuracy: 0.9517 - val_loss: 1.1343 - val_accuracy: 0.5472\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1347 - accuracy: 0.9564 - val_loss: 1.0933 - val_accuracy: 0.5660\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1401 - accuracy: 0.9533 - val_loss: 1.1120 - val_accuracy: 0.5283\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1411 - accuracy: 0.9439 - val_loss: 1.0968 - val_accuracy: 0.5660\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1455 - accuracy: 0.9517 - val_loss: 1.1272 - val_accuracy: 0.5472\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1432 - accuracy: 0.9579 - val_loss: 1.1077 - val_accuracy: 0.5472\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1451 - accuracy: 0.9595 - val_loss: 1.1118 - val_accuracy: 0.5660\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1428 - accuracy: 0.9564 - val_loss: 1.1143 - val_accuracy: 0.5472\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1378 - accuracy: 0.9611 - val_loss: 1.1487 - val_accuracy: 0.5472\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1253 - accuracy: 0.9657 - val_loss: 1.1718 - val_accuracy: 0.5660\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1312 - accuracy: 0.9564 - val_loss: 1.1410 - val_accuracy: 0.5660\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1226 - accuracy: 0.9642 - val_loss: 1.1726 - val_accuracy: 0.5660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1431 - accuracy: 0.9517 - val_loss: 1.1473 - val_accuracy: 0.5849\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1271 - accuracy: 0.9548 - val_loss: 1.1594 - val_accuracy: 0.5660\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1273 - accuracy: 0.9611 - val_loss: 1.1370 - val_accuracy: 0.5660\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1195 - accuracy: 0.9688 - val_loss: 1.1438 - val_accuracy: 0.5660\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1345 - accuracy: 0.9579 - val_loss: 1.1365 - val_accuracy: 0.5472\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1298 - accuracy: 0.9626 - val_loss: 1.2190 - val_accuracy: 0.5094\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1332 - accuracy: 0.9595 - val_loss: 1.1985 - val_accuracy: 0.5660\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1189 - accuracy: 0.9704 - val_loss: 1.1706 - val_accuracy: 0.5660\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.1201 - accuracy: 0.9704 - val_loss: 1.1521 - val_accuracy: 0.5472\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1207 - accuracy: 0.9595 - val_loss: 1.1554 - val_accuracy: 0.5472\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1241 - accuracy: 0.9657 - val_loss: 1.0929 - val_accuracy: 0.5849\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1231 - accuracy: 0.9626 - val_loss: 1.1242 - val_accuracy: 0.5472\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1119 - accuracy: 0.9642 - val_loss: 1.1592 - val_accuracy: 0.5472\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1203 - accuracy: 0.9751 - val_loss: 1.1833 - val_accuracy: 0.5660\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1160 - accuracy: 0.9642 - val_loss: 1.1930 - val_accuracy: 0.5472\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1174 - accuracy: 0.9704 - val_loss: 1.1744 - val_accuracy: 0.5472\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1229 - accuracy: 0.9564 - val_loss: 1.1510 - val_accuracy: 0.5849\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1162 - accuracy: 0.9611 - val_loss: 1.1700 - val_accuracy: 0.5094\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1107 - accuracy: 0.9657 - val_loss: 1.1736 - val_accuracy: 0.5283\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1067 - accuracy: 0.9720 - val_loss: 1.1954 - val_accuracy: 0.5660\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1161 - accuracy: 0.9595 - val_loss: 1.2171 - val_accuracy: 0.5283\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1063 - accuracy: 0.9735 - val_loss: 1.2301 - val_accuracy: 0.5094\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1155 - accuracy: 0.9704 - val_loss: 1.2011 - val_accuracy: 0.5660\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1067 - accuracy: 0.9720 - val_loss: 1.2225 - val_accuracy: 0.5472\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1508 - accuracy: 0.9455 - val_loss: 1.2208 - val_accuracy: 0.5660\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1198 - accuracy: 0.9626 - val_loss: 1.2314 - val_accuracy: 0.4717\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1030 - accuracy: 0.9735 - val_loss: 1.2782 - val_accuracy: 0.5283\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1024 - accuracy: 0.9673 - val_loss: 1.2556 - val_accuracy: 0.5472\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1040 - accuracy: 0.9766 - val_loss: 1.2603 - val_accuracy: 0.5283\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1062 - accuracy: 0.9704 - val_loss: 1.2710 - val_accuracy: 0.5472\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1048 - accuracy: 0.9751 - val_loss: 1.2091 - val_accuracy: 0.5094\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1209 - accuracy: 0.9657 - val_loss: 1.2042 - val_accuracy: 0.5283\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1136 - accuracy: 0.9642 - val_loss: 1.2018 - val_accuracy: 0.5472\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1074 - accuracy: 0.9720 - val_loss: 1.2428 - val_accuracy: 0.5472\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0998 - accuracy: 0.9766 - val_loss: 1.2038 - val_accuracy: 0.5472\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1000 - accuracy: 0.9782 - val_loss: 1.2101 - val_accuracy: 0.5660\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1052 - accuracy: 0.9657 - val_loss: 1.2724 - val_accuracy: 0.5472\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1024 - accuracy: 0.9735 - val_loss: 1.2521 - val_accuracy: 0.5472\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0921 - accuracy: 0.9751 - val_loss: 1.2522 - val_accuracy: 0.5472\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0934 - accuracy: 0.9782 - val_loss: 1.2650 - val_accuracy: 0.5472\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0983 - accuracy: 0.9735 - val_loss: 1.2950 - val_accuracy: 0.5472\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0873 - accuracy: 0.9813 - val_loss: 1.2701 - val_accuracy: 0.5283\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1080 - accuracy: 0.9735 - val_loss: 1.2866 - val_accuracy: 0.5283\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0946 - accuracy: 0.9766 - val_loss: 1.2560 - val_accuracy: 0.5283\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0942 - accuracy: 0.9782 - val_loss: 1.3122 - val_accuracy: 0.5094\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0942 - accuracy: 0.9766 - val_loss: 1.2810 - val_accuracy: 0.5472\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0947 - accuracy: 0.9720 - val_loss: 1.2856 - val_accuracy: 0.5094\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0988 - accuracy: 0.9688 - val_loss: 1.3101 - val_accuracy: 0.5472\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0886 - accuracy: 0.9813 - val_loss: 1.3071 - val_accuracy: 0.5472\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0916 - accuracy: 0.9782 - val_loss: 1.3426 - val_accuracy: 0.5094\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0798 - accuracy: 0.9829 - val_loss: 1.3084 - val_accuracy: 0.5094\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0955 - accuracy: 0.9782 - val_loss: 1.3160 - val_accuracy: 0.5283\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0845 - accuracy: 0.9766 - val_loss: 1.3016 - val_accuracy: 0.5283\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0845 - accuracy: 0.9751 - val_loss: 1.3084 - val_accuracy: 0.5094\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0928 - accuracy: 0.9751 - val_loss: 1.3454 - val_accuracy: 0.5283\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0866 - accuracy: 0.9798 - val_loss: 1.4212 - val_accuracy: 0.5094\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0849 - accuracy: 0.9829 - val_loss: 1.3722 - val_accuracy: 0.5283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1004 - accuracy: 0.9673 - val_loss: 1.3171 - val_accuracy: 0.4906\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0809 - accuracy: 0.9829 - val_loss: 1.2873 - val_accuracy: 0.5094\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0782 - accuracy: 0.9829 - val_loss: 1.3586 - val_accuracy: 0.5094\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0840 - accuracy: 0.9782 - val_loss: 1.3049 - val_accuracy: 0.5283\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0725 - accuracy: 0.9875 - val_loss: 1.3203 - val_accuracy: 0.5283\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0758 - accuracy: 0.9844 - val_loss: 1.3707 - val_accuracy: 0.5283\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.0972 - accuracy: 0.9720 - val_loss: 1.3513 - val_accuracy: 0.5660\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0817 - accuracy: 0.9766 - val_loss: 1.4104 - val_accuracy: 0.5094\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0860 - accuracy: 0.9720 - val_loss: 1.3507 - val_accuracy: 0.5283\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0784 - accuracy: 0.9766 - val_loss: 1.3700 - val_accuracy: 0.5283\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0753 - accuracy: 0.9829 - val_loss: 1.3561 - val_accuracy: 0.5283\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0763 - accuracy: 0.9829 - val_loss: 1.4071 - val_accuracy: 0.5283\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0878 - accuracy: 0.9844 - val_loss: 1.4145 - val_accuracy: 0.4906\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0720 - accuracy: 0.9860 - val_loss: 1.3468 - val_accuracy: 0.5094\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0769 - accuracy: 0.9844 - val_loss: 1.3678 - val_accuracy: 0.5094\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0755 - accuracy: 0.9860 - val_loss: 1.3423 - val_accuracy: 0.4906\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0736 - accuracy: 0.9844 - val_loss: 1.3980 - val_accuracy: 0.4717\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0719 - accuracy: 0.9860 - val_loss: 1.3580 - val_accuracy: 0.4906\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0793 - accuracy: 0.9798 - val_loss: 1.3939 - val_accuracy: 0.4528\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0814 - accuracy: 0.9813 - val_loss: 1.3498 - val_accuracy: 0.5094\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0799 - accuracy: 0.9751 - val_loss: 1.4249 - val_accuracy: 0.4906\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0730 - accuracy: 0.9844 - val_loss: 1.3882 - val_accuracy: 0.4906\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0736 - accuracy: 0.9813 - val_loss: 1.4394 - val_accuracy: 0.4528\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0751 - accuracy: 0.9798 - val_loss: 1.3828 - val_accuracy: 0.5472\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0763 - accuracy: 0.9844 - val_loss: 1.3388 - val_accuracy: 0.5472\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0746 - accuracy: 0.9844 - val_loss: 1.3388 - val_accuracy: 0.5472\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0687 - accuracy: 0.9829 - val_loss: 1.3463 - val_accuracy: 0.5283\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0657 - accuracy: 0.9875 - val_loss: 1.3873 - val_accuracy: 0.4906\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0633 - accuracy: 0.9938 - val_loss: 1.3864 - val_accuracy: 0.5283\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0639 - accuracy: 0.9875 - val_loss: 1.3936 - val_accuracy: 0.5283\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0676 - accuracy: 0.9875 - val_loss: 1.3931 - val_accuracy: 0.5094\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0668 - accuracy: 0.9844 - val_loss: 1.4162 - val_accuracy: 0.5094\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0591 - accuracy: 0.9907 - val_loss: 1.4800 - val_accuracy: 0.5283\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0722 - accuracy: 0.9751 - val_loss: 1.4229 - val_accuracy: 0.5094\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0568 - accuracy: 0.9891 - val_loss: 1.3888 - val_accuracy: 0.5094\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0616 - accuracy: 0.9891 - val_loss: 1.3876 - val_accuracy: 0.5660\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0651 - accuracy: 0.9766 - val_loss: 1.4426 - val_accuracy: 0.4717\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0571 - accuracy: 0.9891 - val_loss: 1.4491 - val_accuracy: 0.5094\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0709 - accuracy: 0.9798 - val_loss: 1.4571 - val_accuracy: 0.4906\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0582 - accuracy: 0.9860 - val_loss: 1.4429 - val_accuracy: 0.5283\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0708 - accuracy: 0.9798 - val_loss: 1.4986 - val_accuracy: 0.5472\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0593 - accuracy: 0.9907 - val_loss: 1.4067 - val_accuracy: 0.5660\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0632 - accuracy: 0.9844 - val_loss: 1.4655 - val_accuracy: 0.5094\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0786 - accuracy: 0.9766 - val_loss: 1.4903 - val_accuracy: 0.5283\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0655 - accuracy: 0.9798 - val_loss: 1.4655 - val_accuracy: 0.4717\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0556 - accuracy: 0.9891 - val_loss: 1.5183 - val_accuracy: 0.5094\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0688 - accuracy: 0.9829 - val_loss: 1.4507 - val_accuracy: 0.5094\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0565 - accuracy: 0.9860 - val_loss: 1.4298 - val_accuracy: 0.5094\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0609 - accuracy: 0.9907 - val_loss: 1.4665 - val_accuracy: 0.5094\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0660 - accuracy: 0.9860 - val_loss: 1.5401 - val_accuracy: 0.4906\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0548 - accuracy: 0.9907 - val_loss: 1.5248 - val_accuracy: 0.4717\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0674 - accuracy: 0.9813 - val_loss: 1.4439 - val_accuracy: 0.5472\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0586 - accuracy: 0.9860 - val_loss: 1.5490 - val_accuracy: 0.4906\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0669 - accuracy: 0.9798 - val_loss: 1.5525 - val_accuracy: 0.5283\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0618 - accuracy: 0.9860 - val_loss: 1.4748 - val_accuracy: 0.4906\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0502 - accuracy: 0.9969 - val_loss: 1.4686 - val_accuracy: 0.5283\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0547 - accuracy: 0.9891 - val_loss: 1.5004 - val_accuracy: 0.5094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0642 - accuracy: 0.9813 - val_loss: 1.5235 - val_accuracy: 0.5283\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0559 - accuracy: 0.9891 - val_loss: 1.5831 - val_accuracy: 0.5094\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0557 - accuracy: 0.9875 - val_loss: 1.5050 - val_accuracy: 0.5094\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0634 - accuracy: 0.9829 - val_loss: 1.4847 - val_accuracy: 0.5094\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0484 - accuracy: 0.9922 - val_loss: 1.4561 - val_accuracy: 0.5660\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0574 - accuracy: 0.9891 - val_loss: 1.5267 - val_accuracy: 0.4717\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0503 - accuracy: 0.9891 - val_loss: 1.5361 - val_accuracy: 0.5094\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0515 - accuracy: 0.9922 - val_loss: 1.6085 - val_accuracy: 0.5283\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0458 - accuracy: 0.9938 - val_loss: 1.5406 - val_accuracy: 0.4906\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0494 - accuracy: 0.9907 - val_loss: 1.5605 - val_accuracy: 0.5283\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0488 - accuracy: 0.9907 - val_loss: 1.5333 - val_accuracy: 0.5094\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0497 - accuracy: 0.9907 - val_loss: 1.5510 - val_accuracy: 0.5094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8971aae580>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_121.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_121.fit(X_train_over, y_train_over, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "32ad4696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6144 - accuracy: 0.6780\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6212 - accuracy: 0.7358\n"
     ]
    }
   ],
   "source": [
    "m2_eval_test = model_121.evaluate(X_test, y_test)\n",
    "m2_eval_val = model_121.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ed5a7",
   "metadata": {},
   "source": [
    "**For test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f46eef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n",
      "roc auc score:  0.7142857142857143\n",
      "average precision score:  0.7237810007446486\n"
     ]
    }
   ],
   "source": [
    "pred = model_121.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b319044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "74697eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6144 - accuracy: 0.6780\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m2_eval_test = model_121.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978b5da2",
   "metadata": {},
   "source": [
    "**For validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "384a772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "roc auc score:  0.7142857142857143\n",
      "average precision score:  0.6850876298984225\n"
     ]
    }
   ],
   "source": [
    "pred = model_121.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb4869b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4d2bddbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6212 - accuracy: 0.7358\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAFACAYAAAChlvevAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAwwElEQVR4nO3dd5xcVd3H8c93N5WQ0BICoYOABCQBAUGkFzEivT4oRTSgIlUFhEdA9HmwgFKkBKmKoTx0iRCkBZASSoCQBIghSggdIQkESMLv+eOeJcMyszuzmbs7N/m+87qvzG3nnJ2d/c255557jiICMzMrrqauLoCZmS0YB3Izs4JzIDczKzgHcjOzgnMgNzMrOAdyM7OCcyCvI0mnSvpzV5cjD5J2l/SSpFmSNliAdJ6VtHX9Stb5JG0h6bmc85glafU29k+VtH2VaR0s6YEqj+3wZ3hh/vw3ukUykEv6iqR/SHpX0tuSHpS0cVeXa0FJWl7SJZJekTRT0iRJp0nqU4fkfwscERGLR8STHU0kItaNiHvrUJ5PkXSvpJA0pNX2m9L2ratMJyR9rq1jIuL+iFi746VtX3qfp6QyXS7pF3nmZ8W2yAVySf2AvwLnAksDKwCnAR92Zblak9Rc4/FLAw8BvYHNIqIvsAOwJLBGHYq0CvBsHdLJ0/PAgS0rkpYBNgXeqFcGkrrVKy2zelnkAjmwFkBEjIyIeRExOyJGR8TTLQdI+rakiZL+I+kOSauU7Ds7NTHMkPS4pC1apd9L0jWpRvxEaQ1R0jqp5vhOamLYpWTf5ZIukDRK0nvANuny+UeSnk5XD9dI6lXh5zoWmAl8MyKmpp/xpYg4quVnk/RlSWNTWmMlfbkk/3slnZ6uTmZKGi2pv6SekmYBzcBTkv6Zjv9UzbW01pjO+2v6Od+WdL+kprTvkyaBlPbvJU1Py+8l9Uz7tpY0TdJxkl5PVxmHtPO7vQrYt+RLcH/gRuCjknJuIumhVLZXJJ0nqUfaNyYd9lRq2ti3pBzHS3oVuKxlWzpnjfQzbpjWB0l6s9wVgKRDJN1asj5Z0rUl6y9JGlr6/koaDhwA/CSV6daSJIdW+dloXY4F+QwPknS9pDckvSjpyAp59JL0Z0lvpfd6rKSB1ZTParcoBvLngXmSrpD0NUlLle6UtBvwU2APYABwPzCy5JCxwFCy2vxfgOta/QHtClxXsv8mSd0ldQduBUYDywI/BK6SVHqJ/l/AL4G+QEub5j7ATsBqwPrAwRV+ru2BGyLi43I7ldXYbwPOAZYBzgJuU1ZrLc3/kFS+HsCPIuLDiFg87R8SEdXU7o8DppG9fwPJ3s9yY0GcRFZjHgoMATYBTi7ZvxywBNlV06HAH1r/vlqZDkwAdkzrBwJXtjpmHnAM0B/YDNgO+D5ARGyZjhmSmjauKSnH0mRXJcNLE4uIfwLHk/0uFwMuAy6v0Hx0H7CFpCZJywPdgc0BlLWHLw48XXpCRIwg+4L6dSrTN0p2V/vZaK2jn+Emss/wU2S/k+2AoyV9tUweB5H97lYi+7wdDsyusnxWo0UukEfEDOArZIHlYuANSbeU1BYOA/43IiZGxFzgf8hqPquk8/8cEW9FxNyIOBPoCZQG48cj4v8iYg5ZsOxFFqw2JftDPSMiPoqIu8maePYvOffmiHgwIj6OiA/StnMiYnpEvE32RzS0wo+2DPBKGz/614EXIuJPqewjgUlAaWC4LCKej4jZwLVt5NWeOcDywCoRMSe1KZcL5AcAP4+I1yPiDbImrm+1SufnKY1RwCw+/V6XcyVwYPqCXDIiHirdGRGPR8TD6T2YClwEbNVOmh8Dp6Qvtc8Eo4i4GHgBeCT93CeVSyS1ec8ke1+3Au4AXpb0+bR+f6Uv4gqq/Wy0LkdHP8MbAwMi4ufpMzyF7G9ovzLZzCH7TH4uXfk+nv72LAeLXCAHSEH64IhYEVgPGAT8Pu1eBTg7XQ6+A7wNiKwGQrrUn5guZ98hq3X0L0n+pZJ8PiarmQ5Ky0ut/lD/1ZJu63NLvFry+n2yL4Ny3iILIpUMSvmVap1/tXm15zfAZGC0pCmSTqiyTP9K21q8lb5MaynTDcC2ZFc8f2q9U9JaqdnnVUkzyL6o+7c+rpU3Sr5YK7mY7LN0bkS0db/lPmBrYMv0+l6yIL5VWq9Fh35fC/AZXgUY1PK3kc79KdlVV2t/Ivuiujo1m/06XZVaDhbJQF4qIiYBl5P9EUL2IT4sIpYsWXpHxD9SW+LxZJe0S0XEksC7ZIG+xUotL9Kl6Ipkl/zTgZVa2oqTlYGXS4uzAD/K34HdW6VfajrZH2Kp1vnX4n1gsZL15VpeRMTMiDguIlYnq/EfK2m7Ksq0ctrWYRHxPvA34HuUCeTABWRXImtGRD+yQKQyx30q2bZ2SlqcrCJwCXBqasaqpCWQb5Fe30f7gbxuQ5Qu4Gf4JeDFVn8bfSNi2GcKnF1FnRYRg4EvAztTciPa6muRC+SSPp9qJCum9ZXImjceTodcCJwoad20fwlJe6d9fYG5ZL0gukn6GdCvVRZflLSHst4NR5P1hnmY7LL7PbKbVt3TzbBvAFfX6Uc7K5XlipZmIEkrSDpL0vrAKGAtSf8lqZukfYHBZM07HTEO+C9JzZJ2oqR5QtLO6UadgBlk7dLzyqQxEjhZ0gBJ/YGfAfXoh/xTYKuWm76t9E1lmpWaNL7Xav9rQMX+2xWcTdYc8R2y+xAXtnHsfcA2QO+ImEZ2D2YnsmaISt06O1KmShbkM/woMEPZjd/e6Xe/nsp03ZW0jaQvKLvxPIOsqaXcZ8DqYJEL5GRtlF8CHlHWO+RhYDzZDToi4kbgV2SXhDPSvq+lc+8gq+09T9YM8AGfbQ65GdgX+A9Ze+8eqXbyEbBLSutN4HzgwHRFsMBSO+mXyf5gHpE0E7iLrLY1OSLeIqsVHUfWDPMTYOeIeLODWR5F9kX0Dllb900l+9Yku0KYRdYl8vwKN/9+ATxGdoPvGeCJtG2BpHbjSg/A/Ijspu5MsuaQa1rtP5Xsy/AdSfu0l5ekXckC8eFp07HAhpIOqFC258nel/vT+gxgCvBgRFQKdJcAg1OZbmqvTO1YkM/wPLLf+VDgRbLP8R/JmmZaWw74P7IgPpHsC8wPC+VE5e9BmZlZUSyKNXIzs4WKA7mZWcE5kJuZFZwDuZlZwTmQm5kVnAO5mVnBOZCbmRWcA7mZWcE5kJuZFZwDuZlZwTmQm5kVnAO5mVnBOZCbmRWcA7mZWcE5kJuZFZwDuZlZwTmQm5kVnAO5mVnBOZCbmRWcA7mZWcE5kJuZFZwDuZlZwTmQm5kVnAO5mVnBOZCbmRWcA7mZWcE5kJuZFZwDuZlZwTmQm5kVnAO5mVnBOZCbmRWcA7mZWcE5kJuZFZwDuZlZwTmQm5kVXLeuLkAlvTc4Irq6DNZ4Jt9zVlcXwRrQCkv20IKmUUvMmf3keQucXz01bCA3M+tUTc1dXYIOcyA3MwNQcVuaHcjNzADUUK0lNXEgNzMD18jNzArPNXIzs4JzjdzMrODca8XMrODctGJmVnBuWjEzKzjXyM3MCs41cjOzgnMgNzMruGb3WjEzKza3kZuZFZybVszMCq7ANfLifgWZmdWTmqpf2kpGWknSPZImSnpW0lFp+6mSXpY0Li3DKpy/k6TnJE2WdEI1Rc+tRi6pCdg0Iv6RVx5mZnVTv0f05wLHRcQTkvoCj0u6M+37XUT8ttKJkpqBPwA7ANOAsZJuiYgJbWWYW408Ij4GzswrfTOzupKqX9oQEa9ExBPp9UxgIrBClaXYBJgcEVMi4iPgamDX9k7Ku2lltKQ9pQI3PpnZoqGGphVJwyU9VrIML5uktCqwAfBI2nSEpKclXSppqTKnrAC8VLI+jSq+BPK+2Xks0AeYJ2k2ICAiol/O+ZqZ1aaG+mZEjABGtJ2cFgeuB46OiBmSLgBOByL9fybw7danlcuuvfLkGsgjom+e6ZuZ1U0dux9K6k4WxK+KiBsAIuK1kv0XA38tc+o0YKWS9RWB6e3ll3v3Q0m7AFum1Xsjolzhzcy6Vp0CeWpKvgSYGBFnlWxfPiJeSau7A+PLnD4WWFPSasDLwH7Af7WXZ66BXNIZwMbAVWnTUZK+EhFVdakxM+s09eu1sjnwLeAZSePStp8C+0saStZUMhU4DEDSIOCPETEsIuZKOgK4A2gGLo2IZ9vLMO8a+TBgaOrBgqQrgCcBB3Izayx16pMREQ9Qvq17VIXjp5PFypb1UZWOraQznuxcEng7vV6iE/IzM6udH9Gv6H+BJyXdQ/YNtSVwYs55mpnVrsC9pPPutTJS0r1k7eQCjo+IV/PM08ysI4r8uEuu1xKSNgdmRMQtQF/gJ5JWyTNPM7OOUJOqXhpN3o1CFwDvSxoC/Bj4F3BlznmamdVMUtVLo8k7kM+NiCAbK+CciDibrGZuZtZQihzI877ZOVPSicA3gS3TyF7dc87TzKxmjRigq5V3jXxf4EPg0HSTcwXgNznnaWZWM9fIK5sJnB0R8yStBXweGJlznmZmtWu8+Fy1vGvkY4CeklYA7gIOAS7POU8zs5o1NTVVvTSavEukiHgf2AM4NyJ2B9bNOU8zs5q5aaUySdoMOAA4NG2r28g0Zmb10ogBulp5B/KjyR7JvzEinpW0OnBPznmamdWuuHE890f07wPuk9QnrU8BjswzTzOzjihyjTzvR/Q3kzSBbPJRJA2RdH6eeZqZdUSR28jzvtn5e+CrwFsAEfEU82cLMjNrGEUeayX38cgj4qVW32Dz8s7TzKxWjVjTrlbegfwlSV8GQlIPsvbxiTnnaWZWs3oFckkrkQ0OuBzwMTAiIs6W9BvgG8BHwD+BQyLinTLnTyV7mHIe2XhVG7WXZ95NK4cDPyB7NH8aMDStm5k1lDq2kc8FjouIdYBNgR9IGgzcCawXEesDz9P2JDvbRMTQaoI45FgjTwNk/T4iDsgrDzOzeqlXjTwiXgFeSa9nSpoIrBARo0sOexjYqy4ZkmONPCLmAQNSk4qZWUOr5WanpOGSHitZhpdNU1oV2AB4pNWubwN/q1CUAEZLerxSuq3l3UY+FXhQ0i3Aey0bI+KsnPM1M6tJLTXyiBgBjGgnvcWB64GjI2JGyfaTyJpfrqpw6uYRMV3SssCdkiZFxJi28so7kE9PSxOeUMLMGlg9e61I6k4WxK+KiBtKth8E7Axslybd+YyImJ7+f13SjcAmZAMQVpT3k52n5Zm+mVnd1CmOK/tGuASYWNr6IGkn4HhgqzSYYLlz+wBNqW29D7Aj8PP28sw1kEu6lay9p9S7wGPARRHxQZ75F9GKA5fkj6cfyMBl+vFxBJde/yB/GHkvfzrjENZcdSAAS/btzTszZ7Ppfmd0cWmtq1w38kpG3XwDklhtjTU5/r9Pp0fPnl1drEKrY418c+BbwDOSxqVtPwXOAXqSNZcAPBwRh0saBPwxIoYBA4Eb0/5uwF8i4vb2Msy7aWUKMID5k0nsC7wGrAVcTPbDWom58z7mhLNuYNykaSy+WE/+8ZfjueuRSXzrhMs+OeaMY3fn3Vmzu7CU1pXeeP01brzmL1x29U307NWL0356HHff+Td22nm3ri5aodWx18oDlK/fj6pw/HRgWHo9BRhSa555B/INIqL0kfxbJY2JiC0lPZtz3oX06pszePXN7L7IrPc/ZNKLrzJowJJMmvLqJ8fsucOG7HTYOV1VRGsA8+bN5cMPP6Rbt258+MEHLNN/2a4uUuE14oQR1co7kA+QtHJE/BtA0spA/7Tvo5zzLryVl1+aoWuvyNjxUz/ZtvmGa/Da2zP557/f6LqCWZcasOxA9jngYPbbdQd69uzFRl/ajI03/XJXF6v4ivuEfu5Pdh4HPCDpHkn3AvcDP06N+Fe0Pri0b+bcNxftCnuf3j0Y+dvv8OPfXs/M9+bfSthnp4247vbHurBk1tVmzniXB8fcw19uvJ3rbruLD2bP5s6/3drVxSo8j35YQUSMAtYkm2DiaGDtiLgtIt6LiN+XOX5ERGwUERt167/ozgjXrVsTI3/7Xa7522PcfPdTn2xvbm5i122H8H93PNGFpbOu9vjYh1l+0AosudTSdOvWnS222Z5nn3mq/ROtTUUO5Hn3WukOHMb8oWvvlXRRRMzJM9+iu/CUA3juxVc55893f2r7tl9am+envsbLr7/TNQWzhjBw4PJMGP80H3wwm549e/HE2EdYa53BXV2swmvA+Fy1vNvILwC6Ay2TSXwrbftOzvkW1peHrs4BO3+JZ55/mYevPgGAU867hTsemMDeX/0i197+eBeX0LraOuutz1bb7sBhB+5Dc3M3PrfW59l5t727uliF14g17WqpwsNF9UlceioihrS3rZzeGxyRX8GssCbf49Ed7LNWWLLHAkfhtY+/o+qY89yvvtpQUT/vm53zJK3RspImX/bEEmbWcKTql0aTd9PKj4B7JE0h69yzCnBIznmamdWsqQGncKtW3uORDyHrtbI2WSCfFBEf5pWnmVlHNWJNu1p5j0e+S0R8GBFPR8RTDuJm1qjc/bCyf0g6D7iGT49H7o7QZtZQ3LRSWctzw6XDMAawbc75mpnVpBFr2tXKO5DvHRFv5pyHmdkCK3Acz6eNXNI3JL0BPC1pmiSP6GNmDa3IbeR53ez8JbBFRAwC9gT+N6d8zMzqwv3IP2tuREwCiIhHJHm+TjNraI1Y065WXoF8WUnHVlovncfOzKwR1KvXiqSVgCuB5YCPgRERcbakpcl68K0KTAX2iYj/lDl/J+BsoJlsCrh253TMq2nlYqBvydJ63cysodSxaWUucFxErANsCvxA0mDgBOCuiFgTuCuttyqDmoE/AF8DBgP7p3PblEuNPCJOyyNdM7O81HHOzleAV9LrmZImAisAuwJbp8OuAO4Fjm91+ibA5DR3J5KuTudNaCvPTpukTpIfAjKzhlVLjbx0NrO0DC+fplYFNgAeAQamIN8S7MtNtLoC8FLJ+rS0rU159yMvVdw7CWa20KulRh4RI4AR7aS3OHA9cHREzKgy/XIHtTu8bmdOG31bJ+ZlZlaTenY/TLOjXQ9cFRE3pM2vSVo+7V8eeL3MqdOAlUrWVwSmt5dfpwXyiDi5s/IyM6tVU5OqXtqirOp9CTCxVQ+9W4CD0uuDgJvLnD4WWFPSapJ6APul89ouexU/X4dJ2kPSC5LelTRD0kxJM/LM08ysI+r4ZOfmZNNabitpXFqGAWcAO0h6AdghrSNpkKRRABExFzgCuAOYCFwbEc+2l2HebeS/Br4RERNzzsfMbIHUsdfKA1S+J7hdmeOnA8NK1kcBo2rJs90auaRfS+onqbukuyS9KembVab/moO4mRXBwv6I/o4R8RNJu5M1xO8N3AP8uYpzH5N0DXAT8MmkEiWN/2ZmDWFhf0S/e/p/GDAyIt6u4QfuB7wP7FiyLQAHcjNrKAv7xBK3SpoEzAa+L2kA8EE1iUeEJ1o2s0IocIW8/TbyiDgB2AzYKCLmkNWwd60mcUkrSrpR0uuSXpN0vaQVF6zIZmb11yRVvTSaam52Lgb8ALggbRoEbFRl+peR9YEcRPaY6a1pm5lZQynyzc5q+pFfBnzE/Pk3pwG/qDL9ARFxWUTMTcvlwIDai2lmlq+FfYagNSLi18AcgIiYTfXjprwp6ZuSmtPyTeCtDpbVzCw3Tap+aTTVBPKPJPUmDdwiaQ1KuhK249vAPsCrZMM67pW2mZk1lHo9ot8Vqum1cgpwO7CSpKvIHj89uJrEI+LfwC4dLp2ZWSdRgQdobTeQR8SdaSzxTcmaVI6KiDfbOkfSz9pOMk6vrZhmZvlqwIp21doN5JK2TC9npv8HSyIixrRx2ntltvUBDgWWARzIzayhNOJNzGpV07Ty45LXvcimInoc2LbSCRFxZstrSX2Bo4BDgKuBMyudZ2bWVQocx6tqWvlG6XqaIfrX7Z2XZow+FjiAbH66DcvNGG1m1giaC9y20pFhbKcB67V1gKTfAHuQTYX0hYiY1YF8zMw6zULdtCLpXObPGdcEDAWeaue048i6KJ4MnFTyBonsZme/jhTWzCwvBY7jVdXIHyt5PZdsBMQH2zohIjpzLlAzswXWiGOoVKuaNvIrOqMgZmZdqZ5hXNKlwM7A6xGxXtp2DbB2OmRJ4J2IGFrm3KlkvQTnAXMjot2xrSoGcknPML9J5VO7yJpH1m8vcTOzoqhzG/nlwHnAlS0bImLfkrzOBN5t4/xt2ntep1RbNfKdq03EzKzo6tlrJSLGSFq13D5l3xj70EYX7lpVDOQR8a96ZWJm1uhqqZBLGg4ML9k0IiJGVHn6FmTzGb9QYX8AoyUFcFE16VbTa2VT4FxgHaAH0Ay8554nZrYwqaVpJQXXagN3a/sDI9vYv3lETJe0LHCnpEntPElf1eiH56WMXwB6A98hC+xmZguNzhjGVlI3smdsrql0TERMT/+/DtxI9jR922WvJvOImAw0R8S8iLgM2Kaa88zMiqKTJpbYHpgUEdMqlKFPGtYESX3IJq4f316i1QTy9yX1AMZJ+rWkY8gGwDIzW2iohqXdtKSRwEPA2pKmSTo07dqPVs0qkgZJGpVWBwIPSHoKeBS4LSJuby+/trofbhQRjwHfIgv4RwDHACsBe1bxs5iZFUade63sX2H7wWW2TQeGpddTgCG15tfWzc6LJS1O9u1xdURMAE6rNQMzsyIo8lgrFZtWImIDsr7k84D/kzRO0vGSVum00pmZdRKp+qXRtNlGHhHPRcRpETEYOIjssdK7JbU51oqZWdE0SVUvjaaqYWwlNQHLkjXE9wHeyLNQZmadrQHjc9XaDOSStiDrQ74bWReYq4FjIqKtMQLq4j9jz8s7Cyug+1+oevgJW4SssGT/BU6jucCRvK1eKy8B/yYL3qdFxGudViozs05W5JudbdXIv+LxVsxsUVHgmd48aJaZGSykgdzMbFGysDatmJktMhbKGnmrSZc/IyKOzKVEZmZdoJ6P6He2tmrkj7Wxz8xsoVLkGePbutnpSZfNbJFR4CbyqmYIGgAcDwwGerVsj4i6zTdnZtbVGvHR+2pVczVxFTARWI1s9MOpwNgcy2Rm1ukW2kGzkmUi4hJgTkTcFxHfBjbNuVxmZp2qM6Z6y0s1gXxO+v8VSV+XtAGwYo5lMjPrdM1Nqnppj6RLJb0uaXzJtlMlvZyGBB8naViFc3eS9JykyZJOqKbs1fQj/4WkJYDjyCZd7kc2U5CZ2UKjzjXty8kmrr+y1fbfRcRvK50kqRn4A7ADMA0YK+mWNLFPRe0G8oj4a3r5Lp502cwWUqpqNs7qRMQYSat24NRNgMlpyjckXQ3sCixYIJd0GWUeDEpt5WZmC4VOavs+QtKBZM/pHBcR/2m1fwXgpZL1acCX2ku0mjbyvwK3peUusqaVWdWU2MysKGq52SlpuKTHSpbhVWRxAbAGMBR4BTizzDHlvk4qPmHfopqmles/lYs0Evh7e+eZmRVJLY/oR8QIYEQt6ZfO6SDpYrJKcmvTgJVK1lcEpreXdkeeSl0TWLkD55mZNay8+5FLWr5kdXeyWddaGwusKWk1ST2A/YBb2ku7mjbymXy6av8q2ZOeZmYLjXo+2ZlaLrYG+kuaBpwCbC1pKFk8nQoclo4dBPwxIoZFxFxJRwB3AM3ApRHxbHv5VdO00rdjP4qZWXHU82ZnROxfZvMlFY6dDgwrWR8FjKolv3abViTdVc02M7MiK/Ij+m2NR94LWIzs0mAp5t9N7QcM6oSymZl1mqY69iPvbG01rRwGHE0WtB9nfiCfQfbkkZnZQqO5wAOStzUe+dnA2ZJ+GBHndmKZzMw63cI+jO3HkpZsWZG0lKTv51ckM7POV+Q28moC+Xcj4p2WlfRI6XdzK5GZWRdokqpeGk01ox82SVJEBHwyOlePfItlZta5GjA+V62aQH4HcK2kC8k6sh8O3J5rqczMOlmB73VWFciPB4YD3yPruTIauDjPQpmZdbZGbDKpVrtfQhHxcURcGBF7RcSewLNkE0yYmS00itxGXtXVhKShkn4laSpwOjCpinOaJf15ActnZtYpVMPSaNp6snMtspG39gfeAq4BFBFVzRIUEfMkDZDUIyI+qktpzcxy0oAV7aq11UY+Cbgf+EZETAaQVOtcnVOBByXdArzXsjEizqoxHTOzXKnAkbytQL4nWY38Hkm3A1dT+1XF9LQ0AR5F0cwaVvPCGMgj4kbgRkl9gN2AY4CBki4AboyI0e0lHhGnAUjqm62Gp4gzs4ZU3DBeXa+V9yLiqojYmWzaoXHACdUkLmk9SU+SzYTxrKTHJa27IAU2M8uDpKqXRlNTH/iIeDsiLoqIbas8ZQRwbESsEhGrAMfhPuhm1oCaalgaTd5l6hMR97SsRMS9QJ+c8zQzq1k9a+SSLpX0uqTxJdt+I2mSpKcl3Vg6GGGrc6dKekbSOEmPVVP2vAP5FEn/LWnVtJwMvJhznmZmNatzP/LLgZ1abbsTWC8i1geeB05s4/xtImJoRGxUTWZ5B/JvAwOAG4Abgf7AITnnaWZWs2ap6qU9ETEGeLvVttERMTetPkx2z7EuqhlrpcPSkLdHwiejJvaJiBl55mlm1hGdfA/z22QPWZYTwGhJAVwUESPaSyzXGrmkv0jql7owPgs8J+nHeeZpZtYRquWfNFzSYyXL8KrzkU4C5gJXVThk84jYEPga8ANJW7aXZt5NK4NTDXw3YBSwMvCtnPM0M6tZLTMERcSIiNioZGm31pzloYOAnYEDWuZ4aC0ipqf/Xydrkt6kvXTzDuTdJXUnC+Q3R8QcsssGM7OG0oSqXjpC0k5kw4LvEhHvVzimT3qAktSSsSPZczjtlD1fF5GNt9IHGCNpFcBt5GbWcJqaql/aI2kk8BCwtqRpkg4FziMbquTO1LXwwnTsIEmj0qkDgQckPQU8CtwWEe1O5KMKtfvcSOpWcue2og/muuZun3X/C292dRGsAe2wTv8FvlV558Q3q4459civnvK+2XlUutkpSZdIegKo9qlQM7NO06Tql0aTez/ydLNzR7L+5IcAZ+Scp5lZzWrptdJocu1HzvyHoIYBl0XEU2rEEWfMbJFX5MiUdyB/XNJoYDXgxHQ39uOc81yozJgxg9N+djKTJz+PJE47/X8YMnSDri6WdbI/n/s/jH/sQfousRQnnZPNoHjj5ecxfuyDNHfrTv/lVuCbP/wpiy3uYf87qhFr2tXK9WanpCZgKDAlIt6RtAywQkQ83d65vtmZOfnE49nwixuxx157M+ejj5j9wQf069evq4vVZRbVm52Tnx1Hz169ufLs0z8J5BOffIS11v8izc3duOmK8wHY7aDvd2Uxu0w9bj7e//x/qo45W6y1VENF/bzbyAMYTHpMn6wbYq+c81xozJo1i8cfH8vue+4FQPcePRbpIL4o+9y6Q1ls8U//7tfZ4Es0N2cX1autvS7vvPV6VxRtoVHLA0GNJu9Afj6wGdkEzgAzgT/knOdCY9pLL7HUUkvzs5NOZJ89d+PUn53E+++XfY7AFnEP/f02Bm+4WVcXo9DqPPphp8o7kH8pIn4AfACfDKLVI+c8Fxrz5s1l0sQJ7L3f/lx7/U307t2bS/9Y1ZPAtgi5/boraGpuZuOtduzqohRak1T10mjyDuRz0qiHASBpAG3c7CwdiOaSix2wBg5cjoEDl2P99YcAsMOOOzFp4oQuLpU1kofvHsX4xx7k4GNPacgpyIqkyDXyvHutnEM26Muykn4J7AWcXOngNPDMCPDNToD+AwYwcLnlmPriFFZdbXUeefghVl9jja4uljWICU88zN9vuIqjfnkePXr61tMCa8QIXaXceq2kHiubkg2uvh3Z23RXREys5nwH8sykiRM57ZSTmDNnDiuuuBI//8X/0m+JJbq6WF1mUe21ctmZp/DC+CeZNeMd+i25NMP2O5TR1/+JuXPm0KdvdhN01bXXZf/v/aSLS9o16tFr5dEp71YdczZZfYmGCvt5dz98KCI6dAfGgdzKWVQDubWtHoF8bA2BfOMGC+R5t5GPlrSnn+Y0s4ZX4EbyvNvIjyXrOz5X0gdkb0FEhDtDm1lDKfKTnXnP2ennhc2sEIrcbpBrIJe0YZnN7wL/qmZMcjOzzuJAXtn5wIbAM2n9C8BTwDKSDo+I0Tnnb2ZWlSI3reR9s3MqsEFEfDEivkg2gNZ4YHvg1znnbWZWtXqOtSLpUkmvSxpfsm1pSXdKeiH9v1SFc3eS9JykyZJOqKbseQfyz0fEsy0rETGBLLBPyTlfM7Oa1LnTyuXATq22nUD2LM2awF1p/dNlyJ6E/wPwNbIBB/eXNLi9zPIO5M9JukDSVmk5H3heUk9gTs55m5lVr46RPCLGkD0MWWpX4Ir0+gpgtzKnbgJMjogpEfERcHU6r015B/KDgcnA0cAxwJS0bQ6wTc55m5lVrROmehsYEa8ApP+XLXPMCsBLJevT0rY25d39cLakc4HRZANnPRcRLTXxWXnmbWZWi1omVZY0HBhesmlEGitqQZUrRbtPnObd/XBrskuIqWQFXEnSQemyw8yscdQQyEsH+KvBa5KWj4hXJC0PlJsJZBqwUsn6isD09hLOu2nlTGDHiNgqIrYEvgr8Luc8zcxq1glNK7cAB6XXBwE3lzlmLLCmpNUk9QD2S+e1Ke9A3j0inmtZiYjnge4552lmVrM6dz8cCTwErC1pmqRDgTOAHSS9AOyQ1pE0SNIogPSg5BHAHcBE4NrSnn+V5P1A0OOSLgH+lNYPAB7POU8zs5rV83GgiNi/wq7tyhw7HRhWsj4KGFVLfnkH8sOBH5BNvixgDNnTnmZmjaW4D3bmF8jTxBKPR8R6wFl55WNmVg+NOBdntXJrI4+Ij4GnJK2cVx5mZvVS4OHIc29aWR54VtKjwHstGyNil5zzNTOrTSNG6CrlHchPyzl9M7O6KPLoh7kEckm9yG50fo5sCNtLPP64mTWyAjeR51Yjv4JsPJX7mT+K11E55WVmtsAcyD9rcER8ASD1I380p3zMzOrCTSuf9ckQtRExV0X+qjOzRUKRw1RegXyIpBnptYDeaV1ARES/nPI1M+uQAsfxfAJ5RDTnka6ZWW4KHMnz7n5oZlYIbiM3Myu4WiaWaDQO5GZm+GanmdlCoLiR3IHczAzXyM3MCq/AcTz3qd7MzAqhXlO9SVpb0riSZYako1sds7Wkd0uO+dmClN01cjMzoF5PoKd5ioemNJuBl4Ebyxx6f0TsXI88HcjNzMitaWU74J8R8a98ks+4acXMjPo1rbSyHzCywr7NJD0l6W+S1l2QsjuQm5mRPdlZ9T9puKTHSpbhn0lP6gHsAlxXJrsngFUiYghwLnDTgpTdTStmZlBT20pEjABGtHPY14AnIuK1MufPKHk9StL5kvpHxJvVl2I+B3IzM3J5RH9/KjSrSFoOeC0iQtImZK0jb3U0IwdyMzPqO2iWpMWAHYDDSrYdDhARFwJ7Ad+TNBeYDewXEdHh/Bbg3Fx9MJfGLJh1qftf6NCVpy3kdlin/wJH4f+8P6/qmLPUYs0N9fyQb3aamRWcm1bMzPBYK2ZmheeJJczMCs4TS5iZFZ0DuZlZsblpxcys4Hyz08ys4Aocxx3IzcyAQkdyB3IzM6CpwG0rDfuIvs0naXgabc3sE/5cWAs/ol8Mnxnr2Ax/LixxIDczKzgHcjOzgnMgLwa3g1o5/lwY4JudZmaF5xq5mVnBOZCbmRWcA3krkkLSmSXrP5J0ap3SPlXSy5LGSRovaZd6pGuNR9K8kt/zdWkOR7NcOJB/1ofAHpL655T+7yJiKLA3cKmkT/0OJC3Q07YLen6NeTV3Vl4FNDsihkbEesBHwOGlO+vx3nXW+9+ZnynrGAfyz5pL1hvgmNY7JK0i6S5JT6f/V07bL5d0jqR/SJoiaa/2MomIiSmv/pLulfQ/ku4DjpK0naQnJT0j6VJJPVM+wyRNkvRAyu+vafupkkZIGg1cKWmApOsljU3L5um4rVItcVxKv6+k5SWNKak9bpGO3T/lP17Sr0reg1mSfi7pEWCzBXyvFxX3A5+TtLWkeyT9BXhGUi9Jl6X3+UlJ20A2A7uka9Pn7BpJj0jaKO371Psv6ZuSHk2/v4skNafl8vS7e0bSMencIyVNSOlenbYtLemmtO1hSeun7Z/6THXFm2Y1iAgvJQswC+gHTAWWAH4EnJr23QoclF5/G7gpvb4cuI7si3EwMLlC2qcCP0qvvwRMJxuq517g/LS9F/ASsFZavxI4umT7amn7SOCvJek+DvRO638BvpJerwxMLCn/5un14mRj7RwHnJS2NQN9gUHAv4EB6Zi7gd3SMQHs09W/p0ZfgFnp/27AzcD3gK2B90p+h8cBl6XXn0/vea/0mbsobV+P7At/o9bvP7BO+p12T+vnAwcCXwTuLCnLkun/6UDPVtvOBU5Jr7cFxpX7THlp7MU18jIiYgZZAD2y1a7NyIIkwJ+Ar5TsuykiPo6ICcDANpI/RtI44LfAvpH+aoBr0v9rAy9GxPNp/QpgS7I/9CkR8WLaPrJVurdExOz0envgvJTPLUA/SX2BB4GzJB1J9oc8FxgLHJLuA3whImYCGwP3RsQb6ZirUhkA5gHXt/HzWaZ3ev8fIwvQl6Ttj5b8Dr9C9jkiIiYB/wLWStuvTtvHA0+XpFv6/m9HFrTHpry2A1YHpgCrSzpX0k7AjHT808BVkr5J9uXQugx3A8tIWiLtK/1MWQNz21dlvweeAC5r45jSTvgflrwWgKRfAl8HiKxdHLI28t+WSeu90nPLaG9otvdKXjcBm5X5IzxD0m3AMOBhSdtHxBhJW6Zy/knSb5j/h1/OBxExr52yWGojL92gbHS90t9TR37Xpe+/gCsi4sTPJCANAb4K/ADYh+wK8utkX8i7AP8tad0KebV8rt8rs88akGvkFUTE28C1wKElm/8B7JdeHwA80E4aJ0V2w2toDVlPAlaV9Lm0/i3gvrR9dUmrpu37tpHGaOCIlhVJQ9P/a0TEMxHxK7Ka4uclrQK8HhEXk9UaNwQeAbaS1D/dUNs/lcHqawzZ5whJa5E1gz1H9rnaJ20fDHyhwvl3AXtJWjYdu3S6j9MfaIqI64H/BjZMN9VXioh7gJ8AS5I1r5WWYWvgzXRFagXiGnnbzqQkIJI1tVwq6cfAG8Ah9c4wIj6QdAhwXeotMBa4MCI+lPR94HZJbwKPtpHMkcAfJD1N9jseQ9Zr4uh0Q20eMAH4G9kX048lzSG7P3BgRLwi6UTgHrIa26iIuLneP6txPnChpGfImjoOTr/n84Er0u/vSbImkXdbnxwREySdDIxOgXoOWQ18NnCZ5veIOpHs/sefU7OJyK4M30lNapelvN4HDsrx57Wc+BH9ApG0eETMUnaN/gfghYj4XVeXy+orXQV1T1/qa5DVvNeKiI+6uGjWoFwjL5bvSjoI6EFWU7uoi8tj+VgMuEdSd7La8/ccxK0trpGbmRWcb3aamRWcA7mZWcE5kJuZFZwDuZlZwTmQm5kVnAO5mVnBOZCbmRWcA7mZWcE5kJuZFZwDuZlZwTmQm5kVnAO5mVnBOZCbmRWcA7mZWcE5kNunSJonaZyk8ZKuk7TYAqR1uaS90us/pmnLKh27taQvdyCPqWlqs9b5HtZq226SRlVTVrOicSC31maneUbXAz4imyLuE2n2mppFxHciYkIbh2wN1BzIKxjJ/LlVW+yXtpstdBzIrS33A59LteV7JP0FeEZSs6TfSBor6emW2q8y50maIOk2YNmWhCTdK2mj9HonSU9IekrSXWlC6cOBY9LVwBaSBki6PuUxVtLm6dxlJI2W9KSkiyg/C/zfySaWXj6dsxiwPXCTpJ+l9MZLGpGmzfuU0lq+pI0k3Zte95F0aTr/SUm7pu3rSno0lf1pSWvW4803q5YDuZWVJn7+GvBM2rQJcFJEDAYOBd6NiI2BjcmmoFsN2B1Ym2zW9+9SpoYtaQBwMbBnRAwB9o6IqcCFZBMCD42I+4Gz0/rGwJ7AH1MSpwAPRMQGwC1kM89/SkTMA24gzUQP7ALcExEzgfMiYuN0xdEb2LmGt+Uk4O5Upm2A30jqQ/YldHZEDAU2AqbVkKbZAvOcndZab0nj0uv7gUvIAvKjEfFi2r4jsH5Jm/ISwJrAlsDIFEinS7q7TPqbAmNa0oqItyuUY3tgcEmFuZ+kvimPPdK5t0n6T4XzRwK/IftC2A+4Mm3fRtJPyObFXBp4Fri1Qhqt7QjsIulHab0X2RfJQ8BJklYEboiIF6pMz6wuHMittdmpZvmJFEzfK90E/DAi7mh13DCgvUlgVcUxkF0tbhYRs8uUpZrzHwSWlzSE7ItoP0m9gPOBjSLiJUmnkgXj1uYy/2q1dL/IriSea3X8REmPAF8H7pD0nYgo9yVmlgs3rVhH3AF8L83yjqS1UhPDGLKA2Zzap7cpc+5DwFapKQZJS6ftM4G+JceNBo5oWZE0NL0cAxyQtn0NWKpcASObVfxa4ApgVER8wPyg/KakxYFKvVSmAl9Mr/ds9XP/sKVdXdIG6f/VgSkRcQ5Zc8/6FdI1y4UDuXXEH4EJwBOSxgMXkV3d3Qi8QNaufgFwX+sTI+INYDhwg6SngGvSrluB3VtudgJHAhulm4cTmN975jRgS0lPkDV1/LuNco4EhgBXp7zfIWuffwa4CRhb4bzTgLMl3Q/MK9l+OtAdeDr93Ken7fsC41OT1OeZ34xj1imUVVzMzKyoXCM3Mys4B3Izs4JzIDczKzgHcjOzgnMgNzMrOAdyM7OCcyA3Mys4B3Izs4L7f/2OW/hii4ZKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m2_eval_test = model_121.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d7959",
   "metadata": {},
   "source": [
    "#### 1.2.2 Alvin's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cb42a385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_11 (Conv1D)          (None, 766, 64)           256       \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 764, 32)           6176      \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 24448)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 112)               2738288   \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2)                 226       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,744,946\n",
      "Trainable params: 2,744,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model1\n",
    "model_122 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_122.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_122.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_122.add(Flatten())\n",
    "model_122.add(Dense(112, activation='relu'))\n",
    "model_122.add(Dense(2, activation='softmax'))\n",
    "model_122.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a73640b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=400,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "88ced1f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.6936 - accuracy: 0.5202 - val_loss: 0.6738 - val_accuracy: 0.6604\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.6880 - accuracy: 0.5000 - val_loss: 0.6592 - val_accuracy: 0.6604\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.6838 - accuracy: 0.5296 - val_loss: 0.6713 - val_accuracy: 0.6981\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.6806 - accuracy: 0.5732 - val_loss: 0.6330 - val_accuracy: 0.6604\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.6696 - accuracy: 0.6012 - val_loss: 0.6690 - val_accuracy: 0.6604\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.6624 - accuracy: 0.6246 - val_loss: 0.6276 - val_accuracy: 0.7170\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.6525 - accuracy: 0.6355 - val_loss: 0.6967 - val_accuracy: 0.5660\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.6545 - accuracy: 0.6184 - val_loss: 0.6113 - val_accuracy: 0.6981\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.6403 - accuracy: 0.6386 - val_loss: 0.6275 - val_accuracy: 0.6792\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.6324 - accuracy: 0.6667 - val_loss: 0.6452 - val_accuracy: 0.6604\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.6238 - accuracy: 0.6667 - val_loss: 0.6624 - val_accuracy: 0.6604\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.6301 - accuracy: 0.6386 - val_loss: 0.5807 - val_accuracy: 0.6604\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.6218 - accuracy: 0.6542 - val_loss: 0.6184 - val_accuracy: 0.6604\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.6147 - accuracy: 0.6807 - val_loss: 0.6245 - val_accuracy: 0.6415\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.6042 - accuracy: 0.6822 - val_loss: 0.7002 - val_accuracy: 0.6226\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.6047 - accuracy: 0.6838 - val_loss: 0.6105 - val_accuracy: 0.6981\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.6047 - accuracy: 0.6760 - val_loss: 0.6100 - val_accuracy: 0.6604\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.5902 - accuracy: 0.6760 - val_loss: 0.6413 - val_accuracy: 0.6604\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.5798 - accuracy: 0.6931 - val_loss: 0.6321 - val_accuracy: 0.6604\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.5759 - accuracy: 0.6994 - val_loss: 0.6944 - val_accuracy: 0.6226\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.5689 - accuracy: 0.6978 - val_loss: 0.6414 - val_accuracy: 0.6415\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.5621 - accuracy: 0.7118 - val_loss: 0.6195 - val_accuracy: 0.6415\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.5594 - accuracy: 0.7056 - val_loss: 0.6435 - val_accuracy: 0.6415\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.5513 - accuracy: 0.7227 - val_loss: 0.6325 - val_accuracy: 0.6415\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.5455 - accuracy: 0.7368 - val_loss: 0.6290 - val_accuracy: 0.6415\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.5457 - accuracy: 0.7290 - val_loss: 0.6576 - val_accuracy: 0.6226\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.5286 - accuracy: 0.7243 - val_loss: 0.6303 - val_accuracy: 0.6226\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.5337 - accuracy: 0.7321 - val_loss: 0.6480 - val_accuracy: 0.6415\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.5207 - accuracy: 0.7445 - val_loss: 0.6580 - val_accuracy: 0.6226\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.5113 - accuracy: 0.7632 - val_loss: 0.7187 - val_accuracy: 0.5660\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.5080 - accuracy: 0.7430 - val_loss: 0.7519 - val_accuracy: 0.5660\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.5081 - accuracy: 0.7570 - val_loss: 0.7011 - val_accuracy: 0.6038\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.4966 - accuracy: 0.7555 - val_loss: 0.6794 - val_accuracy: 0.6226\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.4938 - accuracy: 0.7741 - val_loss: 0.6728 - val_accuracy: 0.6226\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.4978 - accuracy: 0.7570 - val_loss: 0.7531 - val_accuracy: 0.6038\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.4798 - accuracy: 0.7773 - val_loss: 0.6872 - val_accuracy: 0.6038\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.4720 - accuracy: 0.7741 - val_loss: 0.7208 - val_accuracy: 0.5660\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.4670 - accuracy: 0.7913 - val_loss: 0.6966 - val_accuracy: 0.6038\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.4643 - accuracy: 0.7897 - val_loss: 0.7002 - val_accuracy: 0.5849\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.4573 - accuracy: 0.7960 - val_loss: 0.7697 - val_accuracy: 0.5472\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.4477 - accuracy: 0.8053 - val_loss: 0.7722 - val_accuracy: 0.5660\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.5013 - accuracy: 0.7492 - val_loss: 0.7931 - val_accuracy: 0.6038\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.4438 - accuracy: 0.8053 - val_loss: 0.7161 - val_accuracy: 0.6038\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.4351 - accuracy: 0.7944 - val_loss: 0.7109 - val_accuracy: 0.6038\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.4289 - accuracy: 0.8146 - val_loss: 0.7368 - val_accuracy: 0.6038\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.4230 - accuracy: 0.8146 - val_loss: 0.7939 - val_accuracy: 0.5472\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.4414 - accuracy: 0.8053 - val_loss: 0.7909 - val_accuracy: 0.5472\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.4209 - accuracy: 0.8069 - val_loss: 0.7910 - val_accuracy: 0.5472\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.4106 - accuracy: 0.8333 - val_loss: 0.8248 - val_accuracy: 0.5660\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.4221 - accuracy: 0.8209 - val_loss: 0.8600 - val_accuracy: 0.5472\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.4036 - accuracy: 0.8318 - val_loss: 0.8092 - val_accuracy: 0.5660\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.3960 - accuracy: 0.8333 - val_loss: 0.7843 - val_accuracy: 0.5660\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.3867 - accuracy: 0.8489 - val_loss: 0.8115 - val_accuracy: 0.5660\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.3856 - accuracy: 0.8411 - val_loss: 0.7976 - val_accuracy: 0.5849\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.3714 - accuracy: 0.8551 - val_loss: 0.7919 - val_accuracy: 0.6038\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.3996 - accuracy: 0.8333 - val_loss: 0.8481 - val_accuracy: 0.5283\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.3702 - accuracy: 0.8442 - val_loss: 0.8662 - val_accuracy: 0.5660\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 35ms/step - loss: 0.3877 - accuracy: 0.8255 - val_loss: 0.8578 - val_accuracy: 0.5472\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.3553 - accuracy: 0.8660 - val_loss: 0.8355 - val_accuracy: 0.6038\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.3691 - accuracy: 0.8520 - val_loss: 0.8642 - val_accuracy: 0.5849\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.3495 - accuracy: 0.8629 - val_loss: 0.8463 - val_accuracy: 0.6226\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.3748 - accuracy: 0.8333 - val_loss: 0.8638 - val_accuracy: 0.6038\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.3434 - accuracy: 0.8801 - val_loss: 0.8520 - val_accuracy: 0.6226\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.3440 - accuracy: 0.8629 - val_loss: 0.9187 - val_accuracy: 0.5849\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.3330 - accuracy: 0.8738 - val_loss: 0.8399 - val_accuracy: 0.6038\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.3354 - accuracy: 0.8614 - val_loss: 0.8505 - val_accuracy: 0.6038\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.3295 - accuracy: 0.8738 - val_loss: 0.8951 - val_accuracy: 0.5660\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.3438 - accuracy: 0.8754 - val_loss: 0.8978 - val_accuracy: 0.5849\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.3185 - accuracy: 0.8956 - val_loss: 0.8975 - val_accuracy: 0.5849\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.3172 - accuracy: 0.8863 - val_loss: 0.8647 - val_accuracy: 0.5849\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.3083 - accuracy: 0.8941 - val_loss: 0.9130 - val_accuracy: 0.5472\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.3031 - accuracy: 0.8941 - val_loss: 0.9138 - val_accuracy: 0.5849\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.3046 - accuracy: 0.8863 - val_loss: 0.9096 - val_accuracy: 0.6226\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.3112 - accuracy: 0.8738 - val_loss: 0.9038 - val_accuracy: 0.6038\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.2877 - accuracy: 0.9003 - val_loss: 1.0189 - val_accuracy: 0.5660\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2901 - accuracy: 0.9050 - val_loss: 0.9915 - val_accuracy: 0.5660\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2944 - accuracy: 0.8956 - val_loss: 0.9918 - val_accuracy: 0.5660\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.2829 - accuracy: 0.8988 - val_loss: 1.0416 - val_accuracy: 0.6038\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.2819 - accuracy: 0.8816 - val_loss: 0.9514 - val_accuracy: 0.5472\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2678 - accuracy: 0.9097 - val_loss: 1.0178 - val_accuracy: 0.5472\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2612 - accuracy: 0.9081 - val_loss: 1.0083 - val_accuracy: 0.5472\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2588 - accuracy: 0.9065 - val_loss: 0.9842 - val_accuracy: 0.5283\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.2537 - accuracy: 0.9221 - val_loss: 1.0267 - val_accuracy: 0.5472\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2503 - accuracy: 0.9206 - val_loss: 0.9943 - val_accuracy: 0.5283\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2539 - accuracy: 0.9174 - val_loss: 1.0245 - val_accuracy: 0.5283\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2460 - accuracy: 0.9112 - val_loss: 1.1042 - val_accuracy: 0.5472\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2423 - accuracy: 0.9206 - val_loss: 1.0655 - val_accuracy: 0.5472\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2458 - accuracy: 0.9143 - val_loss: 1.0286 - val_accuracy: 0.5094\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2479 - accuracy: 0.9159 - val_loss: 1.0313 - val_accuracy: 0.5283\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2188 - accuracy: 0.9299 - val_loss: 1.0497 - val_accuracy: 0.5283\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2181 - accuracy: 0.9315 - val_loss: 1.0556 - val_accuracy: 0.5094\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2185 - accuracy: 0.9361 - val_loss: 1.0884 - val_accuracy: 0.5283\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2127 - accuracy: 0.9221 - val_loss: 1.0596 - val_accuracy: 0.5283\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2165 - accuracy: 0.9408 - val_loss: 1.2575 - val_accuracy: 0.5849\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.2432 - accuracy: 0.9050 - val_loss: 1.0582 - val_accuracy: 0.5094\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.2233 - accuracy: 0.9330 - val_loss: 1.0898 - val_accuracy: 0.5094\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1959 - accuracy: 0.9393 - val_loss: 1.0860 - val_accuracy: 0.5283\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.2035 - accuracy: 0.9346 - val_loss: 1.2070 - val_accuracy: 0.5849\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2472 - accuracy: 0.9050 - val_loss: 1.2182 - val_accuracy: 0.5660\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.1988 - accuracy: 0.9393 - val_loss: 1.1792 - val_accuracy: 0.5472\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.1997 - accuracy: 0.9439 - val_loss: 1.1054 - val_accuracy: 0.5283\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2048 - accuracy: 0.9315 - val_loss: 1.1689 - val_accuracy: 0.5660\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1864 - accuracy: 0.9361 - val_loss: 1.3190 - val_accuracy: 0.5660\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2078 - accuracy: 0.9252 - val_loss: 1.1902 - val_accuracy: 0.5283\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1769 - accuracy: 0.9517 - val_loss: 1.1621 - val_accuracy: 0.5283\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1659 - accuracy: 0.9564 - val_loss: 1.2508 - val_accuracy: 0.5660\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.1651 - accuracy: 0.9564 - val_loss: 1.2023 - val_accuracy: 0.5283\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.1640 - accuracy: 0.9502 - val_loss: 1.2938 - val_accuracy: 0.5849\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1644 - accuracy: 0.9564 - val_loss: 1.2301 - val_accuracy: 0.5283\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1597 - accuracy: 0.9486 - val_loss: 1.2229 - val_accuracy: 0.5094\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1496 - accuracy: 0.9595 - val_loss: 1.2679 - val_accuracy: 0.5472\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.1607 - accuracy: 0.9548 - val_loss: 1.2280 - val_accuracy: 0.5283\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.1480 - accuracy: 0.9548 - val_loss: 1.2421 - val_accuracy: 0.5094\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.1395 - accuracy: 0.9626 - val_loss: 1.3301 - val_accuracy: 0.5660\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1485 - accuracy: 0.9595 - val_loss: 1.2688 - val_accuracy: 0.5472\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.1340 - accuracy: 0.9626 - val_loss: 1.2696 - val_accuracy: 0.5283\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.1324 - accuracy: 0.9688 - val_loss: 1.3617 - val_accuracy: 0.5849\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1295 - accuracy: 0.9673 - val_loss: 1.3061 - val_accuracy: 0.5283\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1650 - accuracy: 0.9439 - val_loss: 1.3121 - val_accuracy: 0.5094\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1388 - accuracy: 0.9626 - val_loss: 1.3673 - val_accuracy: 0.5849\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1402 - accuracy: 0.9548 - val_loss: 1.4486 - val_accuracy: 0.5660\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.1896 - accuracy: 0.9237 - val_loss: 1.4231 - val_accuracy: 0.5849\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.1277 - accuracy: 0.9688 - val_loss: 1.3923 - val_accuracy: 0.5660\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1173 - accuracy: 0.9704 - val_loss: 1.3710 - val_accuracy: 0.5283\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.1128 - accuracy: 0.9782 - val_loss: 1.4010 - val_accuracy: 0.5283\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.1193 - accuracy: 0.9688 - val_loss: 1.4399 - val_accuracy: 0.5849\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1358 - accuracy: 0.9533 - val_loss: 1.4065 - val_accuracy: 0.5849\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1068 - accuracy: 0.9704 - val_loss: 1.3709 - val_accuracy: 0.5283\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1061 - accuracy: 0.9751 - val_loss: 1.3634 - val_accuracy: 0.5283\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1061 - accuracy: 0.9782 - val_loss: 1.4537 - val_accuracy: 0.5472\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0985 - accuracy: 0.9782 - val_loss: 1.4318 - val_accuracy: 0.5660\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0964 - accuracy: 0.9829 - val_loss: 1.4298 - val_accuracy: 0.5283\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0996 - accuracy: 0.9782 - val_loss: 1.5280 - val_accuracy: 0.5849\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.1163 - accuracy: 0.9688 - val_loss: 1.3933 - val_accuracy: 0.5849\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0976 - accuracy: 0.9782 - val_loss: 1.5756 - val_accuracy: 0.5849\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.1005 - accuracy: 0.9735 - val_loss: 1.4554 - val_accuracy: 0.5472\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0841 - accuracy: 0.9782 - val_loss: 1.6259 - val_accuracy: 0.5849\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0932 - accuracy: 0.9751 - val_loss: 1.4410 - val_accuracy: 0.5660\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1452 - accuracy: 0.9439 - val_loss: 1.4714 - val_accuracy: 0.5660\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0955 - accuracy: 0.9829 - val_loss: 1.4355 - val_accuracy: 0.5472\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0832 - accuracy: 0.9829 - val_loss: 1.4584 - val_accuracy: 0.5283\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0820 - accuracy: 0.9875 - val_loss: 1.4952 - val_accuracy: 0.5660\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0787 - accuracy: 0.9813 - val_loss: 1.5955 - val_accuracy: 0.6038\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0851 - accuracy: 0.9813 - val_loss: 1.5042 - val_accuracy: 0.6038\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0830 - accuracy: 0.9844 - val_loss: 1.5353 - val_accuracy: 0.5660\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0750 - accuracy: 0.9860 - val_loss: 1.5472 - val_accuracy: 0.5660\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0730 - accuracy: 0.9860 - val_loss: 1.5557 - val_accuracy: 0.5660\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0710 - accuracy: 0.9891 - val_loss: 1.5365 - val_accuracy: 0.5094\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0757 - accuracy: 0.9829 - val_loss: 1.6209 - val_accuracy: 0.5660\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0791 - accuracy: 0.9782 - val_loss: 1.6154 - val_accuracy: 0.5472\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0910 - accuracy: 0.9798 - val_loss: 1.5290 - val_accuracy: 0.5849\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0714 - accuracy: 0.9844 - val_loss: 1.5552 - val_accuracy: 0.5849\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0740 - accuracy: 0.9891 - val_loss: 1.5662 - val_accuracy: 0.5849\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0838 - accuracy: 0.9782 - val_loss: 1.5709 - val_accuracy: 0.5660\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0716 - accuracy: 0.9844 - val_loss: 1.6192 - val_accuracy: 0.5660\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0635 - accuracy: 0.9907 - val_loss: 1.6467 - val_accuracy: 0.6038\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0650 - accuracy: 0.9907 - val_loss: 1.6227 - val_accuracy: 0.5660\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0572 - accuracy: 0.9891 - val_loss: 1.9365 - val_accuracy: 0.5660\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2287 - accuracy: 0.9003 - val_loss: 1.5860 - val_accuracy: 0.5849\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0865 - accuracy: 0.9798 - val_loss: 1.6099 - val_accuracy: 0.5472\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0691 - accuracy: 0.9860 - val_loss: 1.5974 - val_accuracy: 0.5660\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0589 - accuracy: 0.9891 - val_loss: 1.6703 - val_accuracy: 0.5283\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0544 - accuracy: 0.9907 - val_loss: 1.6863 - val_accuracy: 0.5283\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0546 - accuracy: 0.9907 - val_loss: 1.7033 - val_accuracy: 0.5283\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0524 - accuracy: 0.9907 - val_loss: 1.7198 - val_accuracy: 0.5660\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0592 - accuracy: 0.9875 - val_loss: 1.6364 - val_accuracy: 0.5849\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0689 - accuracy: 0.9766 - val_loss: 1.7287 - val_accuracy: 0.5660\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0586 - accuracy: 0.9907 - val_loss: 1.7234 - val_accuracy: 0.5472\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0536 - accuracy: 0.9922 - val_loss: 1.6234 - val_accuracy: 0.5849\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0494 - accuracy: 0.9922 - val_loss: 1.7050 - val_accuracy: 0.5660\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0510 - accuracy: 0.9938 - val_loss: 1.7504 - val_accuracy: 0.5472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0442 - accuracy: 0.9938 - val_loss: 1.7616 - val_accuracy: 0.5660\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0455 - accuracy: 0.9938 - val_loss: 1.9263 - val_accuracy: 0.5849\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2164 - accuracy: 0.9159 - val_loss: 1.8444 - val_accuracy: 0.6038\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0977 - accuracy: 0.9673 - val_loss: 1.6926 - val_accuracy: 0.6226\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0578 - accuracy: 0.9907 - val_loss: 1.7532 - val_accuracy: 0.5849\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0500 - accuracy: 0.9922 - val_loss: 1.7597 - val_accuracy: 0.5660\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0445 - accuracy: 0.9922 - val_loss: 1.7472 - val_accuracy: 0.6038\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0429 - accuracy: 0.9938 - val_loss: 1.7294 - val_accuracy: 0.6038\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0478 - accuracy: 0.9907 - val_loss: 1.7279 - val_accuracy: 0.5849\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0391 - accuracy: 0.9969 - val_loss: 1.7728 - val_accuracy: 0.5660\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0401 - accuracy: 0.9953 - val_loss: 1.7532 - val_accuracy: 0.5660\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0409 - accuracy: 0.9938 - val_loss: 1.7818 - val_accuracy: 0.6226\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0655 - accuracy: 0.9766 - val_loss: 1.9329 - val_accuracy: 0.6226\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0509 - accuracy: 0.9922 - val_loss: 1.8541 - val_accuracy: 0.5660\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0370 - accuracy: 0.9953 - val_loss: 1.8391 - val_accuracy: 0.5660\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0365 - accuracy: 0.9984 - val_loss: 1.8871 - val_accuracy: 0.5660\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0378 - accuracy: 0.9907 - val_loss: 1.9297 - val_accuracy: 0.5849\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0456 - accuracy: 0.9922 - val_loss: 1.8739 - val_accuracy: 0.5849\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0529 - accuracy: 0.9844 - val_loss: 1.8393 - val_accuracy: 0.5849\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0468 - accuracy: 0.9875 - val_loss: 1.8069 - val_accuracy: 0.6038\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0422 - accuracy: 0.9922 - val_loss: 1.8504 - val_accuracy: 0.6038\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0334 - accuracy: 0.9953 - val_loss: 1.8374 - val_accuracy: 0.5849\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0354 - accuracy: 0.9938 - val_loss: 1.8770 - val_accuracy: 0.5849\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0309 - accuracy: 0.9969 - val_loss: 1.9182 - val_accuracy: 0.6038\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0311 - accuracy: 0.9953 - val_loss: 1.8833 - val_accuracy: 0.5660\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0306 - accuracy: 0.9953 - val_loss: 1.8524 - val_accuracy: 0.6038\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0345 - accuracy: 0.9953 - val_loss: 1.8830 - val_accuracy: 0.5849\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0443 - accuracy: 0.9922 - val_loss: 1.9505 - val_accuracy: 0.6226\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.0346 - accuracy: 0.9953 - val_loss: 1.9450 - val_accuracy: 0.6038\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0286 - accuracy: 0.9953 - val_loss: 1.8919 - val_accuracy: 0.6226\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0288 - accuracy: 0.9953 - val_loss: 1.9116 - val_accuracy: 0.6038\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0305 - accuracy: 0.9953 - val_loss: 1.9132 - val_accuracy: 0.6415\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0313 - accuracy: 0.9953 - val_loss: 1.9305 - val_accuracy: 0.6038\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0271 - accuracy: 0.9953 - val_loss: 1.9475 - val_accuracy: 0.6226\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.0292 - accuracy: 0.9953 - val_loss: 2.0041 - val_accuracy: 0.5849\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.0257 - accuracy: 0.9953 - val_loss: 1.9910 - val_accuracy: 0.5660\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0240 - accuracy: 0.9969 - val_loss: 2.0440 - val_accuracy: 0.6038\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0258 - accuracy: 0.9953 - val_loss: 2.0192 - val_accuracy: 0.5849\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0253 - accuracy: 0.9969 - val_loss: 2.0163 - val_accuracy: 0.5849\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0328 - accuracy: 0.9922 - val_loss: 2.0260 - val_accuracy: 0.6226\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0268 - accuracy: 0.9938 - val_loss: 1.9752 - val_accuracy: 0.5849\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0255 - accuracy: 0.9984 - val_loss: 1.9946 - val_accuracy: 0.5849\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0248 - accuracy: 0.9938 - val_loss: 2.0012 - val_accuracy: 0.5849\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0233 - accuracy: 0.9953 - val_loss: 2.0522 - val_accuracy: 0.5849\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0220 - accuracy: 0.9969 - val_loss: 2.0900 - val_accuracy: 0.5660\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0396 - accuracy: 0.9953 - val_loss: 2.1240 - val_accuracy: 0.5849\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0281 - accuracy: 0.9938 - val_loss: 2.0944 - val_accuracy: 0.6038\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0247 - accuracy: 0.9953 - val_loss: 2.1149 - val_accuracy: 0.5849\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0203 - accuracy: 0.9969 - val_loss: 2.0431 - val_accuracy: 0.6038\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 2.0769 - val_accuracy: 0.6038\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0201 - accuracy: 0.9984 - val_loss: 2.0742 - val_accuracy: 0.6038\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0202 - accuracy: 0.9969 - val_loss: 2.0595 - val_accuracy: 0.5849\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0196 - accuracy: 0.9969 - val_loss: 2.1278 - val_accuracy: 0.6038\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 2.0727 - val_accuracy: 0.5849\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0186 - accuracy: 0.9984 - val_loss: 2.1547 - val_accuracy: 0.5849\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0175 - accuracy: 0.9984 - val_loss: 2.2024 - val_accuracy: 0.6226\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.1473 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0171 - accuracy: 0.9984 - val_loss: 2.1446 - val_accuracy: 0.6038\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 2.1366 - val_accuracy: 0.6038\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0159 - accuracy: 0.9984 - val_loss: 2.1173 - val_accuracy: 0.6038\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0155 - accuracy: 0.9984 - val_loss: 2.2039 - val_accuracy: 0.5849\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 2.2233 - val_accuracy: 0.5849\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 2.1660 - val_accuracy: 0.6415\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0160 - accuracy: 0.9984 - val_loss: 2.1720 - val_accuracy: 0.6226\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 2.2631 - val_accuracy: 0.6038\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0258 - accuracy: 0.9969 - val_loss: 2.2500 - val_accuracy: 0.6038\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 2.2172 - val_accuracy: 0.6038\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0162 - accuracy: 0.9984 - val_loss: 2.1871 - val_accuracy: 0.6038\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0166 - accuracy: 0.9984 - val_loss: 2.2053 - val_accuracy: 0.6038\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0150 - accuracy: 0.9984 - val_loss: 2.3013 - val_accuracy: 0.5849\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0170 - accuracy: 0.9984 - val_loss: 2.2627 - val_accuracy: 0.6038\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0157 - accuracy: 0.9984 - val_loss: 2.2783 - val_accuracy: 0.6226\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0141 - accuracy: 0.9984 - val_loss: 2.3276 - val_accuracy: 0.5849\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0141 - accuracy: 0.9984 - val_loss: 2.2711 - val_accuracy: 0.6226\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.2910 - val_accuracy: 0.6226\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 2.2547 - val_accuracy: 0.5849\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.0137 - accuracy: 0.9984 - val_loss: 2.3054 - val_accuracy: 0.6226\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.0113 - accuracy: 0.9984 - val_loss: 2.3257 - val_accuracy: 0.6038\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0114 - accuracy: 0.9984 - val_loss: 2.3406 - val_accuracy: 0.6226\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.3565 - val_accuracy: 0.6226\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.3422 - val_accuracy: 0.6038\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.3962 - val_accuracy: 0.6226\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.3666 - val_accuracy: 0.6226\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.3785 - val_accuracy: 0.6226\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0105 - accuracy: 0.9984 - val_loss: 2.3496 - val_accuracy: 0.6038\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.3584 - val_accuracy: 0.6038\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 2.4638 - val_accuracy: 0.5849\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.3643 - val_accuracy: 0.6226\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 2.3665 - val_accuracy: 0.6226\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.4154 - val_accuracy: 0.6038\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.3881 - val_accuracy: 0.6038\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.4301 - val_accuracy: 0.6226\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0088 - accuracy: 0.9984 - val_loss: 2.4498 - val_accuracy: 0.6226\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.4671 - val_accuracy: 0.6038\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.4553 - val_accuracy: 0.6038\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.4413 - val_accuracy: 0.6226\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.5011 - val_accuracy: 0.6226\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.4984 - val_accuracy: 0.6226\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.4960 - val_accuracy: 0.5849\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0093 - accuracy: 0.9984 - val_loss: 2.5180 - val_accuracy: 0.6038\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.5080 - val_accuracy: 0.6038\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.5396 - val_accuracy: 0.5849\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 2.5515 - val_accuracy: 0.6038\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.5065 - val_accuracy: 0.6038\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.5526 - val_accuracy: 0.6038\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.5500 - val_accuracy: 0.6226\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.6106 - val_accuracy: 0.5849\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.5982 - val_accuracy: 0.6226\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.5704 - val_accuracy: 0.6038\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.5885 - val_accuracy: 0.6038\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.5720 - val_accuracy: 0.6038\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.5595 - val_accuracy: 0.6038\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.5919 - val_accuracy: 0.6038\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7173 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.6037 - val_accuracy: 0.6226\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.6119 - val_accuracy: 0.6038\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.6076 - val_accuracy: 0.6038\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.6349 - val_accuracy: 0.6226\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.6340 - val_accuracy: 0.6038\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.6254 - val_accuracy: 0.6038\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.6433 - val_accuracy: 0.6038\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.6340 - val_accuracy: 0.6038\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.6420 - val_accuracy: 0.6038\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.6768 - val_accuracy: 0.6038\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.6942 - val_accuracy: 0.6038\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.7374 - val_accuracy: 0.6038\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.6984 - val_accuracy: 0.6038\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.6584 - val_accuracy: 0.6038\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 2.7354 - val_accuracy: 0.6226\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.7615 - val_accuracy: 0.6038\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.8000 - val_accuracy: 0.6038\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.7296 - val_accuracy: 0.6038\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.7200 - val_accuracy: 0.6038\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.7122 - val_accuracy: 0.6038\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.9577 - val_accuracy: 0.6038\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0555 - accuracy: 0.9829 - val_loss: 2.9411 - val_accuracy: 0.5472\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0160 - accuracy: 0.9984 - val_loss: 2.6250 - val_accuracy: 0.5849\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 1s 37ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.7188 - val_accuracy: 0.6038\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.7406 - val_accuracy: 0.5472\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.7924 - val_accuracy: 0.6038\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8474 - val_accuracy: 0.6226\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.7805 - val_accuracy: 0.6038\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7305 - val_accuracy: 0.5849\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.7325 - val_accuracy: 0.5849\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.7378 - val_accuracy: 0.5849\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.7708 - val_accuracy: 0.6038\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.7934 - val_accuracy: 0.6038\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7677 - val_accuracy: 0.5849\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8176 - val_accuracy: 0.6038\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8096 - val_accuracy: 0.6038\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.7745 - val_accuracy: 0.6038\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.7991 - val_accuracy: 0.5849\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.8168 - val_accuracy: 0.6038\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8746 - val_accuracy: 0.6038\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8618 - val_accuracy: 0.6038\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.8766 - val_accuracy: 0.5849\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8677 - val_accuracy: 0.5849\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.8471 - val_accuracy: 0.5849\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.8526 - val_accuracy: 0.6038\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.8887 - val_accuracy: 0.5849\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.8904 - val_accuracy: 0.6038\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.8560 - val_accuracy: 0.5849\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9161 - val_accuracy: 0.6038\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9301 - val_accuracy: 0.6038\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9302 - val_accuracy: 0.6038\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9209 - val_accuracy: 0.5849\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9094 - val_accuracy: 0.5849\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9212 - val_accuracy: 0.6038\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9339 - val_accuracy: 0.5849\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9185 - val_accuracy: 0.5849\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.9206 - val_accuracy: 0.5849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.9382 - val_accuracy: 0.5849\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.9293 - val_accuracy: 0.5849\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.9693 - val_accuracy: 0.5849\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.9568 - val_accuracy: 0.5849\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.9322 - val_accuracy: 0.6038\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9591 - val_accuracy: 0.5849\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.0039 - val_accuracy: 0.5849\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0005 - val_accuracy: 0.5849\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9769 - val_accuracy: 0.5849\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.0064 - val_accuracy: 0.5849\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.9991 - val_accuracy: 0.5849\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0141 - val_accuracy: 0.5849\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0068 - val_accuracy: 0.5849\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0166 - val_accuracy: 0.5849\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0378 - val_accuracy: 0.5849\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0180 - val_accuracy: 0.5849\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0816 - val_accuracy: 0.6226\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0515 - val_accuracy: 0.5849\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.0453 - val_accuracy: 0.5849\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.0851 - val_accuracy: 0.5849\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0891 - val_accuracy: 0.6038\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.0677 - val_accuracy: 0.5849\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.0305 - val_accuracy: 0.6038\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.0444 - val_accuracy: 0.6038\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0680 - val_accuracy: 0.5849\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.0816 - val_accuracy: 0.5849\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.0646 - val_accuracy: 0.6038\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0592 - val_accuracy: 0.6038\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0753 - val_accuracy: 0.6038\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.0813 - val_accuracy: 0.6038\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.0511 - val_accuracy: 0.6038\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.1120 - val_accuracy: 0.5849\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.1812 - val_accuracy: 0.6038\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.1609 - val_accuracy: 0.5849\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2149 - val_accuracy: 0.6226\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1674 - val_accuracy: 0.6038\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1668 - val_accuracy: 0.5849\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.1728 - val_accuracy: 0.5849\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.1614 - val_accuracy: 0.6038\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 9.9646e-04 - accuracy: 1.0000 - val_loss: 3.1609 - val_accuracy: 0.6038\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 9.7230e-04 - accuracy: 1.0000 - val_loss: 3.1605 - val_accuracy: 0.6038\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 9.7252e-04 - accuracy: 1.0000 - val_loss: 3.1513 - val_accuracy: 0.6038\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 9.4933e-04 - accuracy: 1.0000 - val_loss: 3.1705 - val_accuracy: 0.6038\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 9.0850e-04 - accuracy: 1.0000 - val_loss: 3.2019 - val_accuracy: 0.5849\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2024 - val_accuracy: 0.5849\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.1991 - val_accuracy: 0.6038\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 8.9769e-04 - accuracy: 1.0000 - val_loss: 3.2099 - val_accuracy: 0.6038\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 8.6894e-04 - accuracy: 1.0000 - val_loss: 3.1968 - val_accuracy: 0.6038\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 8.4302e-04 - accuracy: 1.0000 - val_loss: 3.2320 - val_accuracy: 0.5849\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2032 - val_accuracy: 0.6038\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 8.3704e-04 - accuracy: 1.0000 - val_loss: 3.2061 - val_accuracy: 0.6038\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 8.1613e-04 - accuracy: 1.0000 - val_loss: 3.2391 - val_accuracy: 0.6038\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 8.2294e-04 - accuracy: 1.0000 - val_loss: 3.2131 - val_accuracy: 0.6038\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 7.7488e-04 - accuracy: 1.0000 - val_loss: 3.2122 - val_accuracy: 0.6038\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 7.9112e-04 - accuracy: 1.0000 - val_loss: 3.2327 - val_accuracy: 0.6038\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 7.7465e-04 - accuracy: 1.0000 - val_loss: 3.2613 - val_accuracy: 0.6038\n",
      "Epoch 399/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 36ms/step - loss: 8.0325e-04 - accuracy: 1.0000 - val_loss: 3.2738 - val_accuracy: 0.6038\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 7.8580e-04 - accuracy: 1.0000 - val_loss: 3.2649 - val_accuracy: 0.6038\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 7.7435e-04 - accuracy: 1.0000 - val_loss: 3.2478 - val_accuracy: 0.6038\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.2063 - val_accuracy: 0.6038\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 7.8935e-04 - accuracy: 1.0000 - val_loss: 3.2662 - val_accuracy: 0.6038\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 7.5161e-04 - accuracy: 1.0000 - val_loss: 3.2984 - val_accuracy: 0.6038\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 7.6629e-04 - accuracy: 1.0000 - val_loss: 3.3083 - val_accuracy: 0.6038\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 7.7616e-04 - accuracy: 1.0000 - val_loss: 3.2418 - val_accuracy: 0.6038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f897ed1b8b0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_122.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_122.fit(X_train_over, y_train_over, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5552e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6217 - accuracy: 0.7119\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6276 - accuracy: 0.7170\n"
     ]
    }
   ],
   "source": [
    "m1_eval_test = model_122.evaluate(X_test, y_test)\n",
    "m1_eval_val = model_122.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b03e8",
   "metadata": {},
   "source": [
    "**For test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "780a2b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "roc auc score:  0.7192982456140351\n",
      "average precision score:  0.7275895804819803\n"
     ]
    }
   ],
   "source": [
    "pred = model_122.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d0736fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "20b00039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6217 - accuracy: 0.7119\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_122.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd60a68",
   "metadata": {},
   "source": [
    "**For validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7a236806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n",
      "roc auc score:  0.7142857142857142\n",
      "average precision score:  0.6830003635506698\n"
     ]
    }
   ],
   "source": [
    "pred = model_122.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "20837b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b011d7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6276 - accuracy: 0.7170\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels (validation set)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_122.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f6932",
   "metadata": {},
   "source": [
    "**Model saving:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f0b22f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_121_json = model_121.to_json()\n",
    "with open(\"model_121.json\", \"w\") as json_file:\n",
    "    json_file.write(model_121_json)\n",
    "# serialize weights to HDF5\n",
    "model_121.save_weights(\"model_121.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f8a31bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_122_json = model_122.to_json()\n",
    "with open(\"model_122.json\", \"w\") as json_file:\n",
    "    json_file.write(model_122_json)\n",
    "# serialize weights to HDF5\n",
    "model_122.save_weights(\"model_122.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269b3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
