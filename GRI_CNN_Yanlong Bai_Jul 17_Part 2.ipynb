{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9840c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a976c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   ## data analysis and manipulation\n",
    "import numpy as np    ## numerial computing\n",
    "import seaborn as sns ##  data visualization library based on matplotlib\n",
    "import tensorflow.keras as keras ## main deep learning API\n",
    "\n",
    "## additional functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d586bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5cf378e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EID</th>\n",
       "      <th>PID</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Eye</th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Scan.Type</th>\n",
       "      <th>Diameter..mm.</th>\n",
       "      <th>Diameter....</th>\n",
       "      <th>Fixed.in.mm</th>\n",
       "      <th>ExamDate</th>\n",
       "      <th>...</th>\n",
       "      <th>VF_OCT_BASELINE_DIFF</th>\n",
       "      <th>VF_OCT_FINAL_DIFF</th>\n",
       "      <th>MD_BASELINE</th>\n",
       "      <th>MD_FINAL</th>\n",
       "      <th>VFI_BASELINE</th>\n",
       "      <th>VFI_FINAL</th>\n",
       "      <th>Y_GRI</th>\n",
       "      <th>Y_MD</th>\n",
       "      <th>Y_VFI</th>\n",
       "      <th>Y_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10/24/1949</td>\n",
       "      <td>LE</td>\n",
       "      <td>282596.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.561944</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10/24/1949</td>\n",
       "      <td>RE</td>\n",
       "      <td>282593.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.561944</td>\n",
       "      <td>-7.73</td>\n",
       "      <td>-11.45</td>\n",
       "      <td>82</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8/7/1939</td>\n",
       "      <td>LE</td>\n",
       "      <td>239514.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.151951</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8/7/1939</td>\n",
       "      <td>RE</td>\n",
       "      <td>239512.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.151951</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.60</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5/20/1943</td>\n",
       "      <td>LE</td>\n",
       "      <td>238460.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7/9/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024641</td>\n",
       "      <td>6.266940</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>580</td>\n",
       "      <td>329</td>\n",
       "      <td>3/22/1952</td>\n",
       "      <td>RE</td>\n",
       "      <td>837.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5/5/2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.601643</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>98</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>581</td>\n",
       "      <td>330</td>\n",
       "      <td>5/15/1945</td>\n",
       "      <td>LE</td>\n",
       "      <td>243095.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12/17/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.941136</td>\n",
       "      <td>-8.97</td>\n",
       "      <td>-14.71</td>\n",
       "      <td>78</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>582</td>\n",
       "      <td>330</td>\n",
       "      <td>5/15/1945</td>\n",
       "      <td>RE</td>\n",
       "      <td>243093.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12/17/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.941136</td>\n",
       "      <td>-11.39</td>\n",
       "      <td>-11.37</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>583</td>\n",
       "      <td>331</td>\n",
       "      <td>5/31/1939</td>\n",
       "      <td>LE</td>\n",
       "      <td>109347.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/13/2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172485</td>\n",
       "      <td>6.193018</td>\n",
       "      <td>-3.48</td>\n",
       "      <td>-19.28</td>\n",
       "      <td>97</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>584</td>\n",
       "      <td>331</td>\n",
       "      <td>5/31/1939</td>\n",
       "      <td>RE</td>\n",
       "      <td>109343.2</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/13/2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172485</td>\n",
       "      <td>6.193018</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>-16.15</td>\n",
       "      <td>93</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EID  PID         DOB Eye   ImageID        Scan.Type  Diameter..mm.  \\\n",
       "0      1    1  10/24/1949  LE  282596.0  OCT Circle Scan            3.7   \n",
       "1      2    1  10/24/1949  RE  282593.0  OCT Circle Scan            3.7   \n",
       "2      3    2    8/7/1939  LE  239514.0  OCT Circle Scan            3.4   \n",
       "3      4    2    8/7/1939  RE  239512.0  OCT Circle Scan            3.4   \n",
       "4      5    3   5/20/1943  LE  238460.0  OCT Circle Scan            3.5   \n",
       "..   ...  ...         ...  ..       ...              ...            ...   \n",
       "579  580  329   3/22/1952  RE     837.0  OCT Circle Scan            3.7   \n",
       "580  581  330   5/15/1945  LE  243095.0  OCT Circle Scan            3.5   \n",
       "581  582  330   5/15/1945  RE  243093.0  OCT Circle Scan            3.7   \n",
       "582  583  331   5/31/1939  LE  109347.0  OCT Circle Scan            3.5   \n",
       "583  584  331   5/31/1939  RE  109343.2  OCT Circle Scan            3.5   \n",
       "\n",
       "     Diameter....  Fixed.in.mm    ExamDate  ... VF_OCT_BASELINE_DIFF  \\\n",
       "0            12.0            0   5/11/2017  ...             0.000000   \n",
       "1            12.0            0   5/11/2017  ...             0.000000   \n",
       "2            12.0            0   8/26/2014  ...             0.000000   \n",
       "3            12.0            0   8/26/2014  ...             0.000000   \n",
       "4            12.0            0    7/9/2014  ...             0.024641   \n",
       "..            ...          ...         ...  ...                  ...   \n",
       "579          12.0            0    5/5/2011  ...             0.000000   \n",
       "580          12.0            0  12/17/2014  ...             0.000000   \n",
       "581          12.0            0  12/17/2014  ...             0.000000   \n",
       "582          12.0            0   8/13/2013  ...             0.172485   \n",
       "583          12.0            0   8/13/2013  ...             0.172485   \n",
       "\n",
       "    VF_OCT_FINAL_DIFF  MD_BASELINE  MD_FINAL  VFI_BASELINE  VFI_FINAL  Y_GRI  \\\n",
       "0            3.561944        -2.15     -3.26            98         96      0   \n",
       "1            3.561944        -7.73    -11.45            82         73      1   \n",
       "2            6.151951        -1.28     -1.13            98         97      0   \n",
       "3            6.151951        -0.72      0.60            98         99      0   \n",
       "4            6.266940        -1.69     -0.51            99         99      0   \n",
       "..                ...          ...       ...           ...        ...    ...   \n",
       "579          9.601643         0.53     -2.51            98         93      1   \n",
       "580          5.941136        -8.97    -14.71            78         56      1   \n",
       "581          5.941136       -11.39    -11.37            70         67      1   \n",
       "582          6.193018        -3.48    -19.28            97         51      1   \n",
       "583          6.193018        -3.34    -16.15            93         47      1   \n",
       "\n",
       "     Y_MD  Y_VFI  Y_combined  \n",
       "0       0      0           0  \n",
       "1       0      0           1  \n",
       "2       0      0           0  \n",
       "3       0      0           0  \n",
       "4       0      0           0  \n",
       "..    ...    ...         ...  \n",
       "579     0      0           1  \n",
       "580     1      1           1  \n",
       "581     0      0           1  \n",
       "582     1      1           1  \n",
       "583     1      1           1  \n",
       "\n",
       "[584 rows x 815 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "df = pd.read_csv(\"/Users/a123456/Desktop/Fei's Project/Data/OCT_BASELINE_GRI__VF_6-3_FP-15_NO_PHI_CombinedProgression.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3ffa55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 815)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter only circle scan data\n",
    "circle_scan = (df['Scan.Type'] == 'OCT Circle Scan')\n",
    "df = df[circle_scan]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9781e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6696c49",
   "metadata": {},
   "source": [
    "## 2. GRI only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa471d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>RNFLT.1</th>\n",
       "      <th>RNFLT.2</th>\n",
       "      <th>RNFLT.3</th>\n",
       "      <th>RNFLT.4</th>\n",
       "      <th>RNFLT.5</th>\n",
       "      <th>RNFLT.6</th>\n",
       "      <th>RNFLT.7</th>\n",
       "      <th>RNFLT.8</th>\n",
       "      <th>RNFLT.9</th>\n",
       "      <th>...</th>\n",
       "      <th>RNFLT.761</th>\n",
       "      <th>RNFLT.762</th>\n",
       "      <th>RNFLT.763</th>\n",
       "      <th>RNFLT.764</th>\n",
       "      <th>RNFLT.765</th>\n",
       "      <th>RNFLT.766</th>\n",
       "      <th>RNFLT.767</th>\n",
       "      <th>RNFLT.768</th>\n",
       "      <th>GRI</th>\n",
       "      <th>Y_GRI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-3.688171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.329429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.581343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>329</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-11.691467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>330</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-19.908699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>330</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-10.130481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>331</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-24.731627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>331</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-18.674765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PID  RNFLT.1  RNFLT.2  RNFLT.3  RNFLT.4  RNFLT.5  RNFLT.6  RNFLT.7  \\\n",
       "0      1     47.0     47.0     46.0     46.0     45.0     45.0     45.0   \n",
       "1      1     70.0     71.0     72.0     72.0     73.0     73.0     73.0   \n",
       "2      2     44.0     45.0     45.0     45.0     46.0     47.0     48.0   \n",
       "3      2     44.0     44.0     44.0     45.0     45.0     46.0     46.0   \n",
       "4      3     37.0     38.0     39.0     40.0     41.0     42.0     43.0   \n",
       "..   ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "579  329    100.0    103.0    106.0    108.0    111.0    112.0    113.0   \n",
       "580  330     52.0     52.0     53.0     54.0     55.0     56.0     57.0   \n",
       "581  330     62.0     63.0     64.0     65.0     66.0     67.0     68.0   \n",
       "582  331     47.0     47.0     48.0     48.0     49.0     49.0     50.0   \n",
       "583  331     31.0     31.0     32.0     33.0     33.0     34.0     35.0   \n",
       "\n",
       "     RNFLT.8  RNFLT.9  ...  RNFLT.761  RNFLT.762  RNFLT.763  RNFLT.764  \\\n",
       "0       45.0     45.0  ...       48.0       48.0       48.0       48.0   \n",
       "1       73.0     74.0  ...       60.0       61.0       62.0       63.0   \n",
       "2       50.0     51.0  ...       45.0       45.0       45.0       45.0   \n",
       "3       47.0     47.0  ...       43.0       43.0       43.0       43.0   \n",
       "4       44.0     46.0  ...       35.0       35.0       35.0       35.0   \n",
       "..       ...      ...  ...        ...        ...        ...        ...   \n",
       "579    113.0    113.0  ...       83.0       84.0       86.0       87.0   \n",
       "580     58.0     59.0  ...       47.0       47.0       48.0       48.0   \n",
       "581     68.0     68.0  ...       55.0       56.0       57.0       58.0   \n",
       "582     50.0     50.0  ...       47.0       46.0       46.0       45.0   \n",
       "583     36.0     37.0  ...       31.0       31.0       30.0       30.0   \n",
       "\n",
       "     RNFLT.765  RNFLT.766  RNFLT.767  RNFLT.768        GRI  Y_GRI  \n",
       "0         48.0       48.0       48.0       47.0  -3.688171      0  \n",
       "1         65.0       66.0       67.0       69.0  -6.827438      1  \n",
       "2         45.0       45.0       45.0       44.0   0.329429      0  \n",
       "3         43.0       43.0       43.0       43.0   0.581343      0  \n",
       "4         35.0       35.0       36.0       36.0   0.000000      0  \n",
       "..         ...        ...        ...        ...        ...    ...  \n",
       "579       89.0       92.0       94.0       97.0 -11.691467      1  \n",
       "580       49.0       49.0       50.0       51.0 -19.908699      1  \n",
       "581       58.0       59.0       60.0       61.0 -10.130481      1  \n",
       "582       45.0       46.0       46.0       46.0 -24.731627      1  \n",
       "583       30.0       30.0       30.0       30.0 -18.674765      1  \n",
       "\n",
       "[580 rows x 771 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.iloc[:, np.r_[1, 28:797, 811]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6de403b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 771)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop missing values\n",
    "df = df.dropna()\n",
    "df.isnull().values.sum()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63f3e747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "579    1\n",
       "580    1\n",
       "581    1\n",
       "582    1\n",
       "583    1\n",
       "Name: Y_GRI, Length: 575, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:, 770]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "803f58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/applied-systems-biology/Dynamic_SPHARM/blob/master/SPHARM/classes/stratified_group_shuffle_split.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "class GroupShuffleSplitStratified(StratifiedShuffleSplit):\n",
    "\n",
    "    def __init__(self, n_splits=5, test_size=2, train_size=None, random_state=None):\n",
    "\n",
    "        super(GroupShuffleSplitStratified, self).__init__(\n",
    "            n_splits=n_splits,\n",
    "            test_size=test_size,\n",
    "            train_size=train_size,\n",
    "            random_state=random_state)\n",
    "\n",
    "    def _iter_indices(self, X, y, groups):\n",
    "        if groups is None:\n",
    "            raise ValueError(\"The 'groups' parameter should not be None.\")\n",
    "        groups = check_array(groups, ensure_2d=False, dtype=None)\n",
    "        groups_unique, group_indices = np.unique(groups, return_inverse=True)\n",
    "        classes = []\n",
    "        for gr in groups_unique:\n",
    "            classes.append(y[np.where(groups==gr)[0][0]])\n",
    "\n",
    "        for group_train, group_test in super(\n",
    "                GroupShuffleSplitStratified, self)._iter_indices(X=groups_unique, y=classes):\n",
    "            # these are the indices of classes in the partition\n",
    "            # invert them into data indices\n",
    "\n",
    "            train = np.flatnonzero(np.in1d(group_indices, group_train))\n",
    "            test = np.flatnonzero(np.in1d(group_indices, group_test))\n",
    "\n",
    "            yield train, test\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        return super(GroupShuffleSplitStratified, self).split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d658ccda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(523, 771)\n",
      "(52, 771)\n"
     ]
    }
   ],
   "source": [
    "train_i,test_i = next(GroupShuffleSplitStratified(n_splits=2, test_size=0.1,\n",
    "                                        random_state=8).split(df,y, groups=df['PID']))\n",
    "TrainVal = df.iloc[train_i]\n",
    "TestSet = df.iloc[test_i]\n",
    "print(TrainVal.shape)\n",
    "print(TestSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c2cf044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 771)\n",
      "(55, 771)\n"
     ]
    }
   ],
   "source": [
    "train_id,val_id = next(GroupShuffleSplitStratified(n_splits=2, test_size=0.1,\n",
    "                                        random_state=8).split(TrainVal,y.iloc[train_i], groups=TrainVal['PID']))\n",
    "TrainSet = TrainVal.iloc[train_id]\n",
    "ValSet = TrainVal.iloc[val_id]\n",
    "print(TrainSet.shape)\n",
    "print(ValSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf74753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(52, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNFLT.1</th>\n",
       "      <th>RNFLT.2</th>\n",
       "      <th>RNFLT.3</th>\n",
       "      <th>RNFLT.4</th>\n",
       "      <th>RNFLT.5</th>\n",
       "      <th>RNFLT.6</th>\n",
       "      <th>RNFLT.7</th>\n",
       "      <th>RNFLT.8</th>\n",
       "      <th>RNFLT.9</th>\n",
       "      <th>RNFLT.10</th>\n",
       "      <th>...</th>\n",
       "      <th>RNFLT.759</th>\n",
       "      <th>RNFLT.760</th>\n",
       "      <th>RNFLT.761</th>\n",
       "      <th>RNFLT.762</th>\n",
       "      <th>RNFLT.763</th>\n",
       "      <th>RNFLT.764</th>\n",
       "      <th>RNFLT.765</th>\n",
       "      <th>RNFLT.766</th>\n",
       "      <th>RNFLT.767</th>\n",
       "      <th>RNFLT.768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RNFLT.1  RNFLT.2  RNFLT.3  RNFLT.4  RNFLT.5  RNFLT.6  RNFLT.7  RNFLT.8  \\\n",
       "26     34.0     34.0     35.0     35.0     36.0     36.0     37.0     38.0   \n",
       "27     42.0     43.0     44.0     45.0     46.0     46.0     47.0     47.0   \n",
       "51     34.0     35.0     37.0     40.0     42.0     44.0     46.0     47.0   \n",
       "52     52.0     52.0     52.0     52.0     52.0     52.0     51.0     51.0   \n",
       "62     53.0     53.0     53.0     54.0     54.0     55.0     56.0     56.0   \n",
       "\n",
       "    RNFLT.9  RNFLT.10  ...  RNFLT.759  RNFLT.760  RNFLT.761  RNFLT.762  \\\n",
       "26     39.0      39.0  ...       34.0       33.0       33.0       33.0   \n",
       "27     48.0      48.0  ...       41.0       40.0       40.0       40.0   \n",
       "51     48.0      48.0  ...       29.0       29.0       28.0       28.0   \n",
       "52     51.0      51.0  ...       52.0       53.0       53.0       53.0   \n",
       "62     57.0      58.0  ...       55.0       55.0       55.0       55.0   \n",
       "\n",
       "    RNFLT.763  RNFLT.764  RNFLT.765  RNFLT.766  RNFLT.767  RNFLT.768  \n",
       "26       32.0       32.0       32.0       33.0       33.0       33.0  \n",
       "27       40.0       40.0       40.0       40.0       41.0       41.0  \n",
       "51       28.0       29.0       29.0       30.0       31.0       32.0  \n",
       "52       53.0       53.0       53.0       53.0       52.0       52.0  \n",
       "62       54.0       54.0       54.0       53.0       53.0       53.0  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.iloc[test_i, 1:769]\n",
    "print(x.isnull().values.sum())\n",
    "print(x.shape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e098a3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_test = scaled_x\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cfa912fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = TrainVal.iloc[train_id, 1:769]\n",
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_train = scaled_x\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "edfc56d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = TrainVal.iloc[val_id, 1:769]\n",
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_val = scaled_x\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "925c2608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1\n",
      "1  0    407\n",
      "0  1    168\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1\n",
       "0    1  0\n",
       "1    0  1\n",
       "2    1  0\n",
       "3    1  0\n",
       "4    1  0\n",
       "..  .. ..\n",
       "579  0  1\n",
       "580  0  1\n",
       "581  0  1\n",
       "582  0  1\n",
       "583  0  1\n",
       "\n",
       "[575 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot-encoding our label\n",
    "y = pd.get_dummies(y)\n",
    "print(y.value_counts())\n",
    "y #The second column is 'progressor', The first column is 'non-progressor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7e12a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "0                 1           0\n",
       "1                 0           1\n",
       "2                 1           0\n",
       "3                 1           0\n",
       "4                 1           0\n",
       "..              ...         ...\n",
       "579               0           1\n",
       "580               0           1\n",
       "581               0           1\n",
       "582               0           1\n",
       "583               0           1\n",
       "\n",
       "[575 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.rename(columns={0: \"Non-Progressor\", 1: \"Progressor\"})\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10b88c1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "26                1           0\n",
       "27                1           0\n",
       "51                0           1\n",
       "52                1           0\n",
       "62                0           1\n",
       "63                1           0\n",
       "118               1           0\n",
       "143               0           1\n",
       "144               1           0\n",
       "145               1           0\n",
       "146               1           0\n",
       "196               1           0\n",
       "199               1           0\n",
       "200               1           0\n",
       "201               1           0\n",
       "221               1           0\n",
       "222               1           0\n",
       "249               1           0\n",
       "250               1           0\n",
       "251               1           0\n",
       "252               1           0\n",
       "258               1           0\n",
       "259               1           0\n",
       "260               1           0\n",
       "261               1           0\n",
       "263               0           1\n",
       "264               1           0\n",
       "273               1           0\n",
       "274               1           0\n",
       "277               0           1\n",
       "278               1           0\n",
       "288               0           1\n",
       "312               1           0\n",
       "313               0           1\n",
       "320               1           0\n",
       "321               1           0\n",
       "334               0           1\n",
       "335               0           1\n",
       "339               1           0\n",
       "340               1           0\n",
       "370               1           0\n",
       "437               1           0\n",
       "478               1           0\n",
       "479               0           1\n",
       "482               0           1\n",
       "489               1           0\n",
       "501               1           0\n",
       "519               0           1\n",
       "532               0           1\n",
       "533               0           1\n",
       "544               1           0\n",
       "545               1           0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y.iloc[test_i]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f30e5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "0                 1           0\n",
       "1                 0           1\n",
       "2                 1           0\n",
       "3                 1           0\n",
       "4                 1           0\n",
       "..              ...         ...\n",
       "579               0           1\n",
       "580               0           1\n",
       "581               0           1\n",
       "582               0           1\n",
       "583               0           1\n",
       "\n",
       "[468 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y.iloc[train_i].iloc[train_id]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8ec45d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "12                0           1\n",
       "16                0           1\n",
       "17                1           0\n",
       "28                1           0\n",
       "29                1           0\n",
       "49                0           1\n",
       "50                1           0\n",
       "60                0           1\n",
       "88                0           1\n",
       "89                1           0\n",
       "109               0           1\n",
       "110               0           1\n",
       "121               1           0\n",
       "141               0           1\n",
       "142               0           1\n",
       "154               1           0\n",
       "155               0           1\n",
       "156               1           0\n",
       "157               1           0\n",
       "215               1           0\n",
       "216               1           0\n",
       "217               1           0\n",
       "218               1           0\n",
       "219               1           0\n",
       "220               1           0\n",
       "242               1           0\n",
       "243               1           0\n",
       "279               1           0\n",
       "280               1           0\n",
       "281               1           0\n",
       "282               1           0\n",
       "287               1           0\n",
       "289               1           0\n",
       "290               1           0\n",
       "302               1           0\n",
       "303               1           0\n",
       "349               0           1\n",
       "350               0           1\n",
       "358               1           0\n",
       "359               0           1\n",
       "366               1           0\n",
       "367               1           0\n",
       "368               1           0\n",
       "369               0           1\n",
       "391               1           0\n",
       "392               0           1\n",
       "429               1           0\n",
       "472               0           1\n",
       "473               1           0\n",
       "494               1           0\n",
       "495               1           0\n",
       "528               1           0\n",
       "529               0           1\n",
       "540               1           0\n",
       "541               1           0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = y.iloc[train_i].iloc[val_id]\n",
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a768318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 768, 1)\n",
      "(52, 768, 1)\n",
      "(55, 768, 1)\n",
      "Non-Progressor  Progressor\n",
      "1               0             331\n",
      "0               1             137\n",
      "dtype: int64 \n",
      "\n",
      "Non-Progressor  Progressor\n",
      "1               0             38\n",
      "0               1             17\n",
      "dtype: int64 \n",
      "\n",
      "Non-Progressor  Progressor\n",
      "1               0             38\n",
      "0               1             14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.value_counts(), '\\n')\n",
    "print(y_val.value_counts(), '\\n')\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc9ee0",
   "metadata": {},
   "source": [
    "### 2.1 No resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b3818c",
   "metadata": {},
   "source": [
    "#### 2.1.1 Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e158ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=400,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "756d1a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 766, 64)           256       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 255, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 255, 64)           0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 16320)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                1044544   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,045,874\n",
      "Trainable params: 1,045,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model1\n",
    "model_211 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_211.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_211.add(MaxPooling1D(pool_size=3))\n",
    "# model_1.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_211.add(Dropout(0.5))\n",
    "# model_1.add(MaxPooling1D(pool_size=2))\n",
    "model_211.add(Flatten())\n",
    "model_211.add(Dense(64, activation='relu'))\n",
    "model_211.add(Dense(16, activation='relu'))\n",
    "model_211.add(Dense(2, activation='softmax'))\n",
    "model_211.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5fbc25a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15/15 [==============================] - 1s 32ms/step - loss: 0.6613 - accuracy: 0.6774 - val_loss: 0.6152 - val_accuracy: 0.6909\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.6031 - accuracy: 0.7073 - val_loss: 0.6077 - val_accuracy: 0.6909\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5974 - accuracy: 0.7073 - val_loss: 0.6077 - val_accuracy: 0.6909\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5971 - accuracy: 0.7073 - val_loss: 0.6050 - val_accuracy: 0.6909\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5945 - accuracy: 0.7073 - val_loss: 0.6047 - val_accuracy: 0.6909\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5955 - accuracy: 0.7073 - val_loss: 0.6035 - val_accuracy: 0.6909\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5944 - accuracy: 0.7073 - val_loss: 0.6038 - val_accuracy: 0.6909\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5926 - accuracy: 0.7073 - val_loss: 0.6027 - val_accuracy: 0.6909\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5904 - accuracy: 0.7073 - val_loss: 0.6009 - val_accuracy: 0.6909\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5909 - accuracy: 0.7073 - val_loss: 0.6015 - val_accuracy: 0.6909\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5895 - accuracy: 0.7073 - val_loss: 0.5994 - val_accuracy: 0.6909\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5877 - accuracy: 0.7073 - val_loss: 0.5992 - val_accuracy: 0.6909\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.5855 - accuracy: 0.7073 - val_loss: 0.5985 - val_accuracy: 0.6909\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5870 - accuracy: 0.7073 - val_loss: 0.5965 - val_accuracy: 0.6909\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5837 - accuracy: 0.7073 - val_loss: 0.5963 - val_accuracy: 0.6909\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5822 - accuracy: 0.7073 - val_loss: 0.5958 - val_accuracy: 0.6909\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5803 - accuracy: 0.7073 - val_loss: 0.5942 - val_accuracy: 0.6909\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5798 - accuracy: 0.7073 - val_loss: 0.5972 - val_accuracy: 0.6909\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5774 - accuracy: 0.7073 - val_loss: 0.5931 - val_accuracy: 0.6909\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5780 - accuracy: 0.7073 - val_loss: 0.5916 - val_accuracy: 0.6909\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5743 - accuracy: 0.7073 - val_loss: 0.5966 - val_accuracy: 0.6909\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5730 - accuracy: 0.7094 - val_loss: 0.5912 - val_accuracy: 0.6909\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5748 - accuracy: 0.7073 - val_loss: 0.5921 - val_accuracy: 0.6909\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5720 - accuracy: 0.7094 - val_loss: 0.5893 - val_accuracy: 0.6909\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5685 - accuracy: 0.7115 - val_loss: 0.5900 - val_accuracy: 0.6909\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5672 - accuracy: 0.7094 - val_loss: 0.5909 - val_accuracy: 0.6909\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5649 - accuracy: 0.7115 - val_loss: 0.5890 - val_accuracy: 0.6909\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5682 - accuracy: 0.7094 - val_loss: 0.5893 - val_accuracy: 0.6909\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5652 - accuracy: 0.7115 - val_loss: 0.5891 - val_accuracy: 0.6909\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5592 - accuracy: 0.7158 - val_loss: 0.5857 - val_accuracy: 0.6909\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5575 - accuracy: 0.7137 - val_loss: 0.5891 - val_accuracy: 0.6909\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5593 - accuracy: 0.7137 - val_loss: 0.5852 - val_accuracy: 0.6909\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5585 - accuracy: 0.7179 - val_loss: 0.5867 - val_accuracy: 0.6909\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.5529 - accuracy: 0.7115 - val_loss: 0.5870 - val_accuracy: 0.6909\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5542 - accuracy: 0.7201 - val_loss: 0.5828 - val_accuracy: 0.6909\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5560 - accuracy: 0.7201 - val_loss: 0.5880 - val_accuracy: 0.6909\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5548 - accuracy: 0.7158 - val_loss: 0.5867 - val_accuracy: 0.6909\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5502 - accuracy: 0.7222 - val_loss: 0.5863 - val_accuracy: 0.6909\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5458 - accuracy: 0.7308 - val_loss: 0.5847 - val_accuracy: 0.7091\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5425 - accuracy: 0.7222 - val_loss: 0.5886 - val_accuracy: 0.6909\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5425 - accuracy: 0.7222 - val_loss: 0.5844 - val_accuracy: 0.7091\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5452 - accuracy: 0.7415 - val_loss: 0.5820 - val_accuracy: 0.7091\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5383 - accuracy: 0.7265 - val_loss: 0.5887 - val_accuracy: 0.6909\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5386 - accuracy: 0.7329 - val_loss: 0.5844 - val_accuracy: 0.7091\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5348 - accuracy: 0.7244 - val_loss: 0.5833 - val_accuracy: 0.7091\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5355 - accuracy: 0.7415 - val_loss: 0.5855 - val_accuracy: 0.7091\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.5354 - accuracy: 0.7393 - val_loss: 0.5846 - val_accuracy: 0.7091\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5245 - accuracy: 0.7436 - val_loss: 0.5842 - val_accuracy: 0.7091\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5288 - accuracy: 0.7457 - val_loss: 0.5838 - val_accuracy: 0.6909\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5249 - accuracy: 0.7500 - val_loss: 0.5853 - val_accuracy: 0.6909\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5249 - accuracy: 0.7628 - val_loss: 0.5846 - val_accuracy: 0.6909\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5219 - accuracy: 0.7415 - val_loss: 0.5844 - val_accuracy: 0.6909\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5203 - accuracy: 0.7607 - val_loss: 0.5855 - val_accuracy: 0.6909\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5145 - accuracy: 0.7543 - val_loss: 0.5868 - val_accuracy: 0.6909\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5197 - accuracy: 0.7350 - val_loss: 0.5878 - val_accuracy: 0.6727\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5185 - accuracy: 0.7714 - val_loss: 0.5821 - val_accuracy: 0.6727\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5108 - accuracy: 0.7671 - val_loss: 0.5915 - val_accuracy: 0.6909\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5129 - accuracy: 0.7564 - val_loss: 0.5847 - val_accuracy: 0.6727\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5101 - accuracy: 0.7692 - val_loss: 0.5873 - val_accuracy: 0.6727\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5105 - accuracy: 0.7543 - val_loss: 0.5899 - val_accuracy: 0.6727\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5060 - accuracy: 0.7585 - val_loss: 0.5881 - val_accuracy: 0.6909\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5074 - accuracy: 0.7799 - val_loss: 0.5847 - val_accuracy: 0.6727\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5032 - accuracy: 0.7650 - val_loss: 0.5950 - val_accuracy: 0.6909\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5061 - accuracy: 0.7671 - val_loss: 0.5863 - val_accuracy: 0.6727\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5065 - accuracy: 0.7714 - val_loss: 0.5893 - val_accuracy: 0.6545\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4965 - accuracy: 0.7842 - val_loss: 0.5856 - val_accuracy: 0.6727\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4955 - accuracy: 0.7778 - val_loss: 0.5855 - val_accuracy: 0.6727\n",
      "Epoch 68/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5017 - accuracy: 0.7863 - val_loss: 0.5900 - val_accuracy: 0.6545\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4961 - accuracy: 0.7671 - val_loss: 0.5890 - val_accuracy: 0.6545\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4868 - accuracy: 0.7821 - val_loss: 0.5871 - val_accuracy: 0.6909\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4918 - accuracy: 0.7735 - val_loss: 0.5894 - val_accuracy: 0.6727\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4881 - accuracy: 0.7863 - val_loss: 0.5898 - val_accuracy: 0.6727\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4876 - accuracy: 0.7927 - val_loss: 0.5873 - val_accuracy: 0.6909\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4809 - accuracy: 0.7863 - val_loss: 0.5938 - val_accuracy: 0.6545\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4805 - accuracy: 0.7970 - val_loss: 0.5890 - val_accuracy: 0.6909\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4808 - accuracy: 0.7906 - val_loss: 0.5932 - val_accuracy: 0.6727\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4799 - accuracy: 0.8034 - val_loss: 0.5891 - val_accuracy: 0.6909\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4746 - accuracy: 0.7970 - val_loss: 0.5923 - val_accuracy: 0.6909\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4851 - accuracy: 0.7949 - val_loss: 0.5916 - val_accuracy: 0.6909\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4777 - accuracy: 0.7842 - val_loss: 0.5882 - val_accuracy: 0.7091\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4740 - accuracy: 0.7949 - val_loss: 0.5952 - val_accuracy: 0.6909\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4635 - accuracy: 0.8034 - val_loss: 0.5890 - val_accuracy: 0.7091\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4731 - accuracy: 0.7906 - val_loss: 0.5937 - val_accuracy: 0.7091\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4646 - accuracy: 0.8120 - val_loss: 0.5917 - val_accuracy: 0.7091\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4663 - accuracy: 0.7906 - val_loss: 0.5945 - val_accuracy: 0.7091\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4708 - accuracy: 0.8056 - val_loss: 0.5942 - val_accuracy: 0.7091\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4637 - accuracy: 0.7949 - val_loss: 0.5957 - val_accuracy: 0.7091\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4576 - accuracy: 0.8141 - val_loss: 0.5949 - val_accuracy: 0.7273\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4553 - accuracy: 0.8056 - val_loss: 0.6017 - val_accuracy: 0.7091\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4545 - accuracy: 0.8098 - val_loss: 0.5980 - val_accuracy: 0.7091\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4566 - accuracy: 0.8034 - val_loss: 0.5984 - val_accuracy: 0.7091\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4593 - accuracy: 0.8162 - val_loss: 0.6050 - val_accuracy: 0.7091\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4587 - accuracy: 0.8205 - val_loss: 0.5967 - val_accuracy: 0.7091\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4553 - accuracy: 0.8056 - val_loss: 0.5997 - val_accuracy: 0.7091\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4543 - accuracy: 0.8056 - val_loss: 0.5993 - val_accuracy: 0.7091\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4515 - accuracy: 0.8141 - val_loss: 0.6008 - val_accuracy: 0.7091\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4421 - accuracy: 0.8141 - val_loss: 0.6013 - val_accuracy: 0.7091\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4538 - accuracy: 0.8034 - val_loss: 0.5989 - val_accuracy: 0.7091\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4461 - accuracy: 0.8098 - val_loss: 0.6051 - val_accuracy: 0.7091\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4341 - accuracy: 0.8269 - val_loss: 0.6011 - val_accuracy: 0.7091\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4395 - accuracy: 0.8226 - val_loss: 0.6045 - val_accuracy: 0.7091\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4369 - accuracy: 0.8248 - val_loss: 0.6044 - val_accuracy: 0.7091\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4372 - accuracy: 0.8120 - val_loss: 0.6056 - val_accuracy: 0.7091\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4381 - accuracy: 0.8269 - val_loss: 0.6078 - val_accuracy: 0.7091\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4388 - accuracy: 0.8077 - val_loss: 0.6071 - val_accuracy: 0.6909\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4344 - accuracy: 0.8248 - val_loss: 0.6142 - val_accuracy: 0.7091\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4250 - accuracy: 0.8291 - val_loss: 0.6067 - val_accuracy: 0.7091\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4417 - accuracy: 0.8205 - val_loss: 0.6086 - val_accuracy: 0.7091\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4303 - accuracy: 0.8226 - val_loss: 0.6070 - val_accuracy: 0.6727\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4342 - accuracy: 0.8162 - val_loss: 0.6136 - val_accuracy: 0.7091\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4256 - accuracy: 0.8205 - val_loss: 0.6056 - val_accuracy: 0.6727\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4255 - accuracy: 0.8248 - val_loss: 0.6124 - val_accuracy: 0.7091\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4259 - accuracy: 0.8269 - val_loss: 0.6116 - val_accuracy: 0.7273\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4194 - accuracy: 0.8462 - val_loss: 0.6099 - val_accuracy: 0.6909\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4217 - accuracy: 0.8355 - val_loss: 0.6108 - val_accuracy: 0.7091\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4155 - accuracy: 0.8312 - val_loss: 0.6136 - val_accuracy: 0.6727\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4190 - accuracy: 0.8397 - val_loss: 0.6134 - val_accuracy: 0.7091\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4142 - accuracy: 0.8269 - val_loss: 0.6110 - val_accuracy: 0.6545\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4135 - accuracy: 0.8355 - val_loss: 0.6125 - val_accuracy: 0.7091\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4095 - accuracy: 0.8312 - val_loss: 0.6121 - val_accuracy: 0.7091\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4166 - accuracy: 0.8269 - val_loss: 0.6138 - val_accuracy: 0.6909\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4061 - accuracy: 0.8291 - val_loss: 0.6159 - val_accuracy: 0.6545\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4028 - accuracy: 0.8355 - val_loss: 0.6185 - val_accuracy: 0.6909\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4067 - accuracy: 0.8269 - val_loss: 0.6153 - val_accuracy: 0.6727\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3933 - accuracy: 0.8440 - val_loss: 0.6265 - val_accuracy: 0.6727\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4035 - accuracy: 0.8419 - val_loss: 0.6214 - val_accuracy: 0.6909\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.3957 - accuracy: 0.8483 - val_loss: 0.6243 - val_accuracy: 0.7091\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3940 - accuracy: 0.8504 - val_loss: 0.6206 - val_accuracy: 0.6727\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4010 - accuracy: 0.8504 - val_loss: 0.6270 - val_accuracy: 0.6909\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3987 - accuracy: 0.8440 - val_loss: 0.6252 - val_accuracy: 0.6909\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3977 - accuracy: 0.8440 - val_loss: 0.6283 - val_accuracy: 0.6909\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3936 - accuracy: 0.8355 - val_loss: 0.6253 - val_accuracy: 0.6545\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3914 - accuracy: 0.8440 - val_loss: 0.6254 - val_accuracy: 0.6909\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3915 - accuracy: 0.8333 - val_loss: 0.6240 - val_accuracy: 0.6727\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3965 - accuracy: 0.8504 - val_loss: 0.6323 - val_accuracy: 0.6909\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3855 - accuracy: 0.8462 - val_loss: 0.6274 - val_accuracy: 0.6727\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3899 - accuracy: 0.8440 - val_loss: 0.6302 - val_accuracy: 0.6727\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3874 - accuracy: 0.8547 - val_loss: 0.6331 - val_accuracy: 0.6727\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3890 - accuracy: 0.8483 - val_loss: 0.6283 - val_accuracy: 0.6545\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3816 - accuracy: 0.8590 - val_loss: 0.6283 - val_accuracy: 0.6727\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3758 - accuracy: 0.8504 - val_loss: 0.6292 - val_accuracy: 0.6727\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3822 - accuracy: 0.8590 - val_loss: 0.6339 - val_accuracy: 0.6727\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3777 - accuracy: 0.8568 - val_loss: 0.6312 - val_accuracy: 0.6545\n",
      "Epoch 144/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3703 - accuracy: 0.8611 - val_loss: 0.6402 - val_accuracy: 0.6545\n",
      "Epoch 145/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3753 - accuracy: 0.8654 - val_loss: 0.6321 - val_accuracy: 0.6727\n",
      "Epoch 146/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3788 - accuracy: 0.8568 - val_loss: 0.6371 - val_accuracy: 0.6545\n",
      "Epoch 147/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3702 - accuracy: 0.8547 - val_loss: 0.6343 - val_accuracy: 0.6545\n",
      "Epoch 148/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3650 - accuracy: 0.8526 - val_loss: 0.6361 - val_accuracy: 0.6909\n",
      "Epoch 149/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3601 - accuracy: 0.8590 - val_loss: 0.6374 - val_accuracy: 0.6727\n",
      "Epoch 150/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3734 - accuracy: 0.8440 - val_loss: 0.6359 - val_accuracy: 0.6909\n",
      "Epoch 151/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3690 - accuracy: 0.8397 - val_loss: 0.6446 - val_accuracy: 0.6727\n",
      "Epoch 152/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3681 - accuracy: 0.8739 - val_loss: 0.6414 - val_accuracy: 0.6545\n",
      "Epoch 153/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3638 - accuracy: 0.8632 - val_loss: 0.6416 - val_accuracy: 0.6909\n",
      "Epoch 154/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3477 - accuracy: 0.8739 - val_loss: 0.6417 - val_accuracy: 0.6909\n",
      "Epoch 155/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3659 - accuracy: 0.8632 - val_loss: 0.6418 - val_accuracy: 0.6909\n",
      "Epoch 156/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3462 - accuracy: 0.8761 - val_loss: 0.6449 - val_accuracy: 0.6545\n",
      "Epoch 157/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3616 - accuracy: 0.8611 - val_loss: 0.6429 - val_accuracy: 0.6909\n",
      "Epoch 158/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3481 - accuracy: 0.8697 - val_loss: 0.6432 - val_accuracy: 0.6545\n",
      "Epoch 159/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3500 - accuracy: 0.8739 - val_loss: 0.6448 - val_accuracy: 0.6545\n",
      "Epoch 160/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3602 - accuracy: 0.8654 - val_loss: 0.6529 - val_accuracy: 0.6727\n",
      "Epoch 161/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3467 - accuracy: 0.8590 - val_loss: 0.6463 - val_accuracy: 0.6909\n",
      "Epoch 162/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3445 - accuracy: 0.8675 - val_loss: 0.6532 - val_accuracy: 0.6727\n",
      "Epoch 163/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3477 - accuracy: 0.8654 - val_loss: 0.6466 - val_accuracy: 0.6727\n",
      "Epoch 164/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.3379 - accuracy: 0.8739 - val_loss: 0.6486 - val_accuracy: 0.6727\n",
      "Epoch 165/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3357 - accuracy: 0.8846 - val_loss: 0.6523 - val_accuracy: 0.6727\n",
      "Epoch 166/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3346 - accuracy: 0.8782 - val_loss: 0.6511 - val_accuracy: 0.6727\n",
      "Epoch 167/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3344 - accuracy: 0.8739 - val_loss: 0.6502 - val_accuracy: 0.6909\n",
      "Epoch 168/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3339 - accuracy: 0.8782 - val_loss: 0.6532 - val_accuracy: 0.6727\n",
      "Epoch 169/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3297 - accuracy: 0.8953 - val_loss: 0.6557 - val_accuracy: 0.6727\n",
      "Epoch 170/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3342 - accuracy: 0.8718 - val_loss: 0.6582 - val_accuracy: 0.6727\n",
      "Epoch 171/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3382 - accuracy: 0.8739 - val_loss: 0.6568 - val_accuracy: 0.6727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3373 - accuracy: 0.8761 - val_loss: 0.6669 - val_accuracy: 0.6909\n",
      "Epoch 173/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3206 - accuracy: 0.8932 - val_loss: 0.6593 - val_accuracy: 0.6727\n",
      "Epoch 174/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3361 - accuracy: 0.8825 - val_loss: 0.6630 - val_accuracy: 0.6909\n",
      "Epoch 175/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3345 - accuracy: 0.8825 - val_loss: 0.6641 - val_accuracy: 0.6727\n",
      "Epoch 176/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3383 - accuracy: 0.8654 - val_loss: 0.6685 - val_accuracy: 0.6727\n",
      "Epoch 177/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3307 - accuracy: 0.8825 - val_loss: 0.6606 - val_accuracy: 0.6727\n",
      "Epoch 178/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3266 - accuracy: 0.8803 - val_loss: 0.6649 - val_accuracy: 0.6727\n",
      "Epoch 179/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3244 - accuracy: 0.8718 - val_loss: 0.6645 - val_accuracy: 0.6909\n",
      "Epoch 180/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3124 - accuracy: 0.8868 - val_loss: 0.6733 - val_accuracy: 0.6909\n",
      "Epoch 181/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3137 - accuracy: 0.8868 - val_loss: 0.6691 - val_accuracy: 0.6727\n",
      "Epoch 182/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3207 - accuracy: 0.8846 - val_loss: 0.6705 - val_accuracy: 0.6909\n",
      "Epoch 183/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3123 - accuracy: 0.8953 - val_loss: 0.6693 - val_accuracy: 0.6545\n",
      "Epoch 184/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3182 - accuracy: 0.8825 - val_loss: 0.6726 - val_accuracy: 0.6909\n",
      "Epoch 185/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3121 - accuracy: 0.8889 - val_loss: 0.6680 - val_accuracy: 0.6545\n",
      "Epoch 186/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3085 - accuracy: 0.8846 - val_loss: 0.6703 - val_accuracy: 0.6727\n",
      "Epoch 187/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3182 - accuracy: 0.8739 - val_loss: 0.6784 - val_accuracy: 0.6909\n",
      "Epoch 188/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3074 - accuracy: 0.8803 - val_loss: 0.6771 - val_accuracy: 0.6909\n",
      "Epoch 189/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3138 - accuracy: 0.8889 - val_loss: 0.6837 - val_accuracy: 0.6364\n",
      "Epoch 190/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3043 - accuracy: 0.8910 - val_loss: 0.6785 - val_accuracy: 0.6727\n",
      "Epoch 191/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3066 - accuracy: 0.8846 - val_loss: 0.6864 - val_accuracy: 0.6545\n",
      "Epoch 192/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3032 - accuracy: 0.8910 - val_loss: 0.6835 - val_accuracy: 0.6727\n",
      "Epoch 193/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3007 - accuracy: 0.8974 - val_loss: 0.6913 - val_accuracy: 0.7091\n",
      "Epoch 194/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3043 - accuracy: 0.8868 - val_loss: 0.6884 - val_accuracy: 0.6909\n",
      "Epoch 195/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2995 - accuracy: 0.9167 - val_loss: 0.6838 - val_accuracy: 0.6545\n",
      "Epoch 196/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2994 - accuracy: 0.8932 - val_loss: 0.6931 - val_accuracy: 0.7091\n",
      "Epoch 197/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3012 - accuracy: 0.9017 - val_loss: 0.6902 - val_accuracy: 0.6545\n",
      "Epoch 198/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2949 - accuracy: 0.8889 - val_loss: 0.6940 - val_accuracy: 0.6727\n",
      "Epoch 199/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2850 - accuracy: 0.8996 - val_loss: 0.7021 - val_accuracy: 0.6909\n",
      "Epoch 200/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2950 - accuracy: 0.8974 - val_loss: 0.6967 - val_accuracy: 0.7091\n",
      "Epoch 201/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2834 - accuracy: 0.8996 - val_loss: 0.6929 - val_accuracy: 0.6545\n",
      "Epoch 202/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2985 - accuracy: 0.8932 - val_loss: 0.7011 - val_accuracy: 0.6727\n",
      "Epoch 203/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2906 - accuracy: 0.8974 - val_loss: 0.6992 - val_accuracy: 0.6364\n",
      "Epoch 204/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2936 - accuracy: 0.8996 - val_loss: 0.7032 - val_accuracy: 0.6364\n",
      "Epoch 205/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2842 - accuracy: 0.9060 - val_loss: 0.7034 - val_accuracy: 0.6727\n",
      "Epoch 206/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2816 - accuracy: 0.9038 - val_loss: 0.7015 - val_accuracy: 0.6545\n",
      "Epoch 207/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2833 - accuracy: 0.8974 - val_loss: 0.7066 - val_accuracy: 0.6545\n",
      "Epoch 208/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2853 - accuracy: 0.9017 - val_loss: 0.7038 - val_accuracy: 0.6545\n",
      "Epoch 209/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2797 - accuracy: 0.9038 - val_loss: 0.7182 - val_accuracy: 0.7091\n",
      "Epoch 210/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2807 - accuracy: 0.9145 - val_loss: 0.7126 - val_accuracy: 0.7091\n",
      "Epoch 211/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2779 - accuracy: 0.8932 - val_loss: 0.7099 - val_accuracy: 0.6545\n",
      "Epoch 212/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2769 - accuracy: 0.9060 - val_loss: 0.7160 - val_accuracy: 0.6909\n",
      "Epoch 213/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2696 - accuracy: 0.9124 - val_loss: 0.7207 - val_accuracy: 0.6909\n",
      "Epoch 214/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2835 - accuracy: 0.8996 - val_loss: 0.7098 - val_accuracy: 0.6364\n",
      "Epoch 215/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2796 - accuracy: 0.9038 - val_loss: 0.7109 - val_accuracy: 0.6545\n",
      "Epoch 216/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2675 - accuracy: 0.9038 - val_loss: 0.7163 - val_accuracy: 0.6909\n",
      "Epoch 217/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2699 - accuracy: 0.9081 - val_loss: 0.7157 - val_accuracy: 0.6364\n",
      "Epoch 218/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2730 - accuracy: 0.8974 - val_loss: 0.7196 - val_accuracy: 0.6364\n",
      "Epoch 219/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2600 - accuracy: 0.9145 - val_loss: 0.7214 - val_accuracy: 0.6545\n",
      "Epoch 220/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2674 - accuracy: 0.9038 - val_loss: 0.7216 - val_accuracy: 0.6727\n",
      "Epoch 221/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2626 - accuracy: 0.9124 - val_loss: 0.7287 - val_accuracy: 0.7091\n",
      "Epoch 222/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2674 - accuracy: 0.9038 - val_loss: 0.7204 - val_accuracy: 0.6545\n",
      "Epoch 223/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2633 - accuracy: 0.9103 - val_loss: 0.7382 - val_accuracy: 0.7091\n",
      "Epoch 224/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2752 - accuracy: 0.8996 - val_loss: 0.7197 - val_accuracy: 0.6364\n",
      "Epoch 225/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2591 - accuracy: 0.9167 - val_loss: 0.7307 - val_accuracy: 0.6727\n",
      "Epoch 226/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2578 - accuracy: 0.9209 - val_loss: 0.7402 - val_accuracy: 0.7091\n",
      "Epoch 227/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2538 - accuracy: 0.8996 - val_loss: 0.7299 - val_accuracy: 0.6545\n",
      "Epoch 228/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2586 - accuracy: 0.9124 - val_loss: 0.7308 - val_accuracy: 0.6727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2599 - accuracy: 0.8996 - val_loss: 0.7323 - val_accuracy: 0.6364\n",
      "Epoch 230/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2678 - accuracy: 0.9124 - val_loss: 0.7376 - val_accuracy: 0.6727\n",
      "Epoch 231/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2598 - accuracy: 0.9145 - val_loss: 0.7395 - val_accuracy: 0.6727\n",
      "Epoch 232/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2630 - accuracy: 0.9103 - val_loss: 0.7372 - val_accuracy: 0.6727\n",
      "Epoch 233/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2462 - accuracy: 0.9124 - val_loss: 0.7460 - val_accuracy: 0.6727\n",
      "Epoch 234/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2538 - accuracy: 0.9081 - val_loss: 0.7407 - val_accuracy: 0.6727\n",
      "Epoch 235/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2473 - accuracy: 0.9060 - val_loss: 0.7464 - val_accuracy: 0.6727\n",
      "Epoch 236/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2508 - accuracy: 0.9167 - val_loss: 0.7594 - val_accuracy: 0.6727\n",
      "Epoch 237/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2464 - accuracy: 0.9038 - val_loss: 0.7480 - val_accuracy: 0.6364\n",
      "Epoch 238/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.2384 - accuracy: 0.9124 - val_loss: 0.7646 - val_accuracy: 0.6909\n",
      "Epoch 239/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2381 - accuracy: 0.9252 - val_loss: 0.7498 - val_accuracy: 0.6545\n",
      "Epoch 240/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2422 - accuracy: 0.9124 - val_loss: 0.7629 - val_accuracy: 0.6727\n",
      "Epoch 241/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2383 - accuracy: 0.9252 - val_loss: 0.7578 - val_accuracy: 0.6727\n",
      "Epoch 242/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2380 - accuracy: 0.9295 - val_loss: 0.7576 - val_accuracy: 0.6727\n",
      "Epoch 243/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2387 - accuracy: 0.9209 - val_loss: 0.7658 - val_accuracy: 0.6727\n",
      "Epoch 244/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2333 - accuracy: 0.9209 - val_loss: 0.7712 - val_accuracy: 0.6727\n",
      "Epoch 245/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2252 - accuracy: 0.9231 - val_loss: 0.7625 - val_accuracy: 0.6545\n",
      "Epoch 246/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2323 - accuracy: 0.9231 - val_loss: 0.7768 - val_accuracy: 0.6727\n",
      "Epoch 247/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2263 - accuracy: 0.9338 - val_loss: 0.7682 - val_accuracy: 0.6545\n",
      "Epoch 248/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2337 - accuracy: 0.9252 - val_loss: 0.7778 - val_accuracy: 0.6727\n",
      "Epoch 249/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2243 - accuracy: 0.9231 - val_loss: 0.7775 - val_accuracy: 0.6727\n",
      "Epoch 250/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2214 - accuracy: 0.9231 - val_loss: 0.7792 - val_accuracy: 0.6727\n",
      "Epoch 251/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2296 - accuracy: 0.9252 - val_loss: 0.7924 - val_accuracy: 0.6727\n",
      "Epoch 252/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2176 - accuracy: 0.9274 - val_loss: 0.7878 - val_accuracy: 0.6000\n",
      "Epoch 253/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2123 - accuracy: 0.9338 - val_loss: 0.7989 - val_accuracy: 0.6727\n",
      "Epoch 254/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2222 - accuracy: 0.9167 - val_loss: 0.7817 - val_accuracy: 0.6364\n",
      "Epoch 255/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2247 - accuracy: 0.9231 - val_loss: 0.8002 - val_accuracy: 0.6727\n",
      "Epoch 256/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2253 - accuracy: 0.9188 - val_loss: 0.7826 - val_accuracy: 0.6364\n",
      "Epoch 257/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2118 - accuracy: 0.9295 - val_loss: 0.7955 - val_accuracy: 0.6545\n",
      "Epoch 258/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2129 - accuracy: 0.9274 - val_loss: 0.8020 - val_accuracy: 0.6545\n",
      "Epoch 259/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2241 - accuracy: 0.9231 - val_loss: 0.7955 - val_accuracy: 0.6545\n",
      "Epoch 260/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2214 - accuracy: 0.9316 - val_loss: 0.7947 - val_accuracy: 0.6545\n",
      "Epoch 261/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2046 - accuracy: 0.9402 - val_loss: 0.7960 - val_accuracy: 0.6727\n",
      "Epoch 262/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.2106 - accuracy: 0.9252 - val_loss: 0.7982 - val_accuracy: 0.6182\n",
      "Epoch 263/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2111 - accuracy: 0.9380 - val_loss: 0.8080 - val_accuracy: 0.6727\n",
      "Epoch 264/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2146 - accuracy: 0.9295 - val_loss: 0.8138 - val_accuracy: 0.6727\n",
      "Epoch 265/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2069 - accuracy: 0.9274 - val_loss: 0.7967 - val_accuracy: 0.6182\n",
      "Epoch 266/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2052 - accuracy: 0.9402 - val_loss: 0.8046 - val_accuracy: 0.6727\n",
      "Epoch 267/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2115 - accuracy: 0.9274 - val_loss: 0.8018 - val_accuracy: 0.6182\n",
      "Epoch 268/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2032 - accuracy: 0.9487 - val_loss: 0.8155 - val_accuracy: 0.6727\n",
      "Epoch 269/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2065 - accuracy: 0.9359 - val_loss: 0.8158 - val_accuracy: 0.6364\n",
      "Epoch 270/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2039 - accuracy: 0.9359 - val_loss: 0.8176 - val_accuracy: 0.6182\n",
      "Epoch 271/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1980 - accuracy: 0.9423 - val_loss: 0.8180 - val_accuracy: 0.6364\n",
      "Epoch 272/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2086 - accuracy: 0.9274 - val_loss: 0.8215 - val_accuracy: 0.6727\n",
      "Epoch 273/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.2037 - accuracy: 0.9359 - val_loss: 0.8175 - val_accuracy: 0.6545\n",
      "Epoch 274/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1975 - accuracy: 0.9402 - val_loss: 0.8184 - val_accuracy: 0.6182\n",
      "Epoch 275/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1994 - accuracy: 0.9359 - val_loss: 0.8404 - val_accuracy: 0.6727\n",
      "Epoch 276/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.2066 - accuracy: 0.9295 - val_loss: 0.8229 - val_accuracy: 0.6182\n",
      "Epoch 277/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1898 - accuracy: 0.9423 - val_loss: 0.8388 - val_accuracy: 0.6364\n",
      "Epoch 278/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1890 - accuracy: 0.9359 - val_loss: 0.8294 - val_accuracy: 0.6182\n",
      "Epoch 279/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1956 - accuracy: 0.9338 - val_loss: 0.8514 - val_accuracy: 0.6727\n",
      "Epoch 280/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2002 - accuracy: 0.9359 - val_loss: 0.8314 - val_accuracy: 0.6182\n",
      "Epoch 281/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1961 - accuracy: 0.9338 - val_loss: 0.8473 - val_accuracy: 0.6727\n",
      "Epoch 282/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1884 - accuracy: 0.9359 - val_loss: 0.8381 - val_accuracy: 0.6364\n",
      "Epoch 283/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1806 - accuracy: 0.9423 - val_loss: 0.8400 - val_accuracy: 0.6182\n",
      "Epoch 284/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1967 - accuracy: 0.9402 - val_loss: 0.8376 - val_accuracy: 0.6182\n",
      "Epoch 285/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1822 - accuracy: 0.9423 - val_loss: 0.8470 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1908 - accuracy: 0.9402 - val_loss: 0.8555 - val_accuracy: 0.6364\n",
      "Epoch 287/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1910 - accuracy: 0.9316 - val_loss: 0.8455 - val_accuracy: 0.6000\n",
      "Epoch 288/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1852 - accuracy: 0.9380 - val_loss: 0.8486 - val_accuracy: 0.6182\n",
      "Epoch 289/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1800 - accuracy: 0.9338 - val_loss: 0.8618 - val_accuracy: 0.6727\n",
      "Epoch 290/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1826 - accuracy: 0.9444 - val_loss: 0.8479 - val_accuracy: 0.6182\n",
      "Epoch 291/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1827 - accuracy: 0.9402 - val_loss: 0.8536 - val_accuracy: 0.6182\n",
      "Epoch 292/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1734 - accuracy: 0.9637 - val_loss: 0.8703 - val_accuracy: 0.6727\n",
      "Epoch 293/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.8649 - val_accuracy: 0.6182\n",
      "Epoch 294/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1867 - accuracy: 0.9402 - val_loss: 0.8657 - val_accuracy: 0.6182\n",
      "Epoch 295/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1866 - accuracy: 0.9338 - val_loss: 0.8962 - val_accuracy: 0.6727\n",
      "Epoch 296/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1832 - accuracy: 0.9466 - val_loss: 0.8608 - val_accuracy: 0.6182\n",
      "Epoch 297/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1758 - accuracy: 0.9274 - val_loss: 0.8645 - val_accuracy: 0.6364\n",
      "Epoch 298/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1707 - accuracy: 0.9423 - val_loss: 0.8740 - val_accuracy: 0.6727\n",
      "Epoch 299/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1719 - accuracy: 0.9444 - val_loss: 0.8684 - val_accuracy: 0.6545\n",
      "Epoch 300/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1866 - accuracy: 0.9359 - val_loss: 0.8676 - val_accuracy: 0.6182\n",
      "Epoch 301/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1650 - accuracy: 0.9487 - val_loss: 0.8732 - val_accuracy: 0.6545\n",
      "Epoch 302/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1695 - accuracy: 0.9380 - val_loss: 0.8710 - val_accuracy: 0.6182\n",
      "Epoch 303/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1635 - accuracy: 0.9530 - val_loss: 0.8875 - val_accuracy: 0.6364\n",
      "Epoch 304/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1658 - accuracy: 0.9594 - val_loss: 0.8826 - val_accuracy: 0.6364\n",
      "Epoch 305/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1596 - accuracy: 0.9466 - val_loss: 0.8765 - val_accuracy: 0.6182\n",
      "Epoch 306/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1762 - accuracy: 0.9466 - val_loss: 0.8825 - val_accuracy: 0.6364\n",
      "Epoch 307/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1688 - accuracy: 0.9509 - val_loss: 0.8884 - val_accuracy: 0.6182\n",
      "Epoch 308/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.1801 - accuracy: 0.9359 - val_loss: 0.9047 - val_accuracy: 0.6364\n",
      "Epoch 309/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1550 - accuracy: 0.9573 - val_loss: 0.9035 - val_accuracy: 0.6182\n",
      "Epoch 310/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1568 - accuracy: 0.9530 - val_loss: 0.9051 - val_accuracy: 0.6364\n",
      "Epoch 311/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1589 - accuracy: 0.9573 - val_loss: 0.9033 - val_accuracy: 0.6182\n",
      "Epoch 312/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1657 - accuracy: 0.9423 - val_loss: 0.9045 - val_accuracy: 0.6182\n",
      "Epoch 313/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1627 - accuracy: 0.9615 - val_loss: 0.9008 - val_accuracy: 0.6182\n",
      "Epoch 314/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1551 - accuracy: 0.9551 - val_loss: 0.9055 - val_accuracy: 0.6182\n",
      "Epoch 315/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1664 - accuracy: 0.9423 - val_loss: 0.9166 - val_accuracy: 0.6364\n",
      "Epoch 316/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1568 - accuracy: 0.9551 - val_loss: 0.9102 - val_accuracy: 0.6364\n",
      "Epoch 317/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1675 - accuracy: 0.9487 - val_loss: 0.9021 - val_accuracy: 0.6364\n",
      "Epoch 318/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1622 - accuracy: 0.9530 - val_loss: 0.9342 - val_accuracy: 0.6727\n",
      "Epoch 319/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1463 - accuracy: 0.9615 - val_loss: 0.8967 - val_accuracy: 0.6182\n",
      "Epoch 320/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1524 - accuracy: 0.9551 - val_loss: 0.9170 - val_accuracy: 0.6545\n",
      "Epoch 321/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1437 - accuracy: 0.9551 - val_loss: 0.9265 - val_accuracy: 0.6364\n",
      "Epoch 322/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1581 - accuracy: 0.9509 - val_loss: 0.9360 - val_accuracy: 0.6364\n",
      "Epoch 323/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1576 - accuracy: 0.9551 - val_loss: 0.9308 - val_accuracy: 0.6545\n",
      "Epoch 324/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1541 - accuracy: 0.9402 - val_loss: 0.9325 - val_accuracy: 0.6182\n",
      "Epoch 325/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1525 - accuracy: 0.9487 - val_loss: 0.9271 - val_accuracy: 0.6182\n",
      "Epoch 326/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1490 - accuracy: 0.9594 - val_loss: 0.9178 - val_accuracy: 0.6182\n",
      "Epoch 327/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1352 - accuracy: 0.9679 - val_loss: 0.9527 - val_accuracy: 0.6364\n",
      "Epoch 328/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1570 - accuracy: 0.9615 - val_loss: 0.9386 - val_accuracy: 0.6364\n",
      "Epoch 329/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1383 - accuracy: 0.9615 - val_loss: 0.9520 - val_accuracy: 0.6364\n",
      "Epoch 330/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1372 - accuracy: 0.9658 - val_loss: 0.9392 - val_accuracy: 0.6182\n",
      "Epoch 331/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1431 - accuracy: 0.9573 - val_loss: 0.9465 - val_accuracy: 0.6182\n",
      "Epoch 332/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1386 - accuracy: 0.9615 - val_loss: 0.9533 - val_accuracy: 0.6727\n",
      "Epoch 333/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1431 - accuracy: 0.9594 - val_loss: 0.9581 - val_accuracy: 0.6182\n",
      "Epoch 334/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1376 - accuracy: 0.9551 - val_loss: 0.9632 - val_accuracy: 0.6182\n",
      "Epoch 335/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1418 - accuracy: 0.9594 - val_loss: 0.9572 - val_accuracy: 0.6182\n",
      "Epoch 336/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1429 - accuracy: 0.9573 - val_loss: 0.9639 - val_accuracy: 0.6364\n",
      "Epoch 337/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1337 - accuracy: 0.9637 - val_loss: 0.9544 - val_accuracy: 0.6182\n",
      "Epoch 338/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1397 - accuracy: 0.9615 - val_loss: 0.9715 - val_accuracy: 0.6545\n",
      "Epoch 339/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1394 - accuracy: 0.9701 - val_loss: 0.9546 - val_accuracy: 0.6364\n",
      "Epoch 340/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1362 - accuracy: 0.9679 - val_loss: 0.9566 - val_accuracy: 0.6182\n",
      "Epoch 341/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1314 - accuracy: 0.9530 - val_loss: 0.9615 - val_accuracy: 0.6364\n",
      "Epoch 342/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1305 - accuracy: 0.9744 - val_loss: 0.9793 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1340 - accuracy: 0.9573 - val_loss: 0.9832 - val_accuracy: 0.6364\n",
      "Epoch 344/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1386 - accuracy: 0.9573 - val_loss: 1.0085 - val_accuracy: 0.6364\n",
      "Epoch 345/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1386 - accuracy: 0.9573 - val_loss: 0.9808 - val_accuracy: 0.6364\n",
      "Epoch 346/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1435 - accuracy: 0.9509 - val_loss: 0.9688 - val_accuracy: 0.6182\n",
      "Epoch 347/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1313 - accuracy: 0.9637 - val_loss: 0.9969 - val_accuracy: 0.6364\n",
      "Epoch 348/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1349 - accuracy: 0.9594 - val_loss: 0.9719 - val_accuracy: 0.6364\n",
      "Epoch 349/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1235 - accuracy: 0.9744 - val_loss: 0.9807 - val_accuracy: 0.6182\n",
      "Epoch 350/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1355 - accuracy: 0.9551 - val_loss: 1.0006 - val_accuracy: 0.6364\n",
      "Epoch 351/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1345 - accuracy: 0.9551 - val_loss: 0.9860 - val_accuracy: 0.6364\n",
      "Epoch 352/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1320 - accuracy: 0.9573 - val_loss: 1.0019 - val_accuracy: 0.6364\n",
      "Epoch 353/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1280 - accuracy: 0.9679 - val_loss: 1.0169 - val_accuracy: 0.6727\n",
      "Epoch 354/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1444 - accuracy: 0.9701 - val_loss: 1.0049 - val_accuracy: 0.6364\n",
      "Epoch 355/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1296 - accuracy: 0.9594 - val_loss: 0.9983 - val_accuracy: 0.6364\n",
      "Epoch 356/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1293 - accuracy: 0.9679 - val_loss: 1.0096 - val_accuracy: 0.6364\n",
      "Epoch 357/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1218 - accuracy: 0.9765 - val_loss: 0.9956 - val_accuracy: 0.6182\n",
      "Epoch 358/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1260 - accuracy: 0.9573 - val_loss: 0.9947 - val_accuracy: 0.6182\n",
      "Epoch 359/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1310 - accuracy: 0.9679 - val_loss: 1.0127 - val_accuracy: 0.6545\n",
      "Epoch 360/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1283 - accuracy: 0.9658 - val_loss: 1.0245 - val_accuracy: 0.6364\n",
      "Epoch 361/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1335 - accuracy: 0.9487 - val_loss: 1.0183 - val_accuracy: 0.6182\n",
      "Epoch 362/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1168 - accuracy: 0.9701 - val_loss: 1.0169 - val_accuracy: 0.6364\n",
      "Epoch 363/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1193 - accuracy: 0.9594 - val_loss: 1.0076 - val_accuracy: 0.6364\n",
      "Epoch 364/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1119 - accuracy: 0.9658 - val_loss: 1.0006 - val_accuracy: 0.6364\n",
      "Epoch 365/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1145 - accuracy: 0.9744 - val_loss: 1.0183 - val_accuracy: 0.6364\n",
      "Epoch 366/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1276 - accuracy: 0.9573 - val_loss: 1.0309 - val_accuracy: 0.6364\n",
      "Epoch 367/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1173 - accuracy: 0.9701 - val_loss: 1.0218 - val_accuracy: 0.6364\n",
      "Epoch 368/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1142 - accuracy: 0.9701 - val_loss: 1.0256 - val_accuracy: 0.6364\n",
      "Epoch 369/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1184 - accuracy: 0.9658 - val_loss: 1.0284 - val_accuracy: 0.6182\n",
      "Epoch 370/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1113 - accuracy: 0.9786 - val_loss: 1.0207 - val_accuracy: 0.6182\n",
      "Epoch 371/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1095 - accuracy: 0.9701 - val_loss: 1.0397 - val_accuracy: 0.6182\n",
      "Epoch 372/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1107 - accuracy: 0.9786 - val_loss: 1.0328 - val_accuracy: 0.6182\n",
      "Epoch 373/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1135 - accuracy: 0.9701 - val_loss: 1.0419 - val_accuracy: 0.6364\n",
      "Epoch 374/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1009 - accuracy: 0.9808 - val_loss: 1.0452 - val_accuracy: 0.6545\n",
      "Epoch 375/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1060 - accuracy: 0.9744 - val_loss: 1.0481 - val_accuracy: 0.6364\n",
      "Epoch 376/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1127 - accuracy: 0.9615 - val_loss: 1.0363 - val_accuracy: 0.6364\n",
      "Epoch 377/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1112 - accuracy: 0.9701 - val_loss: 1.0445 - val_accuracy: 0.6364\n",
      "Epoch 378/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1166 - accuracy: 0.9722 - val_loss: 1.0533 - val_accuracy: 0.6364\n",
      "Epoch 379/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1044 - accuracy: 0.9829 - val_loss: 1.0531 - val_accuracy: 0.6545\n",
      "Epoch 380/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1184 - accuracy: 0.9701 - val_loss: 1.0716 - val_accuracy: 0.6545\n",
      "Epoch 381/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1094 - accuracy: 0.9701 - val_loss: 1.0513 - val_accuracy: 0.6364\n",
      "Epoch 382/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1016 - accuracy: 0.9744 - val_loss: 1.0709 - val_accuracy: 0.6545\n",
      "Epoch 383/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0999 - accuracy: 0.9744 - val_loss: 1.0594 - val_accuracy: 0.6182\n",
      "Epoch 384/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0953 - accuracy: 0.9850 - val_loss: 1.0824 - val_accuracy: 0.6364\n",
      "Epoch 385/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1036 - accuracy: 0.9722 - val_loss: 1.0773 - val_accuracy: 0.6364\n",
      "Epoch 386/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1056 - accuracy: 0.9722 - val_loss: 1.0768 - val_accuracy: 0.6182\n",
      "Epoch 387/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0952 - accuracy: 0.9829 - val_loss: 1.0762 - val_accuracy: 0.6364\n",
      "Epoch 388/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1001 - accuracy: 0.9786 - val_loss: 1.1084 - val_accuracy: 0.6545\n",
      "Epoch 389/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1021 - accuracy: 0.9744 - val_loss: 1.0895 - val_accuracy: 0.6364\n",
      "Epoch 390/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1010 - accuracy: 0.9722 - val_loss: 1.0954 - val_accuracy: 0.6182\n",
      "Epoch 391/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1065 - accuracy: 0.9722 - val_loss: 1.1010 - val_accuracy: 0.6364\n",
      "Epoch 392/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0965 - accuracy: 0.9765 - val_loss: 1.0957 - val_accuracy: 0.6545\n",
      "Epoch 393/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1026 - accuracy: 0.9722 - val_loss: 1.1006 - val_accuracy: 0.6364\n",
      "Epoch 394/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1084 - accuracy: 0.9679 - val_loss: 1.1097 - val_accuracy: 0.6545\n",
      "Epoch 395/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0919 - accuracy: 0.9765 - val_loss: 1.1076 - val_accuracy: 0.6545\n",
      "Epoch 396/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1096 - accuracy: 0.9637 - val_loss: 1.1381 - val_accuracy: 0.6545\n",
      "Epoch 397/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.1037 - accuracy: 0.9744 - val_loss: 1.1191 - val_accuracy: 0.6364\n",
      "Epoch 398/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1007 - accuracy: 0.9765 - val_loss: 1.1263 - val_accuracy: 0.6364\n",
      "Epoch 399/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0960 - accuracy: 0.9808 - val_loss: 1.1048 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0922 - accuracy: 0.9765 - val_loss: 1.1196 - val_accuracy: 0.6545\n",
      "Epoch 401/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0917 - accuracy: 0.9808 - val_loss: 1.1130 - val_accuracy: 0.6182\n",
      "Epoch 402/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0887 - accuracy: 0.9808 - val_loss: 1.1159 - val_accuracy: 0.6364\n",
      "Epoch 403/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0914 - accuracy: 0.9786 - val_loss: 1.1270 - val_accuracy: 0.6182\n",
      "Epoch 404/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0927 - accuracy: 0.9808 - val_loss: 1.1231 - val_accuracy: 0.6364\n",
      "Epoch 405/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1019 - accuracy: 0.9786 - val_loss: 1.1109 - val_accuracy: 0.6364\n",
      "Epoch 406/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.0944 - accuracy: 0.9786 - val_loss: 1.1422 - val_accuracy: 0.6545\n",
      "Epoch 407/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0940 - accuracy: 0.9786 - val_loss: 1.0911 - val_accuracy: 0.6364\n",
      "Epoch 408/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0968 - accuracy: 0.9808 - val_loss: 1.1188 - val_accuracy: 0.6364\n",
      "Epoch 409/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0886 - accuracy: 0.9829 - val_loss: 1.1199 - val_accuracy: 0.6545\n",
      "Epoch 410/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0914 - accuracy: 0.9744 - val_loss: 1.1133 - val_accuracy: 0.6364\n",
      "Epoch 411/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0884 - accuracy: 0.9722 - val_loss: 1.1564 - val_accuracy: 0.6545\n",
      "Epoch 412/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0887 - accuracy: 0.9765 - val_loss: 1.1458 - val_accuracy: 0.6364\n",
      "Epoch 413/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0858 - accuracy: 0.9829 - val_loss: 1.1431 - val_accuracy: 0.6364\n",
      "Epoch 414/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0905 - accuracy: 0.9765 - val_loss: 1.1315 - val_accuracy: 0.6364\n",
      "Epoch 415/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0805 - accuracy: 0.9872 - val_loss: 1.1252 - val_accuracy: 0.6364\n",
      "Epoch 416/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0833 - accuracy: 0.9829 - val_loss: 1.1320 - val_accuracy: 0.6364\n",
      "Epoch 417/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0960 - accuracy: 0.9744 - val_loss: 1.1576 - val_accuracy: 0.6182\n",
      "Epoch 418/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0998 - accuracy: 0.9786 - val_loss: 1.1595 - val_accuracy: 0.6364\n",
      "Epoch 419/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0808 - accuracy: 0.9850 - val_loss: 1.1592 - val_accuracy: 0.6364\n",
      "Epoch 420/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0737 - accuracy: 0.9786 - val_loss: 1.1660 - val_accuracy: 0.6364\n",
      "Epoch 421/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0917 - accuracy: 0.9786 - val_loss: 1.1908 - val_accuracy: 0.6545\n",
      "Epoch 422/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0834 - accuracy: 0.9786 - val_loss: 1.1771 - val_accuracy: 0.6364\n",
      "Epoch 423/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0913 - accuracy: 0.9786 - val_loss: 1.1890 - val_accuracy: 0.6364\n",
      "Epoch 424/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0880 - accuracy: 0.9829 - val_loss: 1.1841 - val_accuracy: 0.6364\n",
      "Epoch 425/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0860 - accuracy: 0.9808 - val_loss: 1.1906 - val_accuracy: 0.6364\n",
      "Epoch 426/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0814 - accuracy: 0.9786 - val_loss: 1.1908 - val_accuracy: 0.6364\n",
      "Epoch 427/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0783 - accuracy: 0.9829 - val_loss: 1.1776 - val_accuracy: 0.6364\n",
      "Epoch 428/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0769 - accuracy: 0.9850 - val_loss: 1.1840 - val_accuracy: 0.6364\n",
      "Epoch 429/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0745 - accuracy: 0.9829 - val_loss: 1.2061 - val_accuracy: 0.6364\n",
      "Epoch 430/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0755 - accuracy: 0.9850 - val_loss: 1.2377 - val_accuracy: 0.6545\n",
      "Epoch 431/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0831 - accuracy: 0.9829 - val_loss: 1.2309 - val_accuracy: 0.6545\n",
      "Epoch 432/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0787 - accuracy: 0.9808 - val_loss: 1.1932 - val_accuracy: 0.6182\n",
      "Epoch 433/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0731 - accuracy: 0.9872 - val_loss: 1.2017 - val_accuracy: 0.6545\n",
      "Epoch 434/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0788 - accuracy: 0.9808 - val_loss: 1.2130 - val_accuracy: 0.6545\n",
      "Epoch 435/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0760 - accuracy: 0.9808 - val_loss: 1.2249 - val_accuracy: 0.6545\n",
      "Epoch 436/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0808 - accuracy: 0.9765 - val_loss: 1.2000 - val_accuracy: 0.6545\n",
      "Epoch 437/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0825 - accuracy: 0.9808 - val_loss: 1.1974 - val_accuracy: 0.6182\n",
      "Epoch 438/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0683 - accuracy: 0.9872 - val_loss: 1.1910 - val_accuracy: 0.6545\n",
      "Epoch 439/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0732 - accuracy: 0.9829 - val_loss: 1.2021 - val_accuracy: 0.6545\n",
      "Epoch 440/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0742 - accuracy: 0.9850 - val_loss: 1.2289 - val_accuracy: 0.6364\n",
      "Epoch 441/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0785 - accuracy: 0.9786 - val_loss: 1.2126 - val_accuracy: 0.6364\n",
      "Epoch 442/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0749 - accuracy: 0.9850 - val_loss: 1.2661 - val_accuracy: 0.6364\n",
      "Epoch 443/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0639 - accuracy: 0.9893 - val_loss: 1.2392 - val_accuracy: 0.6364\n",
      "Epoch 444/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0731 - accuracy: 0.9850 - val_loss: 1.2289 - val_accuracy: 0.6182\n",
      "Epoch 445/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0818 - accuracy: 0.9786 - val_loss: 1.2674 - val_accuracy: 0.6545\n",
      "Epoch 446/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0646 - accuracy: 0.9872 - val_loss: 1.2476 - val_accuracy: 0.6182\n",
      "Epoch 447/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0710 - accuracy: 0.9829 - val_loss: 1.2381 - val_accuracy: 0.6182\n",
      "Epoch 448/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0714 - accuracy: 0.9808 - val_loss: 1.2465 - val_accuracy: 0.6364\n",
      "Epoch 449/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0752 - accuracy: 0.9786 - val_loss: 1.2497 - val_accuracy: 0.6182\n",
      "Epoch 450/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0735 - accuracy: 0.9829 - val_loss: 1.2531 - val_accuracy: 0.6364\n",
      "Epoch 451/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0704 - accuracy: 0.9915 - val_loss: 1.2572 - val_accuracy: 0.6545\n",
      "Epoch 452/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0678 - accuracy: 0.9850 - val_loss: 1.2384 - val_accuracy: 0.6000\n",
      "Epoch 453/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0867 - accuracy: 0.9701 - val_loss: 1.2850 - val_accuracy: 0.6545\n",
      "Epoch 454/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0764 - accuracy: 0.9786 - val_loss: 1.2646 - val_accuracy: 0.6545\n",
      "Epoch 455/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0692 - accuracy: 0.9808 - val_loss: 1.2586 - val_accuracy: 0.6182\n",
      "Epoch 456/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0647 - accuracy: 0.9850 - val_loss: 1.2678 - val_accuracy: 0.6182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0829 - accuracy: 0.9829 - val_loss: 1.2556 - val_accuracy: 0.6182\n",
      "Epoch 458/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0635 - accuracy: 0.9829 - val_loss: 1.2637 - val_accuracy: 0.6545\n",
      "Epoch 459/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0587 - accuracy: 0.9915 - val_loss: 1.2834 - val_accuracy: 0.6364\n",
      "Epoch 460/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0632 - accuracy: 0.9872 - val_loss: 1.2545 - val_accuracy: 0.6364\n",
      "Epoch 461/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0704 - accuracy: 0.9872 - val_loss: 1.2948 - val_accuracy: 0.6364\n",
      "Epoch 462/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0620 - accuracy: 0.9872 - val_loss: 1.2651 - val_accuracy: 0.6182\n",
      "Epoch 463/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0729 - accuracy: 0.9786 - val_loss: 1.2754 - val_accuracy: 0.6182\n",
      "Epoch 464/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0561 - accuracy: 0.9872 - val_loss: 1.3148 - val_accuracy: 0.6364\n",
      "Epoch 465/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0633 - accuracy: 0.9829 - val_loss: 1.2686 - val_accuracy: 0.6182\n",
      "Epoch 466/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.0655 - accuracy: 0.9872 - val_loss: 1.2988 - val_accuracy: 0.6182\n",
      "Epoch 467/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0591 - accuracy: 0.9893 - val_loss: 1.3199 - val_accuracy: 0.6182\n",
      "Epoch 468/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0603 - accuracy: 0.9893 - val_loss: 1.2994 - val_accuracy: 0.6545\n",
      "Epoch 469/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0706 - accuracy: 0.9850 - val_loss: 1.2939 - val_accuracy: 0.6364\n",
      "Epoch 470/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0641 - accuracy: 0.9808 - val_loss: 1.2998 - val_accuracy: 0.6182\n",
      "Epoch 471/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0590 - accuracy: 0.9893 - val_loss: 1.3188 - val_accuracy: 0.6545\n",
      "Epoch 472/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0618 - accuracy: 0.9850 - val_loss: 1.3349 - val_accuracy: 0.6545\n",
      "Epoch 473/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0636 - accuracy: 0.9829 - val_loss: 1.3509 - val_accuracy: 0.6182\n",
      "Epoch 474/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0643 - accuracy: 0.9850 - val_loss: 1.3159 - val_accuracy: 0.6182\n",
      "Epoch 475/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0577 - accuracy: 0.9915 - val_loss: 1.3068 - val_accuracy: 0.6182\n",
      "Epoch 476/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0599 - accuracy: 0.9829 - val_loss: 1.3435 - val_accuracy: 0.6364\n",
      "Epoch 477/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0731 - accuracy: 0.9808 - val_loss: 1.3227 - val_accuracy: 0.6182\n",
      "Epoch 478/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0617 - accuracy: 0.9850 - val_loss: 1.3240 - val_accuracy: 0.6182\n",
      "Epoch 479/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0524 - accuracy: 0.9915 - val_loss: 1.3140 - val_accuracy: 0.6364\n",
      "Epoch 480/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0575 - accuracy: 0.9915 - val_loss: 1.3012 - val_accuracy: 0.6182\n",
      "Epoch 481/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0525 - accuracy: 0.9936 - val_loss: 1.3507 - val_accuracy: 0.6364\n",
      "Epoch 482/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0565 - accuracy: 0.9893 - val_loss: 1.3404 - val_accuracy: 0.6182\n",
      "Epoch 483/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0521 - accuracy: 0.9893 - val_loss: 1.3722 - val_accuracy: 0.6364\n",
      "Epoch 484/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0664 - accuracy: 0.9850 - val_loss: 1.3138 - val_accuracy: 0.6182\n",
      "Epoch 485/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0545 - accuracy: 0.9872 - val_loss: 1.3735 - val_accuracy: 0.6364\n",
      "Epoch 486/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0461 - accuracy: 0.9936 - val_loss: 1.3286 - val_accuracy: 0.6182\n",
      "Epoch 487/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0546 - accuracy: 0.9808 - val_loss: 1.3442 - val_accuracy: 0.6182\n",
      "Epoch 488/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0591 - accuracy: 0.9872 - val_loss: 1.3900 - val_accuracy: 0.6545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6783bcc10>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_211.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_211.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fbda4d",
   "metadata": {},
   "source": [
    "**For test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4a14c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6340 - accuracy: 0.6923\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5949 - accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "m1_eval_test = model_211.evaluate(X_test, y_test)\n",
    "m1_eval_val = model_211.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34526fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n",
      "roc auc score:  0.5883458646616542\n",
      "average precision score:  0.5778466684760469\n"
     ]
    }
   ],
   "source": [
    "pred = model_211.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9381d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "edbfb938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6340 - accuracy: 0.6923\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_211.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b1c12e",
   "metadata": {},
   "source": [
    "**For validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e2a0c024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "roc auc score:  0.6594427244582044\n",
      "average precision score:  0.6459363967192853\n"
     ]
    }
   ],
   "source": [
    "pred = model_211.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "044cc283",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "75364eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5949 - accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels (validation set)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_211.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc3a52",
   "metadata": {},
   "source": [
    "#### 1.1.2 Alvin's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e1d753ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 766, 64)           256       \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 764, 32)           6176      \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 24448)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 112)               2738288   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 2)                 226       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,744,946\n",
      "Trainable params: 2,744,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model1\n",
    "model_212 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_212.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_212.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_212.add(Flatten())\n",
    "model_212.add(Dense(112, activation='relu'))\n",
    "model_212.add(Dense(2, activation='softmax'))\n",
    "model_212.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "65a9d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=400,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "882a8235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 0.6094 - accuracy: 0.7073 - val_loss: 0.6215 - val_accuracy: 0.6909\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.6060 - accuracy: 0.7073 - val_loss: 0.6041 - val_accuracy: 0.6909\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5931 - accuracy: 0.7073 - val_loss: 0.6078 - val_accuracy: 0.6909\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5898 - accuracy: 0.7073 - val_loss: 0.6009 - val_accuracy: 0.6909\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5919 - accuracy: 0.7073 - val_loss: 0.6017 - val_accuracy: 0.6909\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5860 - accuracy: 0.7073 - val_loss: 0.5971 - val_accuracy: 0.6909\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5860 - accuracy: 0.7073 - val_loss: 0.5956 - val_accuracy: 0.6909\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5837 - accuracy: 0.7051 - val_loss: 0.5959 - val_accuracy: 0.6909\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5785 - accuracy: 0.7073 - val_loss: 0.5966 - val_accuracy: 0.6909\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5735 - accuracy: 0.7094 - val_loss: 0.5912 - val_accuracy: 0.6909\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5735 - accuracy: 0.7158 - val_loss: 0.5916 - val_accuracy: 0.6909\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.5757 - accuracy: 0.7115 - val_loss: 0.5893 - val_accuracy: 0.6909\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5677 - accuracy: 0.7179 - val_loss: 0.5916 - val_accuracy: 0.6909\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5618 - accuracy: 0.7158 - val_loss: 0.5874 - val_accuracy: 0.6909\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5586 - accuracy: 0.7179 - val_loss: 0.5834 - val_accuracy: 0.6909\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5498 - accuracy: 0.7201 - val_loss: 0.5822 - val_accuracy: 0.6909\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5465 - accuracy: 0.7222 - val_loss: 0.5790 - val_accuracy: 0.7091\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5430 - accuracy: 0.7286 - val_loss: 0.5891 - val_accuracy: 0.6909\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5359 - accuracy: 0.7350 - val_loss: 0.5763 - val_accuracy: 0.6909\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5313 - accuracy: 0.7286 - val_loss: 0.5757 - val_accuracy: 0.6909\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5266 - accuracy: 0.7415 - val_loss: 0.5772 - val_accuracy: 0.6909\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5195 - accuracy: 0.7479 - val_loss: 0.5711 - val_accuracy: 0.6909\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5177 - accuracy: 0.7479 - val_loss: 0.5806 - val_accuracy: 0.6909\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.5137 - accuracy: 0.7479 - val_loss: 0.5777 - val_accuracy: 0.6909\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5108 - accuracy: 0.7628 - val_loss: 0.5781 - val_accuracy: 0.7091\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5027 - accuracy: 0.7650 - val_loss: 0.5802 - val_accuracy: 0.6909\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4951 - accuracy: 0.7821 - val_loss: 0.5694 - val_accuracy: 0.7091\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.4952 - accuracy: 0.7607 - val_loss: 0.5687 - val_accuracy: 0.7091\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5070 - accuracy: 0.7607 - val_loss: 0.5699 - val_accuracy: 0.7273\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4878 - accuracy: 0.7799 - val_loss: 0.5945 - val_accuracy: 0.6909\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4875 - accuracy: 0.7585 - val_loss: 0.5687 - val_accuracy: 0.7273\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4835 - accuracy: 0.7799 - val_loss: 0.5754 - val_accuracy: 0.7091\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.4774 - accuracy: 0.7885 - val_loss: 0.5817 - val_accuracy: 0.7273\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.4807 - accuracy: 0.7585 - val_loss: 0.5882 - val_accuracy: 0.7273\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.4731 - accuracy: 0.7927 - val_loss: 0.5825 - val_accuracy: 0.7273\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.4660 - accuracy: 0.7863 - val_loss: 0.5739 - val_accuracy: 0.7273\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4583 - accuracy: 0.7927 - val_loss: 0.5778 - val_accuracy: 0.7273\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4570 - accuracy: 0.7927 - val_loss: 0.5850 - val_accuracy: 0.7273\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4545 - accuracy: 0.7970 - val_loss: 0.5755 - val_accuracy: 0.6727\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4487 - accuracy: 0.8034 - val_loss: 0.5875 - val_accuracy: 0.7273\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4449 - accuracy: 0.8034 - val_loss: 0.5843 - val_accuracy: 0.7273\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4564 - accuracy: 0.7885 - val_loss: 0.5797 - val_accuracy: 0.6727\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4373 - accuracy: 0.8141 - val_loss: 0.6013 - val_accuracy: 0.7273\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4422 - accuracy: 0.8141 - val_loss: 0.5928 - val_accuracy: 0.7273\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4390 - accuracy: 0.8013 - val_loss: 0.5831 - val_accuracy: 0.6727\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4295 - accuracy: 0.8184 - val_loss: 0.5913 - val_accuracy: 0.7091\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4238 - accuracy: 0.8205 - val_loss: 0.5891 - val_accuracy: 0.6909\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4214 - accuracy: 0.8205 - val_loss: 0.5950 - val_accuracy: 0.7091\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4239 - accuracy: 0.8269 - val_loss: 0.6084 - val_accuracy: 0.7273\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4271 - accuracy: 0.8098 - val_loss: 0.6630 - val_accuracy: 0.7091\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.4267 - accuracy: 0.8205 - val_loss: 0.6050 - val_accuracy: 0.6909\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.4297 - accuracy: 0.8162 - val_loss: 0.6018 - val_accuracy: 0.6909\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4094 - accuracy: 0.8141 - val_loss: 0.6039 - val_accuracy: 0.6909\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.4085 - accuracy: 0.8248 - val_loss: 0.6165 - val_accuracy: 0.7091\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.4098 - accuracy: 0.8162 - val_loss: 0.6000 - val_accuracy: 0.6727\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.3973 - accuracy: 0.8291 - val_loss: 0.6095 - val_accuracy: 0.6909\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3954 - accuracy: 0.8333 - val_loss: 0.6055 - val_accuracy: 0.6364\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 31ms/step - loss: 0.3965 - accuracy: 0.8333 - val_loss: 0.6399 - val_accuracy: 0.6909\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3916 - accuracy: 0.8440 - val_loss: 0.6270 - val_accuracy: 0.7091\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3909 - accuracy: 0.8376 - val_loss: 0.6724 - val_accuracy: 0.7273\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.3865 - accuracy: 0.8291 - val_loss: 0.6217 - val_accuracy: 0.6909\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.3806 - accuracy: 0.8355 - val_loss: 0.6199 - val_accuracy: 0.6909\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.3752 - accuracy: 0.8504 - val_loss: 0.6519 - val_accuracy: 0.6909\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3713 - accuracy: 0.8440 - val_loss: 0.6331 - val_accuracy: 0.6909\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.3654 - accuracy: 0.8483 - val_loss: 0.6460 - val_accuracy: 0.6909\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.3699 - accuracy: 0.8419 - val_loss: 0.6609 - val_accuracy: 0.7091\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3567 - accuracy: 0.8526 - val_loss: 0.6334 - val_accuracy: 0.6545\n",
      "Epoch 68/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3722 - accuracy: 0.8419 - val_loss: 0.6500 - val_accuracy: 0.6909\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.3628 - accuracy: 0.8333 - val_loss: 0.6780 - val_accuracy: 0.6727\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3518 - accuracy: 0.8526 - val_loss: 0.6714 - val_accuracy: 0.6909\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3488 - accuracy: 0.8462 - val_loss: 0.6522 - val_accuracy: 0.6727\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3400 - accuracy: 0.8697 - val_loss: 0.6596 - val_accuracy: 0.6909\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3396 - accuracy: 0.8547 - val_loss: 0.6949 - val_accuracy: 0.6909\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.3380 - accuracy: 0.8568 - val_loss: 0.7138 - val_accuracy: 0.6727\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3335 - accuracy: 0.8632 - val_loss: 0.6560 - val_accuracy: 0.6545\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.3393 - accuracy: 0.8611 - val_loss: 0.6638 - val_accuracy: 0.6545\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3351 - accuracy: 0.8568 - val_loss: 0.6611 - val_accuracy: 0.6545\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3336 - accuracy: 0.8526 - val_loss: 0.7098 - val_accuracy: 0.6909\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.3214 - accuracy: 0.8611 - val_loss: 0.7084 - val_accuracy: 0.6909\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3193 - accuracy: 0.8632 - val_loss: 0.6909 - val_accuracy: 0.6909\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3214 - accuracy: 0.8675 - val_loss: 0.7648 - val_accuracy: 0.7091\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3122 - accuracy: 0.8654 - val_loss: 0.6999 - val_accuracy: 0.6727\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.3126 - accuracy: 0.8611 - val_loss: 0.6926 - val_accuracy: 0.6545\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3108 - accuracy: 0.8718 - val_loss: 0.6888 - val_accuracy: 0.6182\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.3048 - accuracy: 0.8761 - val_loss: 0.7073 - val_accuracy: 0.6909\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2968 - accuracy: 0.8846 - val_loss: 0.7331 - val_accuracy: 0.6909\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2972 - accuracy: 0.8654 - val_loss: 0.7173 - val_accuracy: 0.6909\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2906 - accuracy: 0.8974 - val_loss: 0.7400 - val_accuracy: 0.6909\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2906 - accuracy: 0.8825 - val_loss: 0.7593 - val_accuracy: 0.6909\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2939 - accuracy: 0.8846 - val_loss: 0.7186 - val_accuracy: 0.6364\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2783 - accuracy: 0.8889 - val_loss: 0.7518 - val_accuracy: 0.6909\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2830 - accuracy: 0.8846 - val_loss: 0.7534 - val_accuracy: 0.6909\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2780 - accuracy: 0.8868 - val_loss: 0.7573 - val_accuracy: 0.6909\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2713 - accuracy: 0.8932 - val_loss: 0.7497 - val_accuracy: 0.6727\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2699 - accuracy: 0.8996 - val_loss: 0.7439 - val_accuracy: 0.6182\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2798 - accuracy: 0.8825 - val_loss: 0.7504 - val_accuracy: 0.6545\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2659 - accuracy: 0.8889 - val_loss: 0.7607 - val_accuracy: 0.6727\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2633 - accuracy: 0.8996 - val_loss: 0.7571 - val_accuracy: 0.6545\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2688 - accuracy: 0.8996 - val_loss: 0.7563 - val_accuracy: 0.6000\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.2762 - accuracy: 0.8974 - val_loss: 0.7632 - val_accuracy: 0.6000\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2706 - accuracy: 0.8697 - val_loss: 0.7724 - val_accuracy: 0.6364\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2576 - accuracy: 0.9188 - val_loss: 0.7665 - val_accuracy: 0.6545\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2505 - accuracy: 0.9081 - val_loss: 0.7751 - val_accuracy: 0.6727\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2451 - accuracy: 0.9145 - val_loss: 0.8189 - val_accuracy: 0.6727\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2464 - accuracy: 0.9081 - val_loss: 0.7889 - val_accuracy: 0.6364\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2508 - accuracy: 0.9124 - val_loss: 0.7885 - val_accuracy: 0.6182\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2509 - accuracy: 0.8910 - val_loss: 0.7998 - val_accuracy: 0.6727\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2363 - accuracy: 0.9081 - val_loss: 0.8142 - val_accuracy: 0.6727\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2306 - accuracy: 0.9167 - val_loss: 0.8650 - val_accuracy: 0.6909\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2422 - accuracy: 0.9103 - val_loss: 0.8367 - val_accuracy: 0.6727\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2479 - accuracy: 0.9167 - val_loss: 0.8487 - val_accuracy: 0.6727\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2360 - accuracy: 0.9017 - val_loss: 0.8201 - val_accuracy: 0.6182\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2462 - accuracy: 0.9038 - val_loss: 0.8999 - val_accuracy: 0.7091\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2244 - accuracy: 0.9124 - val_loss: 0.8712 - val_accuracy: 0.6727\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2187 - accuracy: 0.9188 - val_loss: 0.8382 - val_accuracy: 0.6364\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2216 - accuracy: 0.9103 - val_loss: 0.8574 - val_accuracy: 0.6545\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2607 - accuracy: 0.8996 - val_loss: 0.9038 - val_accuracy: 0.6909\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.2209 - accuracy: 0.9188 - val_loss: 0.8639 - val_accuracy: 0.6545\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2096 - accuracy: 0.9231 - val_loss: 0.8426 - val_accuracy: 0.6364\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2078 - accuracy: 0.9252 - val_loss: 0.8538 - val_accuracy: 0.6364\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2070 - accuracy: 0.9274 - val_loss: 0.8534 - val_accuracy: 0.6364\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2234 - accuracy: 0.9209 - val_loss: 0.8411 - val_accuracy: 0.6545\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2129 - accuracy: 0.9338 - val_loss: 0.8469 - val_accuracy: 0.6364\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.2149 - accuracy: 0.9316 - val_loss: 0.8663 - val_accuracy: 0.6182\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2501 - accuracy: 0.9103 - val_loss: 0.8631 - val_accuracy: 0.6364\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2069 - accuracy: 0.9316 - val_loss: 0.8987 - val_accuracy: 0.6545\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1955 - accuracy: 0.9380 - val_loss: 0.8960 - val_accuracy: 0.6364\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1903 - accuracy: 0.9444 - val_loss: 0.9178 - val_accuracy: 0.6545\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1928 - accuracy: 0.9380 - val_loss: 0.8987 - val_accuracy: 0.6364\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1869 - accuracy: 0.9402 - val_loss: 0.8935 - val_accuracy: 0.6545\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1810 - accuracy: 0.9487 - val_loss: 0.9370 - val_accuracy: 0.6545\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1795 - accuracy: 0.9487 - val_loss: 0.9205 - val_accuracy: 0.6364\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1796 - accuracy: 0.9444 - val_loss: 0.9554 - val_accuracy: 0.6182\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1747 - accuracy: 0.9509 - val_loss: 0.9493 - val_accuracy: 0.6545\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1734 - accuracy: 0.9466 - val_loss: 0.9513 - val_accuracy: 0.6364\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1776 - accuracy: 0.9402 - val_loss: 0.9418 - val_accuracy: 0.6545\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1695 - accuracy: 0.9530 - val_loss: 0.9403 - val_accuracy: 0.6182\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1641 - accuracy: 0.9615 - val_loss: 0.9694 - val_accuracy: 0.6364\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1721 - accuracy: 0.9423 - val_loss: 1.0033 - val_accuracy: 0.6545\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.1677 - accuracy: 0.9530 - val_loss: 0.9703 - val_accuracy: 0.6545\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1612 - accuracy: 0.9509 - val_loss: 1.0010 - val_accuracy: 0.6364\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1679 - accuracy: 0.9530 - val_loss: 0.9845 - val_accuracy: 0.6545\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.1554 - accuracy: 0.9615 - val_loss: 1.0501 - val_accuracy: 0.6909\n",
      "Epoch 144/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1743 - accuracy: 0.9487 - val_loss: 1.0026 - val_accuracy: 0.6364\n",
      "Epoch 145/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1528 - accuracy: 0.9551 - val_loss: 1.0235 - val_accuracy: 0.6545\n",
      "Epoch 146/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1512 - accuracy: 0.9573 - val_loss: 1.0528 - val_accuracy: 0.6545\n",
      "Epoch 147/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1482 - accuracy: 0.9530 - val_loss: 1.0420 - val_accuracy: 0.6364\n",
      "Epoch 148/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1460 - accuracy: 0.9615 - val_loss: 1.0475 - val_accuracy: 0.6364\n",
      "Epoch 149/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1469 - accuracy: 0.9573 - val_loss: 1.0443 - val_accuracy: 0.6545\n",
      "Epoch 150/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1567 - accuracy: 0.9487 - val_loss: 1.0822 - val_accuracy: 0.6545\n",
      "Epoch 151/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1494 - accuracy: 0.9594 - val_loss: 1.1043 - val_accuracy: 0.6727\n",
      "Epoch 152/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1517 - accuracy: 0.9594 - val_loss: 1.0789 - val_accuracy: 0.6545\n",
      "Epoch 153/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1574 - accuracy: 0.9487 - val_loss: 1.0614 - val_accuracy: 0.6182\n",
      "Epoch 154/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1363 - accuracy: 0.9679 - val_loss: 1.1251 - val_accuracy: 0.6727\n",
      "Epoch 155/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1364 - accuracy: 0.9573 - val_loss: 1.0722 - val_accuracy: 0.6182\n",
      "Epoch 156/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1321 - accuracy: 0.9637 - val_loss: 1.1169 - val_accuracy: 0.7091\n",
      "Epoch 157/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1352 - accuracy: 0.9658 - val_loss: 1.0967 - val_accuracy: 0.6182\n",
      "Epoch 158/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1322 - accuracy: 0.9658 - val_loss: 1.1378 - val_accuracy: 0.6182\n",
      "Epoch 159/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1321 - accuracy: 0.9594 - val_loss: 1.1483 - val_accuracy: 0.6727\n",
      "Epoch 160/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1369 - accuracy: 0.9637 - val_loss: 1.1439 - val_accuracy: 0.6364\n",
      "Epoch 161/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1327 - accuracy: 0.9658 - val_loss: 1.1214 - val_accuracy: 0.6000\n",
      "Epoch 162/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1502 - accuracy: 0.9530 - val_loss: 1.1279 - val_accuracy: 0.6182\n",
      "Epoch 163/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1364 - accuracy: 0.9637 - val_loss: 1.1400 - val_accuracy: 0.6000\n",
      "Epoch 164/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1321 - accuracy: 0.9658 - val_loss: 1.1279 - val_accuracy: 0.6000\n",
      "Epoch 165/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1284 - accuracy: 0.9679 - val_loss: 1.1197 - val_accuracy: 0.6182\n",
      "Epoch 166/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1218 - accuracy: 0.9679 - val_loss: 1.1510 - val_accuracy: 0.6182\n",
      "Epoch 167/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1136 - accuracy: 0.9765 - val_loss: 1.1670 - val_accuracy: 0.6182\n",
      "Epoch 168/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1115 - accuracy: 0.9722 - val_loss: 1.1967 - val_accuracy: 0.6545\n",
      "Epoch 169/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1182 - accuracy: 0.9679 - val_loss: 1.2156 - val_accuracy: 0.6364\n",
      "Epoch 170/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1255 - accuracy: 0.9615 - val_loss: 1.1974 - val_accuracy: 0.6000\n",
      "Epoch 171/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1159 - accuracy: 0.9658 - val_loss: 1.2019 - val_accuracy: 0.6545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1076 - accuracy: 0.9786 - val_loss: 1.2019 - val_accuracy: 0.6000\n",
      "Epoch 173/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1068 - accuracy: 0.9722 - val_loss: 1.2213 - val_accuracy: 0.6000\n",
      "Epoch 174/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1046 - accuracy: 0.9722 - val_loss: 1.2202 - val_accuracy: 0.6182\n",
      "Epoch 175/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1055 - accuracy: 0.9786 - val_loss: 1.2435 - val_accuracy: 0.6000\n",
      "Epoch 176/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1057 - accuracy: 0.9615 - val_loss: 1.2664 - val_accuracy: 0.6364\n",
      "Epoch 177/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0983 - accuracy: 0.9722 - val_loss: 1.2485 - val_accuracy: 0.6000\n",
      "Epoch 178/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0971 - accuracy: 0.9850 - val_loss: 1.2836 - val_accuracy: 0.6364\n",
      "Epoch 179/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0950 - accuracy: 0.9786 - val_loss: 1.2773 - val_accuracy: 0.6182\n",
      "Epoch 180/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0938 - accuracy: 0.9829 - val_loss: 1.2877 - val_accuracy: 0.6364\n",
      "Epoch 181/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0952 - accuracy: 0.9786 - val_loss: 1.3098 - val_accuracy: 0.6364\n",
      "Epoch 182/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0952 - accuracy: 0.9722 - val_loss: 1.4272 - val_accuracy: 0.7273\n",
      "Epoch 183/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1002 - accuracy: 0.9744 - val_loss: 1.3402 - val_accuracy: 0.6364\n",
      "Epoch 184/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0889 - accuracy: 0.9829 - val_loss: 1.3318 - val_accuracy: 0.6000\n",
      "Epoch 185/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1305 - accuracy: 0.9530 - val_loss: 1.3472 - val_accuracy: 0.6182\n",
      "Epoch 186/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0955 - accuracy: 0.9744 - val_loss: 1.3306 - val_accuracy: 0.6182\n",
      "Epoch 187/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0878 - accuracy: 0.9829 - val_loss: 1.3379 - val_accuracy: 0.6000\n",
      "Epoch 188/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0821 - accuracy: 0.9829 - val_loss: 1.3636 - val_accuracy: 0.6364\n",
      "Epoch 189/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0897 - accuracy: 0.9808 - val_loss: 1.3765 - val_accuracy: 0.6364\n",
      "Epoch 190/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0798 - accuracy: 0.9829 - val_loss: 1.4000 - val_accuracy: 0.6182\n",
      "Epoch 191/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1007 - accuracy: 0.9658 - val_loss: 1.5063 - val_accuracy: 0.7273\n",
      "Epoch 192/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0848 - accuracy: 0.9808 - val_loss: 1.4069 - val_accuracy: 0.6182\n",
      "Epoch 193/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0985 - accuracy: 0.9744 - val_loss: 1.4138 - val_accuracy: 0.6182\n",
      "Epoch 194/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1039 - accuracy: 0.9658 - val_loss: 1.5247 - val_accuracy: 0.6727\n",
      "Epoch 195/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1105 - accuracy: 0.9658 - val_loss: 1.5362 - val_accuracy: 0.7091\n",
      "Epoch 196/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1015 - accuracy: 0.9679 - val_loss: 1.4601 - val_accuracy: 0.6364\n",
      "Epoch 197/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0788 - accuracy: 0.9872 - val_loss: 1.4170 - val_accuracy: 0.6182\n",
      "Epoch 198/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0763 - accuracy: 0.9872 - val_loss: 1.4598 - val_accuracy: 0.5818\n",
      "Epoch 199/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0805 - accuracy: 0.9872 - val_loss: 1.4588 - val_accuracy: 0.6000\n",
      "Epoch 200/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0738 - accuracy: 0.9829 - val_loss: 1.4656 - val_accuracy: 0.6364\n",
      "Epoch 201/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0777 - accuracy: 0.9850 - val_loss: 1.4753 - val_accuracy: 0.6182\n",
      "Epoch 202/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0806 - accuracy: 0.9829 - val_loss: 1.5028 - val_accuracy: 0.6000\n",
      "Epoch 203/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0886 - accuracy: 0.9786 - val_loss: 1.5310 - val_accuracy: 0.6364\n",
      "Epoch 204/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0852 - accuracy: 0.9744 - val_loss: 1.5114 - val_accuracy: 0.6364\n",
      "Epoch 205/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0694 - accuracy: 0.9850 - val_loss: 1.5392 - val_accuracy: 0.6364\n",
      "Epoch 206/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0712 - accuracy: 0.9829 - val_loss: 1.5493 - val_accuracy: 0.6182\n",
      "Epoch 207/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0694 - accuracy: 0.9850 - val_loss: 1.5783 - val_accuracy: 0.6364\n",
      "Epoch 208/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0779 - accuracy: 0.9744 - val_loss: 1.5695 - val_accuracy: 0.6364\n",
      "Epoch 209/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0689 - accuracy: 0.9872 - val_loss: 1.6035 - val_accuracy: 0.6364\n",
      "Epoch 210/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0706 - accuracy: 0.9829 - val_loss: 1.5961 - val_accuracy: 0.6182\n",
      "Epoch 211/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0634 - accuracy: 0.9850 - val_loss: 1.6091 - val_accuracy: 0.5455\n",
      "Epoch 212/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0818 - accuracy: 0.9701 - val_loss: 1.6031 - val_accuracy: 0.5455\n",
      "Epoch 213/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0639 - accuracy: 0.9872 - val_loss: 1.6157 - val_accuracy: 0.5818\n",
      "Epoch 214/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0594 - accuracy: 0.9872 - val_loss: 1.6418 - val_accuracy: 0.6364\n",
      "Epoch 215/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0583 - accuracy: 0.9872 - val_loss: 1.6553 - val_accuracy: 0.6364\n",
      "Epoch 216/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0610 - accuracy: 0.9893 - val_loss: 1.6647 - val_accuracy: 0.6364\n",
      "Epoch 217/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0566 - accuracy: 0.9893 - val_loss: 1.6734 - val_accuracy: 0.6364\n",
      "Epoch 218/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0587 - accuracy: 0.9872 - val_loss: 1.6862 - val_accuracy: 0.5273\n",
      "Epoch 219/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0556 - accuracy: 0.9872 - val_loss: 1.7046 - val_accuracy: 0.6364\n",
      "Epoch 220/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0600 - accuracy: 0.9850 - val_loss: 1.7084 - val_accuracy: 0.6364\n",
      "Epoch 221/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0559 - accuracy: 0.9893 - val_loss: 1.7197 - val_accuracy: 0.5818\n",
      "Epoch 222/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0538 - accuracy: 0.9872 - val_loss: 1.7446 - val_accuracy: 0.6182\n",
      "Epoch 223/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0547 - accuracy: 0.9893 - val_loss: 1.7687 - val_accuracy: 0.6182\n",
      "Epoch 224/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0520 - accuracy: 0.9915 - val_loss: 1.7628 - val_accuracy: 0.6182\n",
      "Epoch 225/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0603 - accuracy: 0.9808 - val_loss: 1.8031 - val_accuracy: 0.6364\n",
      "Epoch 226/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0541 - accuracy: 0.9872 - val_loss: 1.7826 - val_accuracy: 0.6364\n",
      "Epoch 227/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 1.7678 - val_accuracy: 0.6000\n",
      "Epoch 228/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0465 - accuracy: 0.9872 - val_loss: 1.8066 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0462 - accuracy: 0.9893 - val_loss: 1.8129 - val_accuracy: 0.5818\n",
      "Epoch 230/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0533 - accuracy: 0.9915 - val_loss: 1.8288 - val_accuracy: 0.5818\n",
      "Epoch 231/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0492 - accuracy: 0.9893 - val_loss: 1.8467 - val_accuracy: 0.6364\n",
      "Epoch 232/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0471 - accuracy: 0.9850 - val_loss: 1.8631 - val_accuracy: 0.5273\n",
      "Epoch 233/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0468 - accuracy: 0.9915 - val_loss: 1.8598 - val_accuracy: 0.5273\n",
      "Epoch 234/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0457 - accuracy: 0.9915 - val_loss: 1.8913 - val_accuracy: 0.6364\n",
      "Epoch 235/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0499 - accuracy: 0.9893 - val_loss: 1.9122 - val_accuracy: 0.5818\n",
      "Epoch 236/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0431 - accuracy: 0.9872 - val_loss: 1.9207 - val_accuracy: 0.6000\n",
      "Epoch 237/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0442 - accuracy: 0.9915 - val_loss: 1.9398 - val_accuracy: 0.5636\n",
      "Epoch 238/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0395 - accuracy: 0.9893 - val_loss: 1.9397 - val_accuracy: 0.5818\n",
      "Epoch 239/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0398 - accuracy: 0.9915 - val_loss: 1.9638 - val_accuracy: 0.6000\n",
      "Epoch 240/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0371 - accuracy: 0.9915 - val_loss: 1.9700 - val_accuracy: 0.6364\n",
      "Epoch 241/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0364 - accuracy: 0.9936 - val_loss: 1.9751 - val_accuracy: 0.5818\n",
      "Epoch 242/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0366 - accuracy: 0.9915 - val_loss: 1.9974 - val_accuracy: 0.5818\n",
      "Epoch 243/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0448 - accuracy: 0.9872 - val_loss: 2.0095 - val_accuracy: 0.6000\n",
      "Epoch 244/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0407 - accuracy: 0.9915 - val_loss: 2.0065 - val_accuracy: 0.6000\n",
      "Epoch 245/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0429 - accuracy: 0.9915 - val_loss: 2.0354 - val_accuracy: 0.5091\n",
      "Epoch 246/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0447 - accuracy: 0.9915 - val_loss: 2.0456 - val_accuracy: 0.5273\n",
      "Epoch 247/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0361 - accuracy: 0.9936 - val_loss: 2.0599 - val_accuracy: 0.5273\n",
      "Epoch 248/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0337 - accuracy: 0.9936 - val_loss: 2.0683 - val_accuracy: 0.6000\n",
      "Epoch 249/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0325 - accuracy: 0.9915 - val_loss: 2.1043 - val_accuracy: 0.6000\n",
      "Epoch 250/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0372 - accuracy: 0.9915 - val_loss: 2.1057 - val_accuracy: 0.6000\n",
      "Epoch 251/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0542 - accuracy: 0.9808 - val_loss: 2.2322 - val_accuracy: 0.6545\n",
      "Epoch 252/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0341 - accuracy: 0.9915 - val_loss: 2.1406 - val_accuracy: 0.5636\n",
      "Epoch 253/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0360 - accuracy: 0.9915 - val_loss: 2.1436 - val_accuracy: 0.6364\n",
      "Epoch 254/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0362 - accuracy: 0.9936 - val_loss: 2.1180 - val_accuracy: 0.6000\n",
      "Epoch 255/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0314 - accuracy: 0.9893 - val_loss: 2.1686 - val_accuracy: 0.6364\n",
      "Epoch 256/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0294 - accuracy: 0.9957 - val_loss: 2.1728 - val_accuracy: 0.5455\n",
      "Epoch 257/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0320 - accuracy: 0.9936 - val_loss: 2.1919 - val_accuracy: 0.5455\n",
      "Epoch 258/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0302 - accuracy: 0.9936 - val_loss: 2.2067 - val_accuracy: 0.5455\n",
      "Epoch 259/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0311 - accuracy: 0.9936 - val_loss: 2.1894 - val_accuracy: 0.5818\n",
      "Epoch 260/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0288 - accuracy: 0.9936 - val_loss: 2.1973 - val_accuracy: 0.5455\n",
      "Epoch 261/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0293 - accuracy: 0.9936 - val_loss: 2.1925 - val_accuracy: 0.5273\n",
      "Epoch 262/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0296 - accuracy: 0.9936 - val_loss: 2.2462 - val_accuracy: 0.5091\n",
      "Epoch 263/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0280 - accuracy: 0.9979 - val_loss: 2.2430 - val_accuracy: 0.5636\n",
      "Epoch 264/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0317 - accuracy: 0.9915 - val_loss: 2.2779 - val_accuracy: 0.5273\n",
      "Epoch 265/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0383 - accuracy: 0.9872 - val_loss: 2.3189 - val_accuracy: 0.4727\n",
      "Epoch 266/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0442 - accuracy: 0.9893 - val_loss: 2.2445 - val_accuracy: 0.5273\n",
      "Epoch 267/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0280 - accuracy: 0.9936 - val_loss: 2.2632 - val_accuracy: 0.5273\n",
      "Epoch 268/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 2.2916 - val_accuracy: 0.5636\n",
      "Epoch 269/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0224 - accuracy: 0.9915 - val_loss: 2.3234 - val_accuracy: 0.5455\n",
      "Epoch 270/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0230 - accuracy: 0.9957 - val_loss: 2.3831 - val_accuracy: 0.5636\n",
      "Epoch 271/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0216 - accuracy: 0.9957 - val_loss: 2.3606 - val_accuracy: 0.5636\n",
      "Epoch 272/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0213 - accuracy: 0.9957 - val_loss: 2.3905 - val_accuracy: 0.5636\n",
      "Epoch 273/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 2.3991 - val_accuracy: 0.4909\n",
      "Epoch 274/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0212 - accuracy: 0.9979 - val_loss: 2.3949 - val_accuracy: 0.5455\n",
      "Epoch 275/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0235 - accuracy: 0.9957 - val_loss: 2.4309 - val_accuracy: 0.4727\n",
      "Epoch 276/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0272 - accuracy: 0.9936 - val_loss: 2.5156 - val_accuracy: 0.5091\n",
      "Epoch 277/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0438 - accuracy: 0.9829 - val_loss: 2.4388 - val_accuracy: 0.5091\n",
      "Epoch 278/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0203 - accuracy: 0.9957 - val_loss: 2.4420 - val_accuracy: 0.5818\n",
      "Epoch 279/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.9979 - val_loss: 2.5068 - val_accuracy: 0.5273\n",
      "Epoch 280/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0217 - accuracy: 0.9957 - val_loss: 2.5294 - val_accuracy: 0.5091\n",
      "Epoch 281/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0192 - accuracy: 0.9979 - val_loss: 2.4926 - val_accuracy: 0.5636\n",
      "Epoch 282/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 2.5126 - val_accuracy: 0.5455\n",
      "Epoch 283/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0203 - accuracy: 0.9957 - val_loss: 2.5540 - val_accuracy: 0.5818\n",
      "Epoch 284/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0212 - accuracy: 0.9979 - val_loss: 2.5680 - val_accuracy: 0.5818\n",
      "Epoch 285/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0229 - accuracy: 0.9936 - val_loss: 2.5639 - val_accuracy: 0.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 2.5582 - val_accuracy: 0.5636\n",
      "Epoch 287/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.5525 - val_accuracy: 0.5273\n",
      "Epoch 288/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0162 - accuracy: 0.9979 - val_loss: 2.5782 - val_accuracy: 0.5818\n",
      "Epoch 289/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0158 - accuracy: 0.9979 - val_loss: 2.6004 - val_accuracy: 0.5818\n",
      "Epoch 290/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 2.6221 - val_accuracy: 0.5818\n",
      "Epoch 291/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.6155 - val_accuracy: 0.5818\n",
      "Epoch 292/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0150 - accuracy: 0.9979 - val_loss: 2.6364 - val_accuracy: 0.5818\n",
      "Epoch 293/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0175 - accuracy: 0.9979 - val_loss: 2.6615 - val_accuracy: 0.5455\n",
      "Epoch 294/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.6759 - val_accuracy: 0.5818\n",
      "Epoch 295/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.6684 - val_accuracy: 0.5636\n",
      "Epoch 296/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.7052 - val_accuracy: 0.5818\n",
      "Epoch 297/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.6909 - val_accuracy: 0.5636\n",
      "Epoch 298/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.7106 - val_accuracy: 0.5818\n",
      "Epoch 299/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.7163 - val_accuracy: 0.5273\n",
      "Epoch 300/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.7228 - val_accuracy: 0.5273\n",
      "Epoch 301/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.7634 - val_accuracy: 0.5455\n",
      "Epoch 302/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.7647 - val_accuracy: 0.5273\n",
      "Epoch 303/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0161 - accuracy: 0.9979 - val_loss: 2.7743 - val_accuracy: 0.4909\n",
      "Epoch 304/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.7775 - val_accuracy: 0.5455\n",
      "Epoch 305/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.7992 - val_accuracy: 0.5636\n",
      "Epoch 306/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.8095 - val_accuracy: 0.5273\n",
      "Epoch 307/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.8334 - val_accuracy: 0.5455\n",
      "Epoch 308/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.8513 - val_accuracy: 0.5818\n",
      "Epoch 309/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.8537 - val_accuracy: 0.5818\n",
      "Epoch 310/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.8624 - val_accuracy: 0.5273\n",
      "Epoch 311/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.8981 - val_accuracy: 0.5818\n",
      "Epoch 312/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.8872 - val_accuracy: 0.5455\n",
      "Epoch 313/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.9101 - val_accuracy: 0.5818\n",
      "Epoch 314/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.9122 - val_accuracy: 0.5636\n",
      "Epoch 315/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.9061 - val_accuracy: 0.5273\n",
      "Epoch 316/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.9430 - val_accuracy: 0.5818\n",
      "Epoch 317/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.9681 - val_accuracy: 0.5818\n",
      "Epoch 318/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9473 - val_accuracy: 0.5818\n",
      "Epoch 319/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.9727 - val_accuracy: 0.5818\n",
      "Epoch 320/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.9837 - val_accuracy: 0.5818\n",
      "Epoch 321/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9915 - val_accuracy: 0.5818\n",
      "Epoch 322/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.9941 - val_accuracy: 0.5818\n",
      "Epoch 323/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0018 - val_accuracy: 0.5273\n",
      "Epoch 324/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 3.0212 - val_accuracy: 0.5091\n",
      "Epoch 325/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 3.0216 - val_accuracy: 0.5091\n",
      "Epoch 326/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 3.0348 - val_accuracy: 0.5455\n",
      "Epoch 327/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0610 - val_accuracy: 0.5818\n",
      "Epoch 328/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.0708 - val_accuracy: 0.5636\n",
      "Epoch 329/500\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.0729 - val_accuracy: 0.5818\n",
      "Epoch 330/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.1254 - val_accuracy: 0.5818\n",
      "Epoch 331/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.1035 - val_accuracy: 0.5818\n",
      "Epoch 332/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.0917 - val_accuracy: 0.5273\n",
      "Epoch 333/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 3.1018 - val_accuracy: 0.5818\n",
      "Epoch 334/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.1104 - val_accuracy: 0.5091\n",
      "Epoch 335/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.1343 - val_accuracy: 0.5818\n",
      "Epoch 336/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.1422 - val_accuracy: 0.5455\n",
      "Epoch 337/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 3.1309 - val_accuracy: 0.5273\n",
      "Epoch 338/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1374 - val_accuracy: 0.5273\n",
      "Epoch 339/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 3.1549 - val_accuracy: 0.5455\n",
      "Epoch 340/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.1698 - val_accuracy: 0.5091\n",
      "Epoch 341/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1796 - val_accuracy: 0.5091\n",
      "Epoch 342/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.1871 - val_accuracy: 0.5273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 3.2198 - val_accuracy: 0.5818\n",
      "Epoch 344/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.2466 - val_accuracy: 0.5636\n",
      "Epoch 345/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 3.2490 - val_accuracy: 0.5273\n",
      "Epoch 346/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.2741 - val_accuracy: 0.5818\n",
      "Epoch 347/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 3.2749 - val_accuracy: 0.5455\n",
      "Epoch 348/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.2712 - val_accuracy: 0.5273\n",
      "Epoch 349/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.2755 - val_accuracy: 0.5091\n",
      "Epoch 350/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 3.2675 - val_accuracy: 0.5455\n",
      "Epoch 351/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.2802 - val_accuracy: 0.5273\n",
      "Epoch 352/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.3099 - val_accuracy: 0.5818\n",
      "Epoch 353/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 3.3101 - val_accuracy: 0.5273\n",
      "Epoch 354/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.3311 - val_accuracy: 0.5636\n",
      "Epoch 355/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 3.3521 - val_accuracy: 0.5455\n",
      "Epoch 356/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.3311 - val_accuracy: 0.5455\n",
      "Epoch 357/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 3.3124 - val_accuracy: 0.5273\n",
      "Epoch 358/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.3376 - val_accuracy: 0.5455\n",
      "Epoch 359/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.3825 - val_accuracy: 0.5636\n",
      "Epoch 360/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 3.4206 - val_accuracy: 0.5273\n",
      "Epoch 361/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.3876 - val_accuracy: 0.5273\n",
      "Epoch 362/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 3.4022 - val_accuracy: 0.5455\n",
      "Epoch 363/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 3.4064 - val_accuracy: 0.5091\n",
      "Epoch 364/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 3.3390 - val_accuracy: 0.5273\n",
      "Epoch 365/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 3.3524 - val_accuracy: 0.5273\n",
      "Epoch 366/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.4459 - val_accuracy: 0.6000\n",
      "Epoch 367/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.4258 - val_accuracy: 0.5455\n",
      "Epoch 368/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.4214 - val_accuracy: 0.5273\n",
      "Epoch 369/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.4456 - val_accuracy: 0.5273\n",
      "Epoch 370/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.4632 - val_accuracy: 0.5455\n",
      "Epoch 371/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.4661 - val_accuracy: 0.5273\n",
      "Epoch 372/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.4878 - val_accuracy: 0.5636\n",
      "Epoch 373/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 3.5143 - val_accuracy: 0.5636\n",
      "Epoch 374/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 3.4933 - val_accuracy: 0.5455\n",
      "Epoch 375/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0162 - accuracy: 0.9979 - val_loss: 3.3938 - val_accuracy: 0.5455\n",
      "Epoch 376/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 3.5561 - val_accuracy: 0.4909\n",
      "Epoch 377/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 3.5895 - val_accuracy: 0.4909\n",
      "Epoch 378/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 3.5123 - val_accuracy: 0.5273\n",
      "Epoch 379/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.5435 - val_accuracy: 0.5455\n",
      "Epoch 380/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.5347 - val_accuracy: 0.5273\n",
      "Epoch 381/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.5621 - val_accuracy: 0.5455\n",
      "Epoch 382/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.5451 - val_accuracy: 0.5273\n",
      "Epoch 383/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.5499 - val_accuracy: 0.5273\n",
      "Epoch 384/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.5602 - val_accuracy: 0.5636\n",
      "Epoch 385/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.5662 - val_accuracy: 0.5636\n",
      "Epoch 386/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.5730 - val_accuracy: 0.5636\n",
      "Epoch 387/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.5664 - val_accuracy: 0.5455\n",
      "Epoch 388/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.5750 - val_accuracy: 0.5455\n",
      "Epoch 389/500\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.5842 - val_accuracy: 0.5636\n",
      "Epoch 390/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.5878 - val_accuracy: 0.5636\n",
      "Epoch 391/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.6057 - val_accuracy: 0.5636\n",
      "Epoch 392/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.5967 - val_accuracy: 0.5455\n",
      "Epoch 393/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.6238 - val_accuracy: 0.5818\n",
      "Epoch 394/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.6113 - val_accuracy: 0.5455\n",
      "Epoch 395/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.6333 - val_accuracy: 0.5455\n",
      "Epoch 396/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.6376 - val_accuracy: 0.5818\n",
      "Epoch 397/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.6317 - val_accuracy: 0.5273\n",
      "Epoch 398/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.6652 - val_accuracy: 0.5818\n",
      "Epoch 399/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.6471 - val_accuracy: 0.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.6788 - val_accuracy: 0.5636\n",
      "Epoch 401/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.6967 - val_accuracy: 0.5636\n",
      "Epoch 402/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.6737 - val_accuracy: 0.5455\n",
      "Epoch 403/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.7081 - val_accuracy: 0.5818\n",
      "Epoch 404/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.7281 - val_accuracy: 0.5818\n",
      "Epoch 405/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.6891 - val_accuracy: 0.5455\n",
      "Epoch 406/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.7005 - val_accuracy: 0.5273\n",
      "Epoch 407/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.7079 - val_accuracy: 0.5636\n",
      "Epoch 408/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.7382 - val_accuracy: 0.5636\n",
      "Epoch 409/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.7294 - val_accuracy: 0.5455\n",
      "Epoch 410/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.7282 - val_accuracy: 0.5273\n",
      "Epoch 411/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.7506 - val_accuracy: 0.5273\n",
      "Epoch 412/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.8269 - val_accuracy: 0.5636\n",
      "Epoch 413/500\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.7621 - val_accuracy: 0.5636\n",
      "Epoch 414/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.7503 - val_accuracy: 0.5455\n",
      "Epoch 415/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.7689 - val_accuracy: 0.5636\n",
      "Epoch 416/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.7728 - val_accuracy: 0.5455\n",
      "Epoch 417/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.7753 - val_accuracy: 0.5455\n",
      "Epoch 418/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.8023 - val_accuracy: 0.5636\n",
      "Epoch 419/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.7771 - val_accuracy: 0.5455\n",
      "Epoch 420/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.8080 - val_accuracy: 0.5636\n",
      "Epoch 421/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.8039 - val_accuracy: 0.5636\n",
      "Epoch 422/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.8192 - val_accuracy: 0.5636\n",
      "Epoch 423/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.8176 - val_accuracy: 0.5455\n",
      "Epoch 424/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.8367 - val_accuracy: 0.5636\n",
      "Epoch 425/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8394 - val_accuracy: 0.5455\n",
      "Epoch 426/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8507 - val_accuracy: 0.5636\n",
      "Epoch 427/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8393 - val_accuracy: 0.5455\n",
      "Epoch 428/500\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8543 - val_accuracy: 0.5636\n",
      "Epoch 429/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8604 - val_accuracy: 0.5455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6816c54c0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_212.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_212.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e125fb87",
   "metadata": {},
   "source": [
    "**For test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4f43e2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6037 - accuracy: 0.6923\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5699 - accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "m1_eval_test = model_212.evaluate(X_test, y_test)\n",
    "m1_eval_val = model_212.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fe5508b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n",
      "roc auc score:  0.6090225563909775\n",
      "average precision score:  0.5953945779904664\n"
     ]
    }
   ],
   "source": [
    "pred = model_212.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "777fed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "331ff201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7693491 , 0.23065087],\n",
       "       [0.77742004, 0.22257996],\n",
       "       [0.60963607, 0.39036396],\n",
       "       [0.3613364 , 0.6386636 ],\n",
       "       [0.42655462, 0.5734454 ],\n",
       "       [0.41279483, 0.58720523],\n",
       "       [0.6696947 , 0.33030525],\n",
       "       [0.5877574 , 0.41224253],\n",
       "       [0.73920995, 0.26079   ],\n",
       "       [0.78025013, 0.21974985],\n",
       "       [0.7628834 , 0.23711659],\n",
       "       [0.8023609 , 0.1976391 ],\n",
       "       [0.7087888 , 0.29121116],\n",
       "       [0.8839149 , 0.1160851 ],\n",
       "       [0.537254  , 0.46274602],\n",
       "       [0.8384107 , 0.16158934],\n",
       "       [0.7862765 , 0.21372348],\n",
       "       [0.8432934 , 0.15670663],\n",
       "       [0.5517205 , 0.44827944],\n",
       "       [0.5790524 , 0.42094758],\n",
       "       [0.5248467 , 0.47515333],\n",
       "       [0.7729976 , 0.22700237],\n",
       "       [0.76086885, 0.23913117],\n",
       "       [0.55006015, 0.44993988],\n",
       "       [0.74850553, 0.25149447],\n",
       "       [0.20727625, 0.7927237 ],\n",
       "       [0.8580525 , 0.14194748],\n",
       "       [0.9151948 , 0.08480522],\n",
       "       [0.8497915 , 0.15020856],\n",
       "       [0.66778815, 0.33221182],\n",
       "       [0.30152622, 0.6984739 ],\n",
       "       [0.7179323 , 0.28206772],\n",
       "       [0.3971409 , 0.60285914],\n",
       "       [0.76098686, 0.23901317],\n",
       "       [0.91821647, 0.0817835 ],\n",
       "       [0.8811803 , 0.11881971],\n",
       "       [0.60998297, 0.39001706],\n",
       "       [0.5945661 , 0.4054339 ],\n",
       "       [0.7999966 , 0.20000333],\n",
       "       [0.6025759 , 0.3974241 ],\n",
       "       [0.7928377 , 0.20716228],\n",
       "       [0.7627798 , 0.23722023],\n",
       "       [0.38992986, 0.6100701 ],\n",
       "       [0.37870544, 0.62129456],\n",
       "       [0.54072714, 0.45927283],\n",
       "       [0.5499375 , 0.45006245],\n",
       "       [0.9526816 , 0.04731843],\n",
       "       [0.9197344 , 0.08026554],\n",
       "       [0.79412436, 0.20587564],\n",
       "       [0.93521905, 0.06478094],\n",
       "       [0.6435974 , 0.35640258],\n",
       "       [0.73785365, 0.2621463 ]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a94abb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6037 - accuracy: 0.6923\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_212.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c916a5aa",
   "metadata": {},
   "source": [
    "**For validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6c79dd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "roc auc score:  0.6873065015479876\n",
      "average precision score:  0.665470286935307\n"
     ]
    }
   ],
   "source": [
    "pred = model_212.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8d031d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a1f1f5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5699 - accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels (validation set)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_212.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eca3449",
   "metadata": {},
   "source": [
    "**Model saving:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "77f48fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2503ef22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_211_json = model_211.to_json()\n",
    "with open(\"model_211.json\", \"w\") as json_file:\n",
    "    json_file.write(model_211_json)\n",
    "# serialize weights to HDF5\n",
    "model_211.save_weights(\"model_211.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "25ab768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_212_json = model_212.to_json()\n",
    "with open(\"model_212.json\", \"w\") as json_file:\n",
    "    json_file.write(model_212_json)\n",
    "# serialize weights to HDF5\n",
    "model_212.save_weights(\"model_212.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a28a87f",
   "metadata": {},
   "source": [
    "### 2.2 With resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f40e95ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_progressor = np.array(y_train)[:,1]\n",
    "y_progressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "94ceb84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_progressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9ed0956d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 768, 1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "85f2a076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 768)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2d = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]))\n",
    "X_train_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "559cecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(662, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy = 'minority')\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train_2d, y_progressor)\n",
    "print(X_train_over.shape)\n",
    "y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0ebc057f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>662 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1\n",
       "0    1  0\n",
       "1    0  1\n",
       "2    1  0\n",
       "3    1  0\n",
       "4    1  0\n",
       "..  .. ..\n",
       "657  0  1\n",
       "658  0  1\n",
       "659  0  1\n",
       "660  0  1\n",
       "661  0  1\n",
       "\n",
       "[662 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_over = pd.get_dummies(y_train_over)\n",
    "y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "92df9edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Progressor  Progressor\n",
      "0               1             331\n",
      "1               0             331\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_over=y_train_over.rename(columns={0: \"Non-Progressor\", 1: \"Progressor\"})\n",
    "print(y_train_over.value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f9abdf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Progressor  Progressor\n",
      "1               0             331\n",
      "0               1             137\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "707aa21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>662 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "0                 1           0\n",
       "1                 0           1\n",
       "2                 1           0\n",
       "3                 1           0\n",
       "4                 1           0\n",
       "..              ...         ...\n",
       "657               0           1\n",
       "658               0           1\n",
       "659               0           1\n",
       "660               0           1\n",
       "661               0           1\n",
       "\n",
       "[662 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bbee5770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(662, 768)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ae2ac258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.12335958],\n",
       "        [0.12335958],\n",
       "        [0.12073491],\n",
       "        ...,\n",
       "        [0.12598425],\n",
       "        [0.12598425],\n",
       "        [0.12335958]],\n",
       "\n",
       "       [[0.18372703],\n",
       "        [0.18635171],\n",
       "        [0.18897638],\n",
       "        ...,\n",
       "        [0.17322835],\n",
       "        [0.17585302],\n",
       "        [0.18110236]],\n",
       "\n",
       "       [[0.11548556],\n",
       "        [0.11811024],\n",
       "        [0.11811024],\n",
       "        ...,\n",
       "        [0.11811024],\n",
       "        [0.11811024],\n",
       "        [0.11548556]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.15485564],\n",
       "        [0.15485564],\n",
       "        [0.15748031],\n",
       "        ...,\n",
       "        [0.1496063 ],\n",
       "        [0.1496063 ],\n",
       "        [0.15223097]],\n",
       "\n",
       "       [[0.17585302],\n",
       "        [0.17585302],\n",
       "        [0.17847769],\n",
       "        ...,\n",
       "        [0.17322835],\n",
       "        [0.17322835],\n",
       "        [0.17585302]],\n",
       "\n",
       "       [[0.11023622],\n",
       "        [0.11286089],\n",
       "        [0.11286089],\n",
       "        ...,\n",
       "        [0.11023622],\n",
       "        [0.11023622],\n",
       "        [0.11023622]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over = np.reshape(X_train_over, (X_train_over.shape[0], X_train_over.shape[1], 1))\n",
    "X_train_over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82eaf73",
   "metadata": {},
   "source": [
    "#### 2.2.1 Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f41253ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 766, 64)           256       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 255, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 255, 64)           0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 16320)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                1044544   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,045,874\n",
      "Trainable params: 1,045,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model2\n",
    "model_221 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_221.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_221.add(MaxPooling1D(pool_size=3))\n",
    "# model_1.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_221.add(Dropout(0.5))\n",
    "# model_1.add(MaxPooling1D(pool_size=2))\n",
    "model_221.add(Flatten())\n",
    "model_221.add(Dense(64, activation='relu'))\n",
    "model_221.add(Dense(16, activation='relu'))\n",
    "model_221.add(Dense(2, activation='softmax'))\n",
    "model_221.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d0d29643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=400,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cb294477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.6936 - accuracy: 0.4955 - val_loss: 0.6820 - val_accuracy: 0.6909\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6913 - accuracy: 0.5106 - val_loss: 0.6861 - val_accuracy: 0.7091\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6906 - accuracy: 0.5378 - val_loss: 0.6841 - val_accuracy: 0.6364\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.6888 - accuracy: 0.5453 - val_loss: 0.6802 - val_accuracy: 0.6727\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6861 - accuracy: 0.5816 - val_loss: 0.6773 - val_accuracy: 0.6364\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6840 - accuracy: 0.5650 - val_loss: 0.6812 - val_accuracy: 0.6000\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6809 - accuracy: 0.6027 - val_loss: 0.6585 - val_accuracy: 0.6909\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6768 - accuracy: 0.5967 - val_loss: 0.6761 - val_accuracy: 0.5636\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6730 - accuracy: 0.6088 - val_loss: 0.6922 - val_accuracy: 0.5273\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6705 - accuracy: 0.6118 - val_loss: 0.6367 - val_accuracy: 0.6909\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6628 - accuracy: 0.6133 - val_loss: 0.6695 - val_accuracy: 0.5818\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6576 - accuracy: 0.6405 - val_loss: 0.6309 - val_accuracy: 0.7455\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6590 - accuracy: 0.6133 - val_loss: 0.6437 - val_accuracy: 0.6182\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.6560 - accuracy: 0.6254 - val_loss: 0.6202 - val_accuracy: 0.7273\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6513 - accuracy: 0.6435 - val_loss: 0.6548 - val_accuracy: 0.6000\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6464 - accuracy: 0.6208 - val_loss: 0.6515 - val_accuracy: 0.5818\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.6417 - accuracy: 0.6435 - val_loss: 0.6172 - val_accuracy: 0.7091\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6412 - accuracy: 0.6465 - val_loss: 0.6235 - val_accuracy: 0.6364\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.6362 - accuracy: 0.6511 - val_loss: 0.6651 - val_accuracy: 0.5818\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6326 - accuracy: 0.6571 - val_loss: 0.6235 - val_accuracy: 0.6364\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6290 - accuracy: 0.6752 - val_loss: 0.6194 - val_accuracy: 0.6364\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6248 - accuracy: 0.6647 - val_loss: 0.6597 - val_accuracy: 0.6000\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6246 - accuracy: 0.6647 - val_loss: 0.6448 - val_accuracy: 0.5818\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6220 - accuracy: 0.6586 - val_loss: 0.6365 - val_accuracy: 0.5818\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6244 - accuracy: 0.6511 - val_loss: 0.5988 - val_accuracy: 0.6727\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6209 - accuracy: 0.6752 - val_loss: 0.6538 - val_accuracy: 0.6000\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6116 - accuracy: 0.6843 - val_loss: 0.6235 - val_accuracy: 0.5818\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6069 - accuracy: 0.6828 - val_loss: 0.6209 - val_accuracy: 0.6364\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6049 - accuracy: 0.6903 - val_loss: 0.6559 - val_accuracy: 0.6000\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.6008 - accuracy: 0.7024 - val_loss: 0.6377 - val_accuracy: 0.6000\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5983 - accuracy: 0.7069 - val_loss: 0.6700 - val_accuracy: 0.5818\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6035 - accuracy: 0.6918 - val_loss: 0.6195 - val_accuracy: 0.6545\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5878 - accuracy: 0.7236 - val_loss: 0.6247 - val_accuracy: 0.6545\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5828 - accuracy: 0.7069 - val_loss: 0.6646 - val_accuracy: 0.6000\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5831 - accuracy: 0.7205 - val_loss: 0.6334 - val_accuracy: 0.6545\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5766 - accuracy: 0.7205 - val_loss: 0.6419 - val_accuracy: 0.6364\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5688 - accuracy: 0.7205 - val_loss: 0.6259 - val_accuracy: 0.6364\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5677 - accuracy: 0.7100 - val_loss: 0.6537 - val_accuracy: 0.6182\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5650 - accuracy: 0.7296 - val_loss: 0.6374 - val_accuracy: 0.6364\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5608 - accuracy: 0.7356 - val_loss: 0.6058 - val_accuracy: 0.6364\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5667 - accuracy: 0.7054 - val_loss: 0.6486 - val_accuracy: 0.6545\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5547 - accuracy: 0.7281 - val_loss: 0.6071 - val_accuracy: 0.6364\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5572 - accuracy: 0.7341 - val_loss: 0.6273 - val_accuracy: 0.6364\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5460 - accuracy: 0.7492 - val_loss: 0.6689 - val_accuracy: 0.6000\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5416 - accuracy: 0.7462 - val_loss: 0.6604 - val_accuracy: 0.6182\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5387 - accuracy: 0.7538 - val_loss: 0.7121 - val_accuracy: 0.6182\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5415 - accuracy: 0.7402 - val_loss: 0.6278 - val_accuracy: 0.6182\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5292 - accuracy: 0.7508 - val_loss: 0.6536 - val_accuracy: 0.6364\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5254 - accuracy: 0.7553 - val_loss: 0.7101 - val_accuracy: 0.6364\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5216 - accuracy: 0.7508 - val_loss: 0.6209 - val_accuracy: 0.6182\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5144 - accuracy: 0.7628 - val_loss: 0.6698 - val_accuracy: 0.6364\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5066 - accuracy: 0.7644 - val_loss: 0.6592 - val_accuracy: 0.6364\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5120 - accuracy: 0.7644 - val_loss: 0.6722 - val_accuracy: 0.6364\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5049 - accuracy: 0.7719 - val_loss: 0.6889 - val_accuracy: 0.6364\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5113 - accuracy: 0.7598 - val_loss: 0.6974 - val_accuracy: 0.6364\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5073 - accuracy: 0.7659 - val_loss: 0.7182 - val_accuracy: 0.6182\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4928 - accuracy: 0.7764 - val_loss: 0.6488 - val_accuracy: 0.6182\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4919 - accuracy: 0.7870 - val_loss: 0.6624 - val_accuracy: 0.6000\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4952 - accuracy: 0.7719 - val_loss: 0.6682 - val_accuracy: 0.6364\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4866 - accuracy: 0.7810 - val_loss: 0.6512 - val_accuracy: 0.6182\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4879 - accuracy: 0.7870 - val_loss: 0.6872 - val_accuracy: 0.6545\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4782 - accuracy: 0.7870 - val_loss: 0.6525 - val_accuracy: 0.6182\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4805 - accuracy: 0.7840 - val_loss: 0.6836 - val_accuracy: 0.6182\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4699 - accuracy: 0.7961 - val_loss: 0.6716 - val_accuracy: 0.6182\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4784 - accuracy: 0.7840 - val_loss: 0.6334 - val_accuracy: 0.6182\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4734 - accuracy: 0.7900 - val_loss: 0.6430 - val_accuracy: 0.6182\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4679 - accuracy: 0.7870 - val_loss: 0.6452 - val_accuracy: 0.6182\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4651 - accuracy: 0.7779 - val_loss: 0.6780 - val_accuracy: 0.6182\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4591 - accuracy: 0.8036 - val_loss: 0.6584 - val_accuracy: 0.6000\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4497 - accuracy: 0.8021 - val_loss: 0.6479 - val_accuracy: 0.6182\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4529 - accuracy: 0.8006 - val_loss: 0.6903 - val_accuracy: 0.6364\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4456 - accuracy: 0.8036 - val_loss: 0.6469 - val_accuracy: 0.6182\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4361 - accuracy: 0.8263 - val_loss: 0.7408 - val_accuracy: 0.6364\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4390 - accuracy: 0.8172 - val_loss: 0.6712 - val_accuracy: 0.6000\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4392 - accuracy: 0.8142 - val_loss: 0.7016 - val_accuracy: 0.6364\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4339 - accuracy: 0.8066 - val_loss: 0.6927 - val_accuracy: 0.6182\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4258 - accuracy: 0.8172 - val_loss: 0.7166 - val_accuracy: 0.6364\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4349 - accuracy: 0.8248 - val_loss: 0.6674 - val_accuracy: 0.6000\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4244 - accuracy: 0.8172 - val_loss: 0.6534 - val_accuracy: 0.6000\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4287 - accuracy: 0.8142 - val_loss: 0.6697 - val_accuracy: 0.6000\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4335 - accuracy: 0.8202 - val_loss: 0.6829 - val_accuracy: 0.6182\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4140 - accuracy: 0.8308 - val_loss: 0.6879 - val_accuracy: 0.6182\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4123 - accuracy: 0.8263 - val_loss: 0.6832 - val_accuracy: 0.6000\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4148 - accuracy: 0.8308 - val_loss: 0.6701 - val_accuracy: 0.6000\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4064 - accuracy: 0.8414 - val_loss: 0.7210 - val_accuracy: 0.6182\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4078 - accuracy: 0.8369 - val_loss: 0.6789 - val_accuracy: 0.6000\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4017 - accuracy: 0.8338 - val_loss: 0.6817 - val_accuracy: 0.6000\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4061 - accuracy: 0.8263 - val_loss: 0.6847 - val_accuracy: 0.6000\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4084 - accuracy: 0.8308 - val_loss: 0.6826 - val_accuracy: 0.6000\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3904 - accuracy: 0.8323 - val_loss: 0.7335 - val_accuracy: 0.6182\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3846 - accuracy: 0.8459 - val_loss: 0.7169 - val_accuracy: 0.6182\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3798 - accuracy: 0.8535 - val_loss: 0.7190 - val_accuracy: 0.6182\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3859 - accuracy: 0.8384 - val_loss: 0.6724 - val_accuracy: 0.6182\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3940 - accuracy: 0.8278 - val_loss: 0.7055 - val_accuracy: 0.6182\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3887 - accuracy: 0.8323 - val_loss: 0.6787 - val_accuracy: 0.6182\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3784 - accuracy: 0.8414 - val_loss: 0.7025 - val_accuracy: 0.6000\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3717 - accuracy: 0.8505 - val_loss: 0.7049 - val_accuracy: 0.6182\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3798 - accuracy: 0.8444 - val_loss: 0.6954 - val_accuracy: 0.6000\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3760 - accuracy: 0.8505 - val_loss: 0.6769 - val_accuracy: 0.6727\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3888 - accuracy: 0.8293 - val_loss: 0.6988 - val_accuracy: 0.5818\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3677 - accuracy: 0.8384 - val_loss: 0.7114 - val_accuracy: 0.6182\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3664 - accuracy: 0.8444 - val_loss: 0.6880 - val_accuracy: 0.6182\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3774 - accuracy: 0.8444 - val_loss: 0.7018 - val_accuracy: 0.5818\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3675 - accuracy: 0.8505 - val_loss: 0.7108 - val_accuracy: 0.5818\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3671 - accuracy: 0.8429 - val_loss: 0.7145 - val_accuracy: 0.5818\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3785 - accuracy: 0.8353 - val_loss: 0.7111 - val_accuracy: 0.6182\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3626 - accuracy: 0.8444 - val_loss: 0.7429 - val_accuracy: 0.6000\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3655 - accuracy: 0.8520 - val_loss: 0.7495 - val_accuracy: 0.6000\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3528 - accuracy: 0.8640 - val_loss: 0.7530 - val_accuracy: 0.6000\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3466 - accuracy: 0.8565 - val_loss: 0.7886 - val_accuracy: 0.6182\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3294 - accuracy: 0.8792 - val_loss: 0.7346 - val_accuracy: 0.6000\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3426 - accuracy: 0.8656 - val_loss: 0.7170 - val_accuracy: 0.6000\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3506 - accuracy: 0.8429 - val_loss: 0.7074 - val_accuracy: 0.6000\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3363 - accuracy: 0.8595 - val_loss: 0.7246 - val_accuracy: 0.6000\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 24ms/step - loss: 0.3386 - accuracy: 0.8656 - val_loss: 0.7854 - val_accuracy: 0.6182\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3346 - accuracy: 0.8489 - val_loss: 0.7557 - val_accuracy: 0.6000\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3250 - accuracy: 0.8656 - val_loss: 0.7400 - val_accuracy: 0.6000\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3271 - accuracy: 0.8610 - val_loss: 0.7438 - val_accuracy: 0.6000\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3177 - accuracy: 0.8731 - val_loss: 0.7358 - val_accuracy: 0.6182\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3192 - accuracy: 0.8837 - val_loss: 0.7605 - val_accuracy: 0.6000\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3219 - accuracy: 0.8610 - val_loss: 0.7464 - val_accuracy: 0.6000\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3125 - accuracy: 0.8776 - val_loss: 0.7466 - val_accuracy: 0.5818\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3097 - accuracy: 0.8761 - val_loss: 0.7549 - val_accuracy: 0.5818\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3166 - accuracy: 0.8792 - val_loss: 0.7817 - val_accuracy: 0.6000\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2978 - accuracy: 0.8822 - val_loss: 0.7866 - val_accuracy: 0.5818\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3132 - accuracy: 0.8822 - val_loss: 0.7568 - val_accuracy: 0.5818\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2973 - accuracy: 0.8897 - val_loss: 0.7631 - val_accuracy: 0.5818\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3064 - accuracy: 0.8867 - val_loss: 0.7744 - val_accuracy: 0.5818\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2984 - accuracy: 0.8882 - val_loss: 0.7702 - val_accuracy: 0.5818\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2953 - accuracy: 0.8897 - val_loss: 0.7665 - val_accuracy: 0.6000\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2832 - accuracy: 0.8988 - val_loss: 0.7718 - val_accuracy: 0.6000\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2904 - accuracy: 0.8867 - val_loss: 0.8000 - val_accuracy: 0.5818\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2854 - accuracy: 0.8776 - val_loss: 0.8113 - val_accuracy: 0.5818\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2780 - accuracy: 0.8927 - val_loss: 0.7580 - val_accuracy: 0.6364\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2911 - accuracy: 0.8927 - val_loss: 0.7975 - val_accuracy: 0.5818\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2868 - accuracy: 0.8912 - val_loss: 0.7870 - val_accuracy: 0.5818\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2804 - accuracy: 0.8988 - val_loss: 0.7803 - val_accuracy: 0.6364\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2733 - accuracy: 0.9063 - val_loss: 0.7971 - val_accuracy: 0.5818\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2741 - accuracy: 0.9033 - val_loss: 0.7938 - val_accuracy: 0.5818\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2694 - accuracy: 0.8927 - val_loss: 0.8141 - val_accuracy: 0.5818\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.2632 - accuracy: 0.9048 - val_loss: 0.7985 - val_accuracy: 0.6000\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2716 - accuracy: 0.8973 - val_loss: 0.8349 - val_accuracy: 0.5818\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2585 - accuracy: 0.9033 - val_loss: 0.8145 - val_accuracy: 0.5818\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2625 - accuracy: 0.9094 - val_loss: 0.8041 - val_accuracy: 0.5818\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2456 - accuracy: 0.9169 - val_loss: 0.8563 - val_accuracy: 0.5818\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2544 - accuracy: 0.9048 - val_loss: 0.8050 - val_accuracy: 0.5818\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2455 - accuracy: 0.9124 - val_loss: 0.8011 - val_accuracy: 0.6364\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2585 - accuracy: 0.9018 - val_loss: 0.8584 - val_accuracy: 0.5818\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2423 - accuracy: 0.9199 - val_loss: 0.8412 - val_accuracy: 0.5818\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2467 - accuracy: 0.9063 - val_loss: 0.8620 - val_accuracy: 0.5818\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2346 - accuracy: 0.9154 - val_loss: 0.8277 - val_accuracy: 0.6364\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2388 - accuracy: 0.9003 - val_loss: 0.8160 - val_accuracy: 0.6364\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2371 - accuracy: 0.9169 - val_loss: 0.8330 - val_accuracy: 0.6364\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2333 - accuracy: 0.9199 - val_loss: 0.8281 - val_accuracy: 0.6364\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2329 - accuracy: 0.9245 - val_loss: 0.8288 - val_accuracy: 0.6182\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2231 - accuracy: 0.9260 - val_loss: 0.8419 - val_accuracy: 0.6000\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2269 - accuracy: 0.9109 - val_loss: 0.8633 - val_accuracy: 0.6000\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2311 - accuracy: 0.9094 - val_loss: 0.8379 - val_accuracy: 0.6182\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2163 - accuracy: 0.9350 - val_loss: 0.8598 - val_accuracy: 0.5818\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2186 - accuracy: 0.9260 - val_loss: 0.8431 - val_accuracy: 0.6364\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2272 - accuracy: 0.9245 - val_loss: 0.8677 - val_accuracy: 0.6000\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2187 - accuracy: 0.9260 - val_loss: 0.8534 - val_accuracy: 0.6364\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2197 - accuracy: 0.9305 - val_loss: 0.8565 - val_accuracy: 0.6364\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2297 - accuracy: 0.9139 - val_loss: 0.8518 - val_accuracy: 0.6364\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2203 - accuracy: 0.9260 - val_loss: 0.8545 - val_accuracy: 0.6364\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2219 - accuracy: 0.9199 - val_loss: 0.8527 - val_accuracy: 0.6364\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2257 - accuracy: 0.9063 - val_loss: 0.8887 - val_accuracy: 0.5818\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.2049 - accuracy: 0.9426 - val_loss: 0.9028 - val_accuracy: 0.5818\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.1996 - accuracy: 0.9366 - val_loss: 0.9019 - val_accuracy: 0.5818\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2038 - accuracy: 0.9320 - val_loss: 0.8944 - val_accuracy: 0.6364\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1898 - accuracy: 0.9335 - val_loss: 0.8989 - val_accuracy: 0.5818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2028 - accuracy: 0.9350 - val_loss: 0.8654 - val_accuracy: 0.6364\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1960 - accuracy: 0.9471 - val_loss: 0.8842 - val_accuracy: 0.6364\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2081 - accuracy: 0.9199 - val_loss: 0.9222 - val_accuracy: 0.5818\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.2003 - accuracy: 0.9441 - val_loss: 0.9651 - val_accuracy: 0.5818\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1884 - accuracy: 0.9426 - val_loss: 0.9395 - val_accuracy: 0.5818\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1830 - accuracy: 0.9471 - val_loss: 0.9349 - val_accuracy: 0.5818\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1840 - accuracy: 0.9411 - val_loss: 0.9159 - val_accuracy: 0.6182\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1799 - accuracy: 0.9471 - val_loss: 0.9092 - val_accuracy: 0.6364\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1813 - accuracy: 0.9486 - val_loss: 0.9277 - val_accuracy: 0.6182\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1762 - accuracy: 0.9471 - val_loss: 0.9266 - val_accuracy: 0.6182\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1787 - accuracy: 0.9441 - val_loss: 0.9468 - val_accuracy: 0.6182\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1778 - accuracy: 0.9381 - val_loss: 0.9163 - val_accuracy: 0.6364\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1633 - accuracy: 0.9577 - val_loss: 0.9176 - val_accuracy: 0.6364\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1795 - accuracy: 0.9381 - val_loss: 0.9080 - val_accuracy: 0.6364\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1865 - accuracy: 0.9366 - val_loss: 0.9091 - val_accuracy: 0.6364\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1722 - accuracy: 0.9471 - val_loss: 0.9078 - val_accuracy: 0.6364\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1596 - accuracy: 0.9547 - val_loss: 0.9389 - val_accuracy: 0.6364\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1703 - accuracy: 0.9532 - val_loss: 0.9202 - val_accuracy: 0.6364\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1659 - accuracy: 0.9502 - val_loss: 0.9506 - val_accuracy: 0.6182\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1580 - accuracy: 0.9622 - val_loss: 0.9443 - val_accuracy: 0.6364\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1673 - accuracy: 0.9486 - val_loss: 0.9937 - val_accuracy: 0.6182\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1638 - accuracy: 0.9426 - val_loss: 0.9474 - val_accuracy: 0.6364\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1571 - accuracy: 0.9577 - val_loss: 0.9456 - val_accuracy: 0.6364\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1528 - accuracy: 0.9607 - val_loss: 0.9442 - val_accuracy: 0.6364\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1541 - accuracy: 0.9471 - val_loss: 0.9685 - val_accuracy: 0.6364\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1583 - accuracy: 0.9486 - val_loss: 1.0079 - val_accuracy: 0.6182\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1685 - accuracy: 0.9471 - val_loss: 1.0099 - val_accuracy: 0.6182\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1460 - accuracy: 0.9577 - val_loss: 0.9926 - val_accuracy: 0.6182\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1417 - accuracy: 0.9683 - val_loss: 0.9743 - val_accuracy: 0.6364\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1487 - accuracy: 0.9577 - val_loss: 0.9658 - val_accuracy: 0.6364\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1344 - accuracy: 0.9698 - val_loss: 0.9863 - val_accuracy: 0.6364\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1533 - accuracy: 0.9562 - val_loss: 0.9788 - val_accuracy: 0.6364\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1280 - accuracy: 0.9728 - val_loss: 0.9716 - val_accuracy: 0.6364\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1404 - accuracy: 0.9592 - val_loss: 0.9794 - val_accuracy: 0.6364\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1458 - accuracy: 0.9517 - val_loss: 0.9781 - val_accuracy: 0.6364\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1416 - accuracy: 0.9592 - val_loss: 0.9850 - val_accuracy: 0.6364\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1387 - accuracy: 0.9577 - val_loss: 0.9956 - val_accuracy: 0.6364\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1313 - accuracy: 0.9743 - val_loss: 1.0194 - val_accuracy: 0.6182\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1271 - accuracy: 0.9698 - val_loss: 1.0786 - val_accuracy: 0.6182\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1378 - accuracy: 0.9622 - val_loss: 1.0163 - val_accuracy: 0.6364\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1280 - accuracy: 0.9607 - val_loss: 1.0213 - val_accuracy: 0.6364\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1295 - accuracy: 0.9668 - val_loss: 1.0631 - val_accuracy: 0.6182\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1258 - accuracy: 0.9683 - val_loss: 1.0701 - val_accuracy: 0.6364\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1264 - accuracy: 0.9668 - val_loss: 1.0174 - val_accuracy: 0.6364\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1162 - accuracy: 0.9743 - val_loss: 1.0504 - val_accuracy: 0.6182\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1280 - accuracy: 0.9683 - val_loss: 1.0129 - val_accuracy: 0.6364\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1193 - accuracy: 0.9743 - val_loss: 1.0596 - val_accuracy: 0.6182\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1259 - accuracy: 0.9607 - val_loss: 1.0390 - val_accuracy: 0.6364\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1350 - accuracy: 0.9622 - val_loss: 1.0178 - val_accuracy: 0.6364\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1095 - accuracy: 0.9758 - val_loss: 1.0180 - val_accuracy: 0.6545\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1258 - accuracy: 0.9743 - val_loss: 1.0519 - val_accuracy: 0.6364\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1121 - accuracy: 0.9653 - val_loss: 1.0542 - val_accuracy: 0.6182\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1212 - accuracy: 0.9622 - val_loss: 1.0670 - val_accuracy: 0.6182\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1149 - accuracy: 0.9683 - val_loss: 1.0245 - val_accuracy: 0.6364\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1126 - accuracy: 0.9758 - val_loss: 1.0340 - val_accuracy: 0.6364\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1027 - accuracy: 0.9773 - val_loss: 1.0749 - val_accuracy: 0.6545\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1131 - accuracy: 0.9758 - val_loss: 1.0415 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1141 - accuracy: 0.9728 - val_loss: 1.0470 - val_accuracy: 0.6364\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1134 - accuracy: 0.9668 - val_loss: 1.0628 - val_accuracy: 0.6545\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1066 - accuracy: 0.9713 - val_loss: 1.0780 - val_accuracy: 0.6182\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1069 - accuracy: 0.9698 - val_loss: 1.0464 - val_accuracy: 0.6545\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1014 - accuracy: 0.9698 - val_loss: 1.0871 - val_accuracy: 0.6364\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1011 - accuracy: 0.9758 - val_loss: 1.1046 - val_accuracy: 0.6182\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0993 - accuracy: 0.9789 - val_loss: 1.0916 - val_accuracy: 0.6182\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0914 - accuracy: 0.9849 - val_loss: 1.1162 - val_accuracy: 0.6364\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0969 - accuracy: 0.9728 - val_loss: 1.1126 - val_accuracy: 0.6364\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0967 - accuracy: 0.9789 - val_loss: 1.0783 - val_accuracy: 0.6364\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1023 - accuracy: 0.9743 - val_loss: 1.1211 - val_accuracy: 0.6182\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0927 - accuracy: 0.9789 - val_loss: 1.0774 - val_accuracy: 0.6545\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1152 - accuracy: 0.9743 - val_loss: 1.0949 - val_accuracy: 0.6364\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0884 - accuracy: 0.9804 - val_loss: 1.1240 - val_accuracy: 0.6545\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0903 - accuracy: 0.9758 - val_loss: 1.1003 - val_accuracy: 0.6545\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0891 - accuracy: 0.9879 - val_loss: 1.1027 - val_accuracy: 0.6545\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0896 - accuracy: 0.9773 - val_loss: 1.1267 - val_accuracy: 0.6545\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0913 - accuracy: 0.9773 - val_loss: 1.0831 - val_accuracy: 0.6545\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0869 - accuracy: 0.9834 - val_loss: 1.1761 - val_accuracy: 0.6182\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0876 - accuracy: 0.9804 - val_loss: 1.1136 - val_accuracy: 0.6545\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0869 - accuracy: 0.9789 - val_loss: 1.1372 - val_accuracy: 0.6364\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0885 - accuracy: 0.9834 - val_loss: 1.1588 - val_accuracy: 0.6182\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0878 - accuracy: 0.9834 - val_loss: 1.1610 - val_accuracy: 0.6364\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0845 - accuracy: 0.9864 - val_loss: 1.1226 - val_accuracy: 0.6545\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0864 - accuracy: 0.9834 - val_loss: 1.1231 - val_accuracy: 0.6545\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0756 - accuracy: 0.9819 - val_loss: 1.1567 - val_accuracy: 0.6545\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0853 - accuracy: 0.9834 - val_loss: 1.1972 - val_accuracy: 0.6182\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0858 - accuracy: 0.9834 - val_loss: 1.1498 - val_accuracy: 0.6364\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0765 - accuracy: 0.9909 - val_loss: 1.1462 - val_accuracy: 0.6545\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0731 - accuracy: 0.9894 - val_loss: 1.1778 - val_accuracy: 0.6545\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0766 - accuracy: 0.9864 - val_loss: 1.1626 - val_accuracy: 0.6364\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0794 - accuracy: 0.9849 - val_loss: 1.1253 - val_accuracy: 0.6727\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0786 - accuracy: 0.9879 - val_loss: 1.2069 - val_accuracy: 0.6182\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0768 - accuracy: 0.9849 - val_loss: 1.2075 - val_accuracy: 0.6364\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0725 - accuracy: 0.9864 - val_loss: 1.1803 - val_accuracy: 0.6545\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0753 - accuracy: 0.9864 - val_loss: 1.1915 - val_accuracy: 0.6545\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0735 - accuracy: 0.9894 - val_loss: 1.1837 - val_accuracy: 0.6545\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0673 - accuracy: 0.9879 - val_loss: 1.1873 - val_accuracy: 0.6545\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0850 - accuracy: 0.9804 - val_loss: 1.1545 - val_accuracy: 0.6545\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0728 - accuracy: 0.9849 - val_loss: 1.1453 - val_accuracy: 0.6727\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0703 - accuracy: 0.9819 - val_loss: 1.2326 - val_accuracy: 0.6000\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0707 - accuracy: 0.9864 - val_loss: 1.1830 - val_accuracy: 0.6545\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0634 - accuracy: 0.9940 - val_loss: 1.1624 - val_accuracy: 0.6727\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0637 - accuracy: 0.9909 - val_loss: 1.1610 - val_accuracy: 0.6727\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0668 - accuracy: 0.9909 - val_loss: 1.1698 - val_accuracy: 0.6727\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0756 - accuracy: 0.9834 - val_loss: 1.1695 - val_accuracy: 0.6545\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0671 - accuracy: 0.9864 - val_loss: 1.1800 - val_accuracy: 0.6727\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0560 - accuracy: 0.9940 - val_loss: 1.2282 - val_accuracy: 0.6545\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0611 - accuracy: 0.9879 - val_loss: 1.2674 - val_accuracy: 0.6364\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0689 - accuracy: 0.9864 - val_loss: 1.2286 - val_accuracy: 0.6545\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0668 - accuracy: 0.9834 - val_loss: 1.2202 - val_accuracy: 0.6545\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0678 - accuracy: 0.9864 - val_loss: 1.2187 - val_accuracy: 0.6727\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0737 - accuracy: 0.9773 - val_loss: 1.2126 - val_accuracy: 0.6727\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0631 - accuracy: 0.9864 - val_loss: 1.2290 - val_accuracy: 0.6727\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0551 - accuracy: 0.9924 - val_loss: 1.2546 - val_accuracy: 0.6364\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0659 - accuracy: 0.9879 - val_loss: 1.1976 - val_accuracy: 0.6727\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0583 - accuracy: 0.9924 - val_loss: 1.2202 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0624 - accuracy: 0.9894 - val_loss: 1.2320 - val_accuracy: 0.6364\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0602 - accuracy: 0.9924 - val_loss: 1.2412 - val_accuracy: 0.6364\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0592 - accuracy: 0.9864 - val_loss: 1.2263 - val_accuracy: 0.6909\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0631 - accuracy: 0.9879 - val_loss: 1.2359 - val_accuracy: 0.6545\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0501 - accuracy: 0.9940 - val_loss: 1.2307 - val_accuracy: 0.6727\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0581 - accuracy: 0.9894 - val_loss: 1.2340 - val_accuracy: 0.6727\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0504 - accuracy: 0.9924 - val_loss: 1.2585 - val_accuracy: 0.6727\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0585 - accuracy: 0.9834 - val_loss: 1.2366 - val_accuracy: 0.6545\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0546 - accuracy: 0.9909 - val_loss: 1.2372 - val_accuracy: 0.6545\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0554 - accuracy: 0.9849 - val_loss: 1.2486 - val_accuracy: 0.6727\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0531 - accuracy: 0.9909 - val_loss: 1.2894 - val_accuracy: 0.6364\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0530 - accuracy: 0.9879 - val_loss: 1.2741 - val_accuracy: 0.6727\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0539 - accuracy: 0.9894 - val_loss: 1.2787 - val_accuracy: 0.6727\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0551 - accuracy: 0.9879 - val_loss: 1.2468 - val_accuracy: 0.6727\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0522 - accuracy: 0.9894 - val_loss: 1.2689 - val_accuracy: 0.6545\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0540 - accuracy: 0.9909 - val_loss: 1.2586 - val_accuracy: 0.6545\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0479 - accuracy: 0.9924 - val_loss: 1.2847 - val_accuracy: 0.6727\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0526 - accuracy: 0.9894 - val_loss: 1.3242 - val_accuracy: 0.6909\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0578 - accuracy: 0.9924 - val_loss: 1.2494 - val_accuracy: 0.6545\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0615 - accuracy: 0.9849 - val_loss: 1.2549 - val_accuracy: 0.6545\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0499 - accuracy: 0.9940 - val_loss: 1.2728 - val_accuracy: 0.6727\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0556 - accuracy: 0.9894 - val_loss: 1.2730 - val_accuracy: 0.6727\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0522 - accuracy: 0.9894 - val_loss: 1.2989 - val_accuracy: 0.6727\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0471 - accuracy: 0.9924 - val_loss: 1.2601 - val_accuracy: 0.6727\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0426 - accuracy: 0.9924 - val_loss: 1.3151 - val_accuracy: 0.6727\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0461 - accuracy: 0.9909 - val_loss: 1.3223 - val_accuracy: 0.6727\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0470 - accuracy: 0.9970 - val_loss: 1.3191 - val_accuracy: 0.6909\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0506 - accuracy: 0.9879 - val_loss: 1.3183 - val_accuracy: 0.6545\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0467 - accuracy: 0.9940 - val_loss: 1.2939 - val_accuracy: 0.6909\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0485 - accuracy: 0.9909 - val_loss: 1.3376 - val_accuracy: 0.6727\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0444 - accuracy: 0.9970 - val_loss: 1.3430 - val_accuracy: 0.6727\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0433 - accuracy: 0.9924 - val_loss: 1.4044 - val_accuracy: 0.6182\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0429 - accuracy: 0.9909 - val_loss: 1.3468 - val_accuracy: 0.6909\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0455 - accuracy: 0.9924 - val_loss: 1.3895 - val_accuracy: 0.6364\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0413 - accuracy: 0.9940 - val_loss: 1.3504 - val_accuracy: 0.6727\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0391 - accuracy: 0.9909 - val_loss: 1.3791 - val_accuracy: 0.6727\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0417 - accuracy: 0.9909 - val_loss: 1.4499 - val_accuracy: 0.6364\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0509 - accuracy: 0.9909 - val_loss: 1.3842 - val_accuracy: 0.6545\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0539 - accuracy: 0.9819 - val_loss: 1.3373 - val_accuracy: 0.6727\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0435 - accuracy: 0.9894 - val_loss: 1.3717 - val_accuracy: 0.6727\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0445 - accuracy: 0.9894 - val_loss: 1.3920 - val_accuracy: 0.6727\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0411 - accuracy: 0.9970 - val_loss: 1.3826 - val_accuracy: 0.6909\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0508 - accuracy: 0.9894 - val_loss: 1.3445 - val_accuracy: 0.6727\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0368 - accuracy: 0.9909 - val_loss: 1.3696 - val_accuracy: 0.6727\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0448 - accuracy: 0.9894 - val_loss: 1.3593 - val_accuracy: 0.6727\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0375 - accuracy: 0.9924 - val_loss: 1.3637 - val_accuracy: 0.6727\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0441 - accuracy: 0.9909 - val_loss: 1.4140 - val_accuracy: 0.6727\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0344 - accuracy: 0.9955 - val_loss: 1.3653 - val_accuracy: 0.6727\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0337 - accuracy: 0.9924 - val_loss: 1.3867 - val_accuracy: 0.6727\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0340 - accuracy: 0.9940 - val_loss: 1.3970 - val_accuracy: 0.6545\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0470 - accuracy: 0.9849 - val_loss: 1.4150 - val_accuracy: 0.6545\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0344 - accuracy: 0.9970 - val_loss: 1.3555 - val_accuracy: 0.6909\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0364 - accuracy: 0.9940 - val_loss: 1.3624 - val_accuracy: 0.6545\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0311 - accuracy: 0.9970 - val_loss: 1.4408 - val_accuracy: 0.6727\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0339 - accuracy: 0.9940 - val_loss: 1.4502 - val_accuracy: 0.6364\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0401 - accuracy: 0.9924 - val_loss: 1.4492 - val_accuracy: 0.6727\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0308 - accuracy: 0.9985 - val_loss: 1.4433 - val_accuracy: 0.6727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0269 - accuracy: 0.9955 - val_loss: 1.4634 - val_accuracy: 0.6727\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0288 - accuracy: 0.9985 - val_loss: 1.4368 - val_accuracy: 0.6545\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0367 - accuracy: 0.9909 - val_loss: 1.4151 - val_accuracy: 0.6909\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0375 - accuracy: 0.9955 - val_loss: 1.4036 - val_accuracy: 0.6727\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0306 - accuracy: 0.9924 - val_loss: 1.4870 - val_accuracy: 0.6727\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0275 - accuracy: 0.9985 - val_loss: 1.4602 - val_accuracy: 0.6909\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0322 - accuracy: 0.9940 - val_loss: 1.4669 - val_accuracy: 0.6545\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0319 - accuracy: 0.9940 - val_loss: 1.4557 - val_accuracy: 0.6727\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0288 - accuracy: 0.9955 - val_loss: 1.4460 - val_accuracy: 0.6727\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0352 - accuracy: 0.9924 - val_loss: 1.4218 - val_accuracy: 0.6727\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0328 - accuracy: 0.9940 - val_loss: 1.4680 - val_accuracy: 0.6727\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0353 - accuracy: 0.9909 - val_loss: 1.4350 - val_accuracy: 0.6545\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0344 - accuracy: 0.9940 - val_loss: 1.4943 - val_accuracy: 0.6545\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0296 - accuracy: 0.9955 - val_loss: 1.5030 - val_accuracy: 0.6727\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0251 - accuracy: 0.9985 - val_loss: 1.4804 - val_accuracy: 0.6909\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 1.4705 - val_accuracy: 0.6545\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0325 - accuracy: 0.9924 - val_loss: 1.4209 - val_accuracy: 0.6909\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0321 - accuracy: 0.9955 - val_loss: 1.4583 - val_accuracy: 0.6909\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0351 - accuracy: 0.9909 - val_loss: 1.4916 - val_accuracy: 0.6909\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0285 - accuracy: 0.9970 - val_loss: 1.5055 - val_accuracy: 0.6909\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0312 - accuracy: 0.9924 - val_loss: 1.4831 - val_accuracy: 0.6909\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0234 - accuracy: 0.9970 - val_loss: 1.5041 - val_accuracy: 0.6909\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0262 - accuracy: 0.9940 - val_loss: 1.4756 - val_accuracy: 0.6727\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0322 - accuracy: 0.9924 - val_loss: 1.5052 - val_accuracy: 0.6727\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0313 - accuracy: 0.9909 - val_loss: 1.5153 - val_accuracy: 0.6364\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0318 - accuracy: 0.9924 - val_loss: 1.5534 - val_accuracy: 0.6727\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0300 - accuracy: 0.9955 - val_loss: 1.5001 - val_accuracy: 0.6545\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0271 - accuracy: 0.9955 - val_loss: 1.4912 - val_accuracy: 0.6727\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0245 - accuracy: 0.9970 - val_loss: 1.5071 - val_accuracy: 0.6545\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0275 - accuracy: 0.9970 - val_loss: 1.5448 - val_accuracy: 0.6727\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0279 - accuracy: 0.9955 - val_loss: 1.5033 - val_accuracy: 0.6909\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0242 - accuracy: 0.9970 - val_loss: 1.5080 - val_accuracy: 0.6909\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0264 - accuracy: 0.9955 - val_loss: 1.5363 - val_accuracy: 0.6727\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0236 - accuracy: 0.9970 - val_loss: 1.5317 - val_accuracy: 0.6909\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0279 - accuracy: 0.9985 - val_loss: 1.5339 - val_accuracy: 0.6909\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0232 - accuracy: 0.9970 - val_loss: 1.5204 - val_accuracy: 0.6545\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0214 - accuracy: 0.9970 - val_loss: 1.5237 - val_accuracy: 0.6727\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0257 - accuracy: 0.9955 - val_loss: 1.5394 - val_accuracy: 0.6909\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0220 - accuracy: 0.9970 - val_loss: 1.5767 - val_accuracy: 0.6545\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.0265 - accuracy: 0.9955 - val_loss: 1.5508 - val_accuracy: 0.6909\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0342 - accuracy: 0.9909 - val_loss: 1.5532 - val_accuracy: 0.6182\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0217 - accuracy: 0.9970 - val_loss: 1.5777 - val_accuracy: 0.6727\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0234 - accuracy: 0.9970 - val_loss: 1.5790 - val_accuracy: 0.6727\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0234 - accuracy: 0.9955 - val_loss: 1.6113 - val_accuracy: 0.6727\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0225 - accuracy: 0.9955 - val_loss: 1.5996 - val_accuracy: 0.6364\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0260 - accuracy: 0.9940 - val_loss: 1.5939 - val_accuracy: 0.6364\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0225 - accuracy: 0.9970 - val_loss: 1.5466 - val_accuracy: 0.6727\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0205 - accuracy: 0.9970 - val_loss: 1.6208 - val_accuracy: 0.6364\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0267 - accuracy: 0.9940 - val_loss: 1.5996 - val_accuracy: 0.6909\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0223 - accuracy: 0.9955 - val_loss: 1.5853 - val_accuracy: 0.6545\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0186 - accuracy: 0.9970 - val_loss: 1.5942 - val_accuracy: 0.6909\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.0210 - accuracy: 0.9970 - val_loss: 1.5601 - val_accuracy: 0.6909\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.0248 - accuracy: 0.9955 - val_loss: 1.5979 - val_accuracy: 0.6545\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 1.5978 - val_accuracy: 0.6727\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0241 - accuracy: 0.9955 - val_loss: 1.5570 - val_accuracy: 0.6909\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0186 - accuracy: 0.9970 - val_loss: 1.5814 - val_accuracy: 0.6909\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0195 - accuracy: 0.9985 - val_loss: 1.5344 - val_accuracy: 0.6727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0200 - accuracy: 0.9985 - val_loss: 1.5725 - val_accuracy: 0.6909\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0177 - accuracy: 0.9970 - val_loss: 1.5989 - val_accuracy: 0.6909\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0215 - accuracy: 0.9955 - val_loss: 1.6048 - val_accuracy: 0.6545\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0202 - accuracy: 0.9970 - val_loss: 1.6355 - val_accuracy: 0.6909\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0187 - accuracy: 0.9955 - val_loss: 1.6218 - val_accuracy: 0.6909\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0125 - accuracy: 0.9985 - val_loss: 1.6360 - val_accuracy: 0.6364\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0174 - accuracy: 0.9970 - val_loss: 1.6760 - val_accuracy: 0.6182\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0248 - accuracy: 0.9940 - val_loss: 1.6402 - val_accuracy: 0.6545\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0189 - accuracy: 0.9970 - val_loss: 1.6107 - val_accuracy: 0.6727\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0219 - accuracy: 0.9955 - val_loss: 1.6297 - val_accuracy: 0.6909\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0213 - accuracy: 0.9970 - val_loss: 1.5905 - val_accuracy: 0.6727\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.6142 - val_accuracy: 0.6545\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0180 - accuracy: 0.9955 - val_loss: 1.5768 - val_accuracy: 0.6909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd670f58880>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_221.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_221.fit(X_train_over, y_train_over, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cfc3dd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6201 - accuracy: 0.7885\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6309 - accuracy: 0.7455\n"
     ]
    }
   ],
   "source": [
    "m2_eval_test = model_221.evaluate(X_test, y_test)\n",
    "m2_eval_val = model_221.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750210b",
   "metadata": {},
   "source": [
    "**For test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b2225d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "roc auc score:  0.7349624060150377\n",
      "average precision score:  0.6940112346833278\n"
     ]
    }
   ],
   "source": [
    "pred = model_221.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ed9a29e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dbcf71b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6201 - accuracy: 0.7885\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m2_eval_test = model_221.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2dd29",
   "metadata": {},
   "source": [
    "**For validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7a5e4845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step\n",
      "roc auc score:  0.6795665634674923\n",
      "average precision score:  0.6739399927313978\n"
     ]
    }
   ],
   "source": [
    "pred = model_221.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5bd51a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "17a53dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6309 - accuracy: 0.7455\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m2_eval_test = model_221.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be255a62",
   "metadata": {},
   "source": [
    "#### 2.2.2 Alvin's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "646bbf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_7 (Conv1D)           (None, 766, 64)           256       \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 764, 32)           6176      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 24448)             0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 112)               2738288   \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 226       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,744,946\n",
      "Trainable params: 2,744,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model1\n",
    "model_222 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_222.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_222.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_222.add(Flatten())\n",
    "model_222.add(Dense(112, activation='relu'))\n",
    "model_222.add(Dense(2, activation='softmax'))\n",
    "model_222.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3c9f419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=400,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3170dd0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.6943 - accuracy: 0.5378 - val_loss: 0.7073 - val_accuracy: 0.3091\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.6900 - accuracy: 0.5423 - val_loss: 0.6647 - val_accuracy: 0.6909\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.6849 - accuracy: 0.5604 - val_loss: 0.6599 - val_accuracy: 0.7455\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.6800 - accuracy: 0.5695 - val_loss: 0.6760 - val_accuracy: 0.6182\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.6745 - accuracy: 0.5846 - val_loss: 0.6176 - val_accuracy: 0.7091\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.6643 - accuracy: 0.6178 - val_loss: 0.6432 - val_accuracy: 0.6364\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.6595 - accuracy: 0.6254 - val_loss: 0.6539 - val_accuracy: 0.6000\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.6466 - accuracy: 0.6344 - val_loss: 0.6541 - val_accuracy: 0.5818\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.6407 - accuracy: 0.6465 - val_loss: 0.6749 - val_accuracy: 0.5455\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.6314 - accuracy: 0.6647 - val_loss: 0.6375 - val_accuracy: 0.6364\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.6255 - accuracy: 0.6767 - val_loss: 0.6683 - val_accuracy: 0.5455\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.6162 - accuracy: 0.6662 - val_loss: 0.6053 - val_accuracy: 0.6727\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.6125 - accuracy: 0.6843 - val_loss: 0.6554 - val_accuracy: 0.5818\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.6053 - accuracy: 0.6828 - val_loss: 0.6411 - val_accuracy: 0.6000\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.5965 - accuracy: 0.6918 - val_loss: 0.6781 - val_accuracy: 0.5636\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.5948 - accuracy: 0.6964 - val_loss: 0.7208 - val_accuracy: 0.5273\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.5921 - accuracy: 0.6934 - val_loss: 0.6700 - val_accuracy: 0.6000\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.5838 - accuracy: 0.7130 - val_loss: 0.6210 - val_accuracy: 0.6727\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.5755 - accuracy: 0.7236 - val_loss: 0.6276 - val_accuracy: 0.6364\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.5618 - accuracy: 0.7326 - val_loss: 0.6287 - val_accuracy: 0.6364\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.5580 - accuracy: 0.7402 - val_loss: 0.6369 - val_accuracy: 0.6727\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.5474 - accuracy: 0.7447 - val_loss: 0.6447 - val_accuracy: 0.6182\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.5385 - accuracy: 0.7492 - val_loss: 0.6043 - val_accuracy: 0.6364\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.5505 - accuracy: 0.7356 - val_loss: 0.6010 - val_accuracy: 0.6545\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.5305 - accuracy: 0.7492 - val_loss: 0.6212 - val_accuracy: 0.6182\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.5213 - accuracy: 0.7644 - val_loss: 0.6286 - val_accuracy: 0.6182\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.5106 - accuracy: 0.7659 - val_loss: 0.6222 - val_accuracy: 0.6364\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.5068 - accuracy: 0.7810 - val_loss: 0.6305 - val_accuracy: 0.6364\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.4981 - accuracy: 0.7870 - val_loss: 0.6848 - val_accuracy: 0.6182\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.4949 - accuracy: 0.7719 - val_loss: 0.6609 - val_accuracy: 0.6182\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.4922 - accuracy: 0.7779 - val_loss: 0.6431 - val_accuracy: 0.6364\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.4816 - accuracy: 0.7931 - val_loss: 0.6859 - val_accuracy: 0.6364\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.4805 - accuracy: 0.7870 - val_loss: 0.6469 - val_accuracy: 0.6364\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.4774 - accuracy: 0.7991 - val_loss: 0.6471 - val_accuracy: 0.6364\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.4721 - accuracy: 0.7885 - val_loss: 0.6533 - val_accuracy: 0.6364\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.4705 - accuracy: 0.8021 - val_loss: 0.7036 - val_accuracy: 0.6000\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.4514 - accuracy: 0.8082 - val_loss: 0.6881 - val_accuracy: 0.6000\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.4437 - accuracy: 0.8172 - val_loss: 0.7360 - val_accuracy: 0.6182\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.4524 - accuracy: 0.7931 - val_loss: 0.7088 - val_accuracy: 0.6000\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.4427 - accuracy: 0.8127 - val_loss: 0.7253 - val_accuracy: 0.6000\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.4302 - accuracy: 0.8218 - val_loss: 0.6900 - val_accuracy: 0.6182\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.4262 - accuracy: 0.8263 - val_loss: 0.7104 - val_accuracy: 0.6182\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.4223 - accuracy: 0.8263 - val_loss: 0.7081 - val_accuracy: 0.6182\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.4212 - accuracy: 0.8187 - val_loss: 0.7093 - val_accuracy: 0.6364\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.4062 - accuracy: 0.8248 - val_loss: 0.7334 - val_accuracy: 0.6182\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.4030 - accuracy: 0.8399 - val_loss: 0.7211 - val_accuracy: 0.6364\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.3972 - accuracy: 0.8384 - val_loss: 0.7407 - val_accuracy: 0.6182\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3927 - accuracy: 0.8308 - val_loss: 0.7446 - val_accuracy: 0.6182\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.3827 - accuracy: 0.8399 - val_loss: 0.7464 - val_accuracy: 0.6364\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.3833 - accuracy: 0.8550 - val_loss: 0.7846 - val_accuracy: 0.6182\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3803 - accuracy: 0.8399 - val_loss: 0.7876 - val_accuracy: 0.6182\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.3698 - accuracy: 0.8595 - val_loss: 0.7731 - val_accuracy: 0.6182\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3638 - accuracy: 0.8550 - val_loss: 0.7773 - val_accuracy: 0.6364\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3613 - accuracy: 0.8489 - val_loss: 0.7999 - val_accuracy: 0.6182\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3712 - accuracy: 0.8353 - val_loss: 0.8009 - val_accuracy: 0.6000\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.3646 - accuracy: 0.8459 - val_loss: 0.8081 - val_accuracy: 0.6364\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3610 - accuracy: 0.8474 - val_loss: 0.8207 - val_accuracy: 0.6182\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3414 - accuracy: 0.8580 - val_loss: 0.8103 - val_accuracy: 0.6000\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.3319 - accuracy: 0.8807 - val_loss: 0.8165 - val_accuracy: 0.6364\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3322 - accuracy: 0.8701 - val_loss: 0.8298 - val_accuracy: 0.6364\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3320 - accuracy: 0.8731 - val_loss: 0.8605 - val_accuracy: 0.5818\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3322 - accuracy: 0.8640 - val_loss: 0.8443 - val_accuracy: 0.6000\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3227 - accuracy: 0.8625 - val_loss: 0.8473 - val_accuracy: 0.6364\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3090 - accuracy: 0.8882 - val_loss: 0.8630 - val_accuracy: 0.6364\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3090 - accuracy: 0.8852 - val_loss: 0.8741 - val_accuracy: 0.6364\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3067 - accuracy: 0.8746 - val_loss: 0.8884 - val_accuracy: 0.5818\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2966 - accuracy: 0.8852 - val_loss: 0.9050 - val_accuracy: 0.6364\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2932 - accuracy: 0.8988 - val_loss: 0.9258 - val_accuracy: 0.5455\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.3065 - accuracy: 0.8761 - val_loss: 0.9032 - val_accuracy: 0.6364\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2829 - accuracy: 0.8897 - val_loss: 0.9042 - val_accuracy: 0.6000\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.2727 - accuracy: 0.9003 - val_loss: 0.9240 - val_accuracy: 0.6364\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2660 - accuracy: 0.9003 - val_loss: 0.9486 - val_accuracy: 0.5818\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2700 - accuracy: 0.8973 - val_loss: 0.9399 - val_accuracy: 0.6364\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2675 - accuracy: 0.8867 - val_loss: 0.9605 - val_accuracy: 0.6364\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2826 - accuracy: 0.8958 - val_loss: 0.9602 - val_accuracy: 0.6364\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2539 - accuracy: 0.9094 - val_loss: 0.9701 - val_accuracy: 0.6000\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2453 - accuracy: 0.9199 - val_loss: 0.9804 - val_accuracy: 0.6364\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2427 - accuracy: 0.9184 - val_loss: 1.0033 - val_accuracy: 0.6000\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2546 - accuracy: 0.8958 - val_loss: 1.0019 - val_accuracy: 0.6364\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.2322 - accuracy: 0.9154 - val_loss: 1.0089 - val_accuracy: 0.6000\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2288 - accuracy: 0.9169 - val_loss: 1.0183 - val_accuracy: 0.6182\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2190 - accuracy: 0.9169 - val_loss: 1.0433 - val_accuracy: 0.6000\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.2129 - accuracy: 0.9275 - val_loss: 1.0621 - val_accuracy: 0.6000\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2121 - accuracy: 0.9215 - val_loss: 1.0534 - val_accuracy: 0.6182\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2068 - accuracy: 0.9275 - val_loss: 1.0571 - val_accuracy: 0.6000\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.2013 - accuracy: 0.9245 - val_loss: 1.0984 - val_accuracy: 0.5818\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1951 - accuracy: 0.9366 - val_loss: 1.1040 - val_accuracy: 0.6000\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1936 - accuracy: 0.9320 - val_loss: 1.1072 - val_accuracy: 0.6000\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1867 - accuracy: 0.9366 - val_loss: 1.1129 - val_accuracy: 0.6182\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1783 - accuracy: 0.9396 - val_loss: 1.1299 - val_accuracy: 0.6000\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1808 - accuracy: 0.9426 - val_loss: 1.1600 - val_accuracy: 0.6000\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1900 - accuracy: 0.9320 - val_loss: 1.1492 - val_accuracy: 0.6182\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1698 - accuracy: 0.9411 - val_loss: 1.1835 - val_accuracy: 0.6000\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1619 - accuracy: 0.9471 - val_loss: 1.1918 - val_accuracy: 0.6000\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1645 - accuracy: 0.9502 - val_loss: 1.2077 - val_accuracy: 0.6182\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1537 - accuracy: 0.9562 - val_loss: 1.2069 - val_accuracy: 0.6182\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1558 - accuracy: 0.9547 - val_loss: 1.2466 - val_accuracy: 0.6000\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1515 - accuracy: 0.9592 - val_loss: 1.2318 - val_accuracy: 0.5818\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1416 - accuracy: 0.9607 - val_loss: 1.2863 - val_accuracy: 0.6000\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1601 - accuracy: 0.9471 - val_loss: 1.2839 - val_accuracy: 0.6364\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1566 - accuracy: 0.9471 - val_loss: 1.2948 - val_accuracy: 0.6000\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1341 - accuracy: 0.9577 - val_loss: 1.2876 - val_accuracy: 0.5818\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1237 - accuracy: 0.9728 - val_loss: 1.3365 - val_accuracy: 0.6000\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1306 - accuracy: 0.9668 - val_loss: 1.3136 - val_accuracy: 0.6000\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1358 - accuracy: 0.9622 - val_loss: 1.4210 - val_accuracy: 0.6000\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1411 - accuracy: 0.9547 - val_loss: 1.3940 - val_accuracy: 0.6364\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1633 - accuracy: 0.9396 - val_loss: 1.3836 - val_accuracy: 0.6182\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1193 - accuracy: 0.9637 - val_loss: 1.3651 - val_accuracy: 0.6182\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1118 - accuracy: 0.9668 - val_loss: 1.3982 - val_accuracy: 0.6000\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1094 - accuracy: 0.9804 - val_loss: 1.4040 - val_accuracy: 0.6000\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1079 - accuracy: 0.9804 - val_loss: 1.4049 - val_accuracy: 0.6000\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1008 - accuracy: 0.9758 - val_loss: 1.4303 - val_accuracy: 0.6000\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0974 - accuracy: 0.9819 - val_loss: 1.4566 - val_accuracy: 0.5818\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.1092 - accuracy: 0.9743 - val_loss: 1.4468 - val_accuracy: 0.6000\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1124 - accuracy: 0.9668 - val_loss: 1.4851 - val_accuracy: 0.6182\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0912 - accuracy: 0.9864 - val_loss: 1.4989 - val_accuracy: 0.6000\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0888 - accuracy: 0.9819 - val_loss: 1.4944 - val_accuracy: 0.5818\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0844 - accuracy: 0.9940 - val_loss: 1.5241 - val_accuracy: 0.6000\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0814 - accuracy: 0.9849 - val_loss: 1.5458 - val_accuracy: 0.6182\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0850 - accuracy: 0.9849 - val_loss: 1.5828 - val_accuracy: 0.6000\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0804 - accuracy: 0.9894 - val_loss: 1.5667 - val_accuracy: 0.5818\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0809 - accuracy: 0.9804 - val_loss: 1.5925 - val_accuracy: 0.6000\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.1015 - accuracy: 0.9728 - val_loss: 1.6085 - val_accuracy: 0.6000\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0747 - accuracy: 0.9909 - val_loss: 1.6102 - val_accuracy: 0.5818\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0677 - accuracy: 0.9909 - val_loss: 1.6264 - val_accuracy: 0.5818\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0661 - accuracy: 0.9940 - val_loss: 1.6533 - val_accuracy: 0.5818\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0686 - accuracy: 0.9909 - val_loss: 1.6520 - val_accuracy: 0.6000\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0663 - accuracy: 0.9955 - val_loss: 1.6711 - val_accuracy: 0.5818\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0617 - accuracy: 0.9924 - val_loss: 1.6728 - val_accuracy: 0.5818\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0580 - accuracy: 0.9940 - val_loss: 1.7111 - val_accuracy: 0.6000\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0599 - accuracy: 0.9924 - val_loss: 1.7154 - val_accuracy: 0.6182\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0577 - accuracy: 0.9924 - val_loss: 1.7551 - val_accuracy: 0.6000\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0548 - accuracy: 0.9940 - val_loss: 1.7672 - val_accuracy: 0.6000\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0578 - accuracy: 0.9924 - val_loss: 1.7570 - val_accuracy: 0.6182\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0572 - accuracy: 0.9924 - val_loss: 1.7717 - val_accuracy: 0.6000\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0486 - accuracy: 0.9955 - val_loss: 1.7914 - val_accuracy: 0.6000\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0476 - accuracy: 0.9955 - val_loss: 1.8002 - val_accuracy: 0.6000\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0469 - accuracy: 0.9970 - val_loss: 1.8279 - val_accuracy: 0.6000\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0516 - accuracy: 0.9955 - val_loss: 1.8539 - val_accuracy: 0.6182\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0533 - accuracy: 0.9940 - val_loss: 1.8529 - val_accuracy: 0.6000\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0444 - accuracy: 0.9970 - val_loss: 1.8656 - val_accuracy: 0.5818\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0423 - accuracy: 0.9985 - val_loss: 1.8596 - val_accuracy: 0.5818\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0406 - accuracy: 0.9955 - val_loss: 1.8753 - val_accuracy: 0.5818\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0420 - accuracy: 0.9940 - val_loss: 1.9326 - val_accuracy: 0.6000\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0409 - accuracy: 0.9955 - val_loss: 1.9315 - val_accuracy: 0.6000\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0372 - accuracy: 0.9970 - val_loss: 1.9244 - val_accuracy: 0.6000\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0401 - accuracy: 0.9955 - val_loss: 1.9521 - val_accuracy: 0.6000\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0381 - accuracy: 0.9955 - val_loss: 1.9794 - val_accuracy: 0.6182\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0371 - accuracy: 0.9970 - val_loss: 1.9790 - val_accuracy: 0.6000\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0350 - accuracy: 0.9970 - val_loss: 1.9905 - val_accuracy: 0.5818\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0367 - accuracy: 0.9955 - val_loss: 2.0289 - val_accuracy: 0.6000\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0500 - accuracy: 0.9879 - val_loss: 2.0148 - val_accuracy: 0.5818\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0382 - accuracy: 0.9970 - val_loss: 2.0567 - val_accuracy: 0.5818\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0309 - accuracy: 0.9985 - val_loss: 2.0430 - val_accuracy: 0.6000\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0316 - accuracy: 0.9970 - val_loss: 2.0430 - val_accuracy: 0.6000\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0298 - accuracy: 0.9985 - val_loss: 2.0811 - val_accuracy: 0.6182\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0369 - accuracy: 0.9955 - val_loss: 2.0392 - val_accuracy: 0.6000\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0260 - accuracy: 0.9985 - val_loss: 2.0874 - val_accuracy: 0.5818\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0292 - accuracy: 0.9985 - val_loss: 2.0998 - val_accuracy: 0.6000\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0241 - accuracy: 0.9985 - val_loss: 2.0985 - val_accuracy: 0.5818\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0233 - accuracy: 0.9970 - val_loss: 2.0958 - val_accuracy: 0.5818\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0229 - accuracy: 0.9985 - val_loss: 2.1252 - val_accuracy: 0.6000\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0280 - accuracy: 0.9970 - val_loss: 2.1608 - val_accuracy: 0.6000\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0248 - accuracy: 0.9985 - val_loss: 2.1652 - val_accuracy: 0.6000\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0225 - accuracy: 0.9985 - val_loss: 2.1984 - val_accuracy: 0.6000\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0239 - accuracy: 0.9955 - val_loss: 2.1333 - val_accuracy: 0.6000\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0312 - accuracy: 0.9940 - val_loss: 2.2103 - val_accuracy: 0.6182\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0266 - accuracy: 0.9955 - val_loss: 2.2228 - val_accuracy: 0.6364\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0310 - accuracy: 0.9940 - val_loss: 2.2040 - val_accuracy: 0.5818\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0254 - accuracy: 0.9955 - val_loss: 2.2960 - val_accuracy: 0.6182\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0355 - accuracy: 0.9940 - val_loss: 2.2299 - val_accuracy: 0.5818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.0193 - accuracy: 0.9985 - val_loss: 2.2371 - val_accuracy: 0.6000\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0178 - accuracy: 0.9985 - val_loss: 2.2607 - val_accuracy: 0.6000\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0170 - accuracy: 0.9985 - val_loss: 2.2787 - val_accuracy: 0.6000\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0174 - accuracy: 0.9985 - val_loss: 2.2815 - val_accuracy: 0.6000\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0172 - accuracy: 0.9985 - val_loss: 2.2668 - val_accuracy: 0.6000\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0165 - accuracy: 0.9985 - val_loss: 2.2939 - val_accuracy: 0.6000\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0237 - accuracy: 0.9955 - val_loss: 2.3243 - val_accuracy: 0.5818\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0150 - accuracy: 0.9985 - val_loss: 2.3162 - val_accuracy: 0.6000\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0146 - accuracy: 0.9985 - val_loss: 2.3403 - val_accuracy: 0.6000\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0152 - accuracy: 0.9985 - val_loss: 2.3369 - val_accuracy: 0.6000\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0166 - accuracy: 0.9985 - val_loss: 2.3323 - val_accuracy: 0.6000\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0165 - accuracy: 0.9970 - val_loss: 2.3647 - val_accuracy: 0.5818\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0139 - accuracy: 0.9985 - val_loss: 2.3756 - val_accuracy: 0.6000\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.4001 - val_accuracy: 0.6182\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.4457 - val_accuracy: 0.6000\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 2.4588 - val_accuracy: 0.5818\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 2.4128 - val_accuracy: 0.6000\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0112 - accuracy: 0.9985 - val_loss: 2.4372 - val_accuracy: 0.5818\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.4425 - val_accuracy: 0.6000\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.4488 - val_accuracy: 0.5818\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.4690 - val_accuracy: 0.5818\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 2.4490 - val_accuracy: 0.5818\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.5088 - val_accuracy: 0.5818\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.4996 - val_accuracy: 0.6000\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.5261 - val_accuracy: 0.5818\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.5256 - val_accuracy: 0.6000\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.5613 - val_accuracy: 0.5818\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0106 - accuracy: 0.9985 - val_loss: 2.5227 - val_accuracy: 0.5818\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.5556 - val_accuracy: 0.6000\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.5438 - val_accuracy: 0.5818\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.5732 - val_accuracy: 0.5818\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.5935 - val_accuracy: 0.5818\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.5900 - val_accuracy: 0.5818\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.5920 - val_accuracy: 0.6000\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.6017 - val_accuracy: 0.6000\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.6229 - val_accuracy: 0.5818\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.6341 - val_accuracy: 0.6000\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.6271 - val_accuracy: 0.5818\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.6324 - val_accuracy: 0.5818\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.6481 - val_accuracy: 0.6000\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.6597 - val_accuracy: 0.6000\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.6857 - val_accuracy: 0.6000\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.6996 - val_accuracy: 0.5818\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7092 - val_accuracy: 0.5818\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7220 - val_accuracy: 0.5818\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 1s 35ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.7178 - val_accuracy: 0.5818\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 1s 36ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.7319 - val_accuracy: 0.5818\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.7558 - val_accuracy: 0.5818\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 1s 38ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.7754 - val_accuracy: 0.5818\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 1s 34ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.7638 - val_accuracy: 0.5818\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.7759 - val_accuracy: 0.5818\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.7874 - val_accuracy: 0.5818\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.7799 - val_accuracy: 0.5818\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.7977 - val_accuracy: 0.5818\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.7976 - val_accuracy: 0.5818\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.8234 - val_accuracy: 0.5818\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.8126 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8307 - val_accuracy: 0.5818\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.8427 - val_accuracy: 0.6000\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.8612 - val_accuracy: 0.6000\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.8697 - val_accuracy: 0.6000\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.8707 - val_accuracy: 0.5818\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8869 - val_accuracy: 0.5818\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.9074 - val_accuracy: 0.5818\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9054 - val_accuracy: 0.5818\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9111 - val_accuracy: 0.5818\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.9119 - val_accuracy: 0.5818\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.9369 - val_accuracy: 0.5818\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.9348 - val_accuracy: 0.5818\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9603 - val_accuracy: 0.5818\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9825 - val_accuracy: 0.5818\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9673 - val_accuracy: 0.5818\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9867 - val_accuracy: 0.6000\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9896 - val_accuracy: 0.5818\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9954 - val_accuracy: 0.5818\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0051 - val_accuracy: 0.6000\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0099 - val_accuracy: 0.5818\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0282 - val_accuracy: 0.5818\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0289 - val_accuracy: 0.5818\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0297 - val_accuracy: 0.6000\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.0511 - val_accuracy: 0.5818\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0562 - val_accuracy: 0.5818\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0558 - val_accuracy: 0.5818\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0642 - val_accuracy: 0.5818\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0805 - val_accuracy: 0.5818\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.0902 - val_accuracy: 0.5818\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1003 - val_accuracy: 0.5818\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1129 - val_accuracy: 0.5818\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1115 - val_accuracy: 0.5818\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1225 - val_accuracy: 0.5818\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1222 - val_accuracy: 0.5818\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1345 - val_accuracy: 0.5818\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1281 - val_accuracy: 0.5818\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.1552 - val_accuracy: 0.5818\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1502 - val_accuracy: 0.5818\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1713 - val_accuracy: 0.5818\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.1806 - val_accuracy: 0.5818\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1790 - val_accuracy: 0.5818\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.1961 - val_accuracy: 0.5818\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1843 - val_accuracy: 0.5818\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2045 - val_accuracy: 0.5818\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2036 - val_accuracy: 0.5818\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2104 - val_accuracy: 0.5818\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2211 - val_accuracy: 0.5818\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2395 - val_accuracy: 0.5818\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2456 - val_accuracy: 0.5818\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.2446 - val_accuracy: 0.5818\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.2700 - val_accuracy: 0.5818\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.2556 - val_accuracy: 0.5818\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.2688 - val_accuracy: 0.5818\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.2780 - val_accuracy: 0.5818\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.2939 - val_accuracy: 0.6000\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.3001 - val_accuracy: 0.5818\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.3046 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.3101 - val_accuracy: 0.5818\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.3160 - val_accuracy: 0.6000\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.3374 - val_accuracy: 0.5818\n",
      "Epoch 289/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.3382 - val_accuracy: 0.5818\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 9.9072e-04 - accuracy: 1.0000 - val_loss: 3.3488 - val_accuracy: 0.5818\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 9.7415e-04 - accuracy: 1.0000 - val_loss: 3.3490 - val_accuracy: 0.6000\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.3621 - val_accuracy: 0.5818\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 9.5136e-04 - accuracy: 1.0000 - val_loss: 3.3697 - val_accuracy: 0.5818\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.3605 - val_accuracy: 0.5818\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 9.0359e-04 - accuracy: 1.0000 - val_loss: 3.3791 - val_accuracy: 0.5818\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 9.0130e-04 - accuracy: 1.0000 - val_loss: 3.3817 - val_accuracy: 0.5818\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 9.5730e-04 - accuracy: 1.0000 - val_loss: 3.3934 - val_accuracy: 0.5818\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.4061 - val_accuracy: 0.5818\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 9.0481e-04 - accuracy: 1.0000 - val_loss: 3.4230 - val_accuracy: 0.5818\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 8.5370e-04 - accuracy: 1.0000 - val_loss: 3.4145 - val_accuracy: 0.5818\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 8.1271e-04 - accuracy: 1.0000 - val_loss: 3.4291 - val_accuracy: 0.5818\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 8.0153e-04 - accuracy: 1.0000 - val_loss: 3.4339 - val_accuracy: 0.5818\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 7.9674e-04 - accuracy: 1.0000 - val_loss: 3.4337 - val_accuracy: 0.5818\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 7.7942e-04 - accuracy: 1.0000 - val_loss: 3.4510 - val_accuracy: 0.5818\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 7.7774e-04 - accuracy: 1.0000 - val_loss: 3.4525 - val_accuracy: 0.5818\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 7.5830e-04 - accuracy: 1.0000 - val_loss: 3.4619 - val_accuracy: 0.6000\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 7.8710e-04 - accuracy: 1.0000 - val_loss: 3.4811 - val_accuracy: 0.5818\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 7.1989e-04 - accuracy: 1.0000 - val_loss: 3.4710 - val_accuracy: 0.5818\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 7.2207e-04 - accuracy: 1.0000 - val_loss: 3.4837 - val_accuracy: 0.6000\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 7.6321e-04 - accuracy: 1.0000 - val_loss: 3.4900 - val_accuracy: 0.5818\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 6.8653e-04 - accuracy: 1.0000 - val_loss: 3.4965 - val_accuracy: 0.6000\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 7.3183e-04 - accuracy: 1.0000 - val_loss: 3.5036 - val_accuracy: 0.5818\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 7.0956e-04 - accuracy: 1.0000 - val_loss: 3.5078 - val_accuracy: 0.5818\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 6.7742e-04 - accuracy: 1.0000 - val_loss: 3.5210 - val_accuracy: 0.5818\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 6.6436e-04 - accuracy: 1.0000 - val_loss: 3.5172 - val_accuracy: 0.5818\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 6.5911e-04 - accuracy: 1.0000 - val_loss: 3.5283 - val_accuracy: 0.5818\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 6.6363e-04 - accuracy: 1.0000 - val_loss: 3.5349 - val_accuracy: 0.5818\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 6.7572e-04 - accuracy: 1.0000 - val_loss: 3.5360 - val_accuracy: 0.6000\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 6.6370e-04 - accuracy: 1.0000 - val_loss: 3.5504 - val_accuracy: 0.6000\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 6.1950e-04 - accuracy: 1.0000 - val_loss: 3.5556 - val_accuracy: 0.5818\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 6.3277e-04 - accuracy: 1.0000 - val_loss: 3.5579 - val_accuracy: 0.5818\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 6.5310e-04 - accuracy: 1.0000 - val_loss: 3.5722 - val_accuracy: 0.5818\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 6.0984e-04 - accuracy: 1.0000 - val_loss: 3.5864 - val_accuracy: 0.5818\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 5.8582e-04 - accuracy: 1.0000 - val_loss: 3.5980 - val_accuracy: 0.5818\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 6.1310e-04 - accuracy: 1.0000 - val_loss: 3.6009 - val_accuracy: 0.5818\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 5.3617e-04 - accuracy: 1.0000 - val_loss: 3.6083 - val_accuracy: 0.5818\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 5.4010e-04 - accuracy: 1.0000 - val_loss: 3.6102 - val_accuracy: 0.5818\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 5.3947e-04 - accuracy: 1.0000 - val_loss: 3.6238 - val_accuracy: 0.5818\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 5.8673e-04 - accuracy: 1.0000 - val_loss: 3.6255 - val_accuracy: 0.5818\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 5.3905e-04 - accuracy: 1.0000 - val_loss: 3.6192 - val_accuracy: 0.5818\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 4.8868e-04 - accuracy: 1.0000 - val_loss: 3.6305 - val_accuracy: 0.5818\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 5.1467e-04 - accuracy: 1.0000 - val_loss: 3.6432 - val_accuracy: 0.5818\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 4.8811e-04 - accuracy: 1.0000 - val_loss: 3.6464 - val_accuracy: 0.5818\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 4.7029e-04 - accuracy: 1.0000 - val_loss: 3.6583 - val_accuracy: 0.5818\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 4.6268e-04 - accuracy: 1.0000 - val_loss: 3.6599 - val_accuracy: 0.5818\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 4.6223e-04 - accuracy: 1.0000 - val_loss: 3.6671 - val_accuracy: 0.5818\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 6.0277e-04 - accuracy: 1.0000 - val_loss: 3.6777 - val_accuracy: 0.5818\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 4.6676e-04 - accuracy: 1.0000 - val_loss: 3.6679 - val_accuracy: 0.5818\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 4.4777e-04 - accuracy: 1.0000 - val_loss: 3.6900 - val_accuracy: 0.5818\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 4.3094e-04 - accuracy: 1.0000 - val_loss: 3.6945 - val_accuracy: 0.5818\n",
      "Epoch 341/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 30ms/step - loss: 4.1345e-04 - accuracy: 1.0000 - val_loss: 3.7044 - val_accuracy: 0.5818\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 4.4743e-04 - accuracy: 1.0000 - val_loss: 3.7052 - val_accuracy: 0.5818\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 4.6350e-04 - accuracy: 1.0000 - val_loss: 3.7124 - val_accuracy: 0.5818\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 4.2636e-04 - accuracy: 1.0000 - val_loss: 3.7188 - val_accuracy: 0.5818\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 4.0325e-04 - accuracy: 1.0000 - val_loss: 3.7235 - val_accuracy: 0.5818\n",
      "Epoch 346/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 3.9317e-04 - accuracy: 1.0000 - val_loss: 3.7318 - val_accuracy: 0.5818\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 3.8583e-04 - accuracy: 1.0000 - val_loss: 3.7482 - val_accuracy: 0.5818\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 3.7435e-04 - accuracy: 1.0000 - val_loss: 3.7532 - val_accuracy: 0.5818\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 3.9727e-04 - accuracy: 1.0000 - val_loss: 3.7519 - val_accuracy: 0.5818\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 3.7094e-04 - accuracy: 1.0000 - val_loss: 3.7624 - val_accuracy: 0.5818\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 3.8662e-04 - accuracy: 1.0000 - val_loss: 3.7698 - val_accuracy: 0.5818\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 3.6826e-04 - accuracy: 1.0000 - val_loss: 3.7724 - val_accuracy: 0.5818\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 3.4835e-04 - accuracy: 1.0000 - val_loss: 3.7819 - val_accuracy: 0.5818\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 3.5095e-04 - accuracy: 1.0000 - val_loss: 3.7872 - val_accuracy: 0.5818\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 3.4512e-04 - accuracy: 1.0000 - val_loss: 3.7929 - val_accuracy: 0.5818\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 3.8617e-04 - accuracy: 1.0000 - val_loss: 3.7873 - val_accuracy: 0.5818\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 4.0160e-04 - accuracy: 1.0000 - val_loss: 3.8170 - val_accuracy: 0.6000\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 3.6591e-04 - accuracy: 1.0000 - val_loss: 3.8185 - val_accuracy: 0.5818\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 3.3775e-04 - accuracy: 1.0000 - val_loss: 3.8299 - val_accuracy: 0.5818\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 3.0681e-04 - accuracy: 1.0000 - val_loss: 3.8456 - val_accuracy: 0.5818\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 3.0582e-04 - accuracy: 1.0000 - val_loss: 3.8408 - val_accuracy: 0.5818\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 3.2409e-04 - accuracy: 1.0000 - val_loss: 3.8431 - val_accuracy: 0.6000\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 3.2402e-04 - accuracy: 1.0000 - val_loss: 3.8547 - val_accuracy: 0.5818\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 3.1172e-04 - accuracy: 1.0000 - val_loss: 3.8582 - val_accuracy: 0.5818\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.8553e-04 - accuracy: 1.0000 - val_loss: 3.8652 - val_accuracy: 0.5818\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.9294e-04 - accuracy: 1.0000 - val_loss: 3.8647 - val_accuracy: 0.6000\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.9443e-04 - accuracy: 1.0000 - val_loss: 3.8786 - val_accuracy: 0.5818\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.7675e-04 - accuracy: 1.0000 - val_loss: 3.8837 - val_accuracy: 0.5818\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.6987e-04 - accuracy: 1.0000 - val_loss: 3.8880 - val_accuracy: 0.5818\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.7977e-04 - accuracy: 1.0000 - val_loss: 3.8978 - val_accuracy: 0.5818\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.7354e-04 - accuracy: 1.0000 - val_loss: 3.8947 - val_accuracy: 0.5818\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.6052e-04 - accuracy: 1.0000 - val_loss: 3.9068 - val_accuracy: 0.5818\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.6239e-04 - accuracy: 1.0000 - val_loss: 3.9104 - val_accuracy: 0.5818\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.5456e-04 - accuracy: 1.0000 - val_loss: 3.9185 - val_accuracy: 0.5818\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.4703e-04 - accuracy: 1.0000 - val_loss: 3.9183 - val_accuracy: 0.5818\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.4598e-04 - accuracy: 1.0000 - val_loss: 3.9283 - val_accuracy: 0.5818\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.5795e-04 - accuracy: 1.0000 - val_loss: 3.9350 - val_accuracy: 0.5818\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.5061e-04 - accuracy: 1.0000 - val_loss: 3.9428 - val_accuracy: 0.5818\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.4183e-04 - accuracy: 1.0000 - val_loss: 3.9445 - val_accuracy: 0.5818\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.4151e-04 - accuracy: 1.0000 - val_loss: 3.9532 - val_accuracy: 0.5818\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.3660e-04 - accuracy: 1.0000 - val_loss: 3.9616 - val_accuracy: 0.5818\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.2936e-04 - accuracy: 1.0000 - val_loss: 3.9667 - val_accuracy: 0.5818\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.2209e-04 - accuracy: 1.0000 - val_loss: 3.9681 - val_accuracy: 0.5818\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.2364e-04 - accuracy: 1.0000 - val_loss: 3.9742 - val_accuracy: 0.5818\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.2219e-04 - accuracy: 1.0000 - val_loss: 3.9768 - val_accuracy: 0.5818\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 2.3711e-04 - accuracy: 1.0000 - val_loss: 3.9893 - val_accuracy: 0.5818\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 2.0912e-04 - accuracy: 1.0000 - val_loss: 3.9877 - val_accuracy: 0.5818\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.0900e-04 - accuracy: 1.0000 - val_loss: 3.9981 - val_accuracy: 0.5818\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.1507e-04 - accuracy: 1.0000 - val_loss: 4.0095 - val_accuracy: 0.5818\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.2002e-04 - accuracy: 1.0000 - val_loss: 4.0084 - val_accuracy: 0.5818\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.0369e-04 - accuracy: 1.0000 - val_loss: 4.0167 - val_accuracy: 0.5818\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 1.9829e-04 - accuracy: 1.0000 - val_loss: 4.0163 - val_accuracy: 0.5818\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 1.9077e-04 - accuracy: 1.0000 - val_loss: 4.0299 - val_accuracy: 0.5818\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 1.9484e-04 - accuracy: 1.0000 - val_loss: 4.0440 - val_accuracy: 0.5818\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.0005e-04 - accuracy: 1.0000 - val_loss: 4.0478 - val_accuracy: 0.5818\n",
      "Epoch 396/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 31ms/step - loss: 1.9264e-04 - accuracy: 1.0000 - val_loss: 4.0495 - val_accuracy: 0.5818\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 1.9202e-04 - accuracy: 1.0000 - val_loss: 4.0569 - val_accuracy: 0.5818\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 2.0169e-04 - accuracy: 1.0000 - val_loss: 4.0544 - val_accuracy: 0.5818\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 1.8063e-04 - accuracy: 1.0000 - val_loss: 4.0683 - val_accuracy: 0.5818\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 1.7987e-04 - accuracy: 1.0000 - val_loss: 4.0750 - val_accuracy: 0.5818\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 1.7856e-04 - accuracy: 1.0000 - val_loss: 4.0787 - val_accuracy: 0.5818\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 1.6692e-04 - accuracy: 1.0000 - val_loss: 4.0844 - val_accuracy: 0.5818\n",
      "Epoch 403/500\n",
      "21/21 [==============================] - 1s 31ms/step - loss: 1.7012e-04 - accuracy: 1.0000 - val_loss: 4.0955 - val_accuracy: 0.5818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6a06b9fd0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_222.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_222.fit(X_train_over, y_train_over, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1bc96b77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6578 - accuracy: 0.7115\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6599 - accuracy: 0.7455\n"
     ]
    }
   ],
   "source": [
    "m1_eval_test = model_222.evaluate(X_test, y_test)\n",
    "m1_eval_val = model_222.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e083593b",
   "metadata": {},
   "source": [
    "**For test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5dc38ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n",
      "roc auc score:  0.6917293233082706\n",
      "average precision score:  0.6319369404120412\n"
     ]
    }
   ],
   "source": [
    "pred = model_222.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2c712255",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f36b821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6578 - accuracy: 0.7115\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_222.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e58600",
   "metadata": {},
   "source": [
    "**For validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "257a0d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n",
      "roc auc score:  0.6702786377708978\n",
      "average precision score:  0.6816161753158589\n"
     ]
    }
   ],
   "source": [
    "pred = model_222.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7d6773e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4d2d18cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6599 - accuracy: 0.7455\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels (validation set)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_222.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edfb65d",
   "metadata": {},
   "source": [
    "**Model saving:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8f093869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_221_json = model_221.to_json()\n",
    "with open(\"model_221.json\", \"w\") as json_file:\n",
    "    json_file.write(model_221_json)\n",
    "# serialize weights to HDF5\n",
    "model_221.save_weights(\"model_221.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "548a5726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_222_json = model_222.to_json()\n",
    "with open(\"model_222.json\", \"w\") as json_file:\n",
    "    json_file.write(model_222_json)\n",
    "# serialize weights to HDF5\n",
    "model_222.save_weights(\"model_222.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb3b59f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
