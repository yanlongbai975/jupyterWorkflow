{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9ca9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a80b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   ## data analysis and manipulation\n",
    "import numpy as np    ## numerial computing\n",
    "import seaborn as sns ##  data visualization library based on matplotlib\n",
    "import tensorflow.keras as keras ## main deep learning API\n",
    "\n",
    "## additional functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f0df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0946f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EID</th>\n",
       "      <th>PID</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Eye</th>\n",
       "      <th>ImageID</th>\n",
       "      <th>Scan.Type</th>\n",
       "      <th>Diameter..mm.</th>\n",
       "      <th>Diameter....</th>\n",
       "      <th>Fixed.in.mm</th>\n",
       "      <th>ExamDate</th>\n",
       "      <th>...</th>\n",
       "      <th>VF_OCT_BASELINE_DIFF</th>\n",
       "      <th>VF_OCT_FINAL_DIFF</th>\n",
       "      <th>MD_BASELINE</th>\n",
       "      <th>MD_FINAL</th>\n",
       "      <th>VFI_BASELINE</th>\n",
       "      <th>VFI_FINAL</th>\n",
       "      <th>Y_GRI</th>\n",
       "      <th>Y_MD</th>\n",
       "      <th>Y_VFI</th>\n",
       "      <th>Y_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10/24/1949</td>\n",
       "      <td>LE</td>\n",
       "      <td>282596.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.561944</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10/24/1949</td>\n",
       "      <td>RE</td>\n",
       "      <td>282593.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5/11/2017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.561944</td>\n",
       "      <td>-7.73</td>\n",
       "      <td>-11.45</td>\n",
       "      <td>82</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8/7/1939</td>\n",
       "      <td>LE</td>\n",
       "      <td>239514.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.151951</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8/7/1939</td>\n",
       "      <td>RE</td>\n",
       "      <td>239512.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/26/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.151951</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.60</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5/20/1943</td>\n",
       "      <td>LE</td>\n",
       "      <td>238460.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7/9/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024641</td>\n",
       "      <td>6.266940</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>580</td>\n",
       "      <td>329</td>\n",
       "      <td>3/22/1952</td>\n",
       "      <td>RE</td>\n",
       "      <td>837.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5/5/2011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.601643</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-2.51</td>\n",
       "      <td>98</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>581</td>\n",
       "      <td>330</td>\n",
       "      <td>5/15/1945</td>\n",
       "      <td>LE</td>\n",
       "      <td>243095.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12/17/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.941136</td>\n",
       "      <td>-8.97</td>\n",
       "      <td>-14.71</td>\n",
       "      <td>78</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>582</td>\n",
       "      <td>330</td>\n",
       "      <td>5/15/1945</td>\n",
       "      <td>RE</td>\n",
       "      <td>243093.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12/17/2014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.941136</td>\n",
       "      <td>-11.39</td>\n",
       "      <td>-11.37</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>583</td>\n",
       "      <td>331</td>\n",
       "      <td>5/31/1939</td>\n",
       "      <td>LE</td>\n",
       "      <td>109347.0</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/13/2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172485</td>\n",
       "      <td>6.193018</td>\n",
       "      <td>-3.48</td>\n",
       "      <td>-19.28</td>\n",
       "      <td>97</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>584</td>\n",
       "      <td>331</td>\n",
       "      <td>5/31/1939</td>\n",
       "      <td>RE</td>\n",
       "      <td>109343.2</td>\n",
       "      <td>OCT Circle Scan</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8/13/2013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172485</td>\n",
       "      <td>6.193018</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>-16.15</td>\n",
       "      <td>93</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 815 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EID  PID         DOB Eye   ImageID        Scan.Type  Diameter..mm.  \\\n",
       "0      1    1  10/24/1949  LE  282596.0  OCT Circle Scan            3.7   \n",
       "1      2    1  10/24/1949  RE  282593.0  OCT Circle Scan            3.7   \n",
       "2      3    2    8/7/1939  LE  239514.0  OCT Circle Scan            3.4   \n",
       "3      4    2    8/7/1939  RE  239512.0  OCT Circle Scan            3.4   \n",
       "4      5    3   5/20/1943  LE  238460.0  OCT Circle Scan            3.5   \n",
       "..   ...  ...         ...  ..       ...              ...            ...   \n",
       "579  580  329   3/22/1952  RE     837.0  OCT Circle Scan            3.7   \n",
       "580  581  330   5/15/1945  LE  243095.0  OCT Circle Scan            3.5   \n",
       "581  582  330   5/15/1945  RE  243093.0  OCT Circle Scan            3.7   \n",
       "582  583  331   5/31/1939  LE  109347.0  OCT Circle Scan            3.5   \n",
       "583  584  331   5/31/1939  RE  109343.2  OCT Circle Scan            3.5   \n",
       "\n",
       "     Diameter....  Fixed.in.mm    ExamDate  ... VF_OCT_BASELINE_DIFF  \\\n",
       "0            12.0            0   5/11/2017  ...             0.000000   \n",
       "1            12.0            0   5/11/2017  ...             0.000000   \n",
       "2            12.0            0   8/26/2014  ...             0.000000   \n",
       "3            12.0            0   8/26/2014  ...             0.000000   \n",
       "4            12.0            0    7/9/2014  ...             0.024641   \n",
       "..            ...          ...         ...  ...                  ...   \n",
       "579          12.0            0    5/5/2011  ...             0.000000   \n",
       "580          12.0            0  12/17/2014  ...             0.000000   \n",
       "581          12.0            0  12/17/2014  ...             0.000000   \n",
       "582          12.0            0   8/13/2013  ...             0.172485   \n",
       "583          12.0            0   8/13/2013  ...             0.172485   \n",
       "\n",
       "    VF_OCT_FINAL_DIFF  MD_BASELINE  MD_FINAL  VFI_BASELINE  VFI_FINAL  Y_GRI  \\\n",
       "0            3.561944        -2.15     -3.26            98         96      0   \n",
       "1            3.561944        -7.73    -11.45            82         73      1   \n",
       "2            6.151951        -1.28     -1.13            98         97      0   \n",
       "3            6.151951        -0.72      0.60            98         99      0   \n",
       "4            6.266940        -1.69     -0.51            99         99      0   \n",
       "..                ...          ...       ...           ...        ...    ...   \n",
       "579          9.601643         0.53     -2.51            98         93      1   \n",
       "580          5.941136        -8.97    -14.71            78         56      1   \n",
       "581          5.941136       -11.39    -11.37            70         67      1   \n",
       "582          6.193018        -3.48    -19.28            97         51      1   \n",
       "583          6.193018        -3.34    -16.15            93         47      1   \n",
       "\n",
       "     Y_MD  Y_VFI  Y_combined  \n",
       "0       0      0           0  \n",
       "1       0      0           1  \n",
       "2       0      0           0  \n",
       "3       0      0           0  \n",
       "4       0      0           0  \n",
       "..    ...    ...         ...  \n",
       "579     0      0           1  \n",
       "580     1      1           1  \n",
       "581     0      0           1  \n",
       "582     1      1           1  \n",
       "583     1      1           1  \n",
       "\n",
       "[584 rows x 815 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "df = pd.read_csv(\"/Users/a123456/Desktop/Fei's Project/Data/OCT_BASELINE_GRI__VF_6-3_FP-15_NO_PHI_CombinedProgression.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab42345b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 815)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter only circle scan data\n",
    "circle_scan = (df['Scan.Type'] == 'OCT Circle Scan')\n",
    "df = df[circle_scan]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a70e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f1d49",
   "metadata": {},
   "source": [
    "## 1. GRI only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dce5b52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>RNFLT.1</th>\n",
       "      <th>RNFLT.2</th>\n",
       "      <th>RNFLT.3</th>\n",
       "      <th>RNFLT.4</th>\n",
       "      <th>RNFLT.5</th>\n",
       "      <th>RNFLT.6</th>\n",
       "      <th>RNFLT.7</th>\n",
       "      <th>RNFLT.8</th>\n",
       "      <th>RNFLT.9</th>\n",
       "      <th>...</th>\n",
       "      <th>RNFLT.761</th>\n",
       "      <th>RNFLT.762</th>\n",
       "      <th>RNFLT.763</th>\n",
       "      <th>RNFLT.764</th>\n",
       "      <th>RNFLT.765</th>\n",
       "      <th>RNFLT.766</th>\n",
       "      <th>RNFLT.767</th>\n",
       "      <th>RNFLT.768</th>\n",
       "      <th>GRI</th>\n",
       "      <th>Y_GRI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-3.688171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.329429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.581343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>329</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-11.691467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>330</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-19.908699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>330</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-10.130481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>331</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-24.731627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>331</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-18.674765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PID  RNFLT.1  RNFLT.2  RNFLT.3  RNFLT.4  RNFLT.5  RNFLT.6  RNFLT.7  \\\n",
       "0      1     47.0     47.0     46.0     46.0     45.0     45.0     45.0   \n",
       "1      1     70.0     71.0     72.0     72.0     73.0     73.0     73.0   \n",
       "2      2     44.0     45.0     45.0     45.0     46.0     47.0     48.0   \n",
       "3      2     44.0     44.0     44.0     45.0     45.0     46.0     46.0   \n",
       "4      3     37.0     38.0     39.0     40.0     41.0     42.0     43.0   \n",
       "..   ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "579  329    100.0    103.0    106.0    108.0    111.0    112.0    113.0   \n",
       "580  330     52.0     52.0     53.0     54.0     55.0     56.0     57.0   \n",
       "581  330     62.0     63.0     64.0     65.0     66.0     67.0     68.0   \n",
       "582  331     47.0     47.0     48.0     48.0     49.0     49.0     50.0   \n",
       "583  331     31.0     31.0     32.0     33.0     33.0     34.0     35.0   \n",
       "\n",
       "     RNFLT.8  RNFLT.9  ...  RNFLT.761  RNFLT.762  RNFLT.763  RNFLT.764  \\\n",
       "0       45.0     45.0  ...       48.0       48.0       48.0       48.0   \n",
       "1       73.0     74.0  ...       60.0       61.0       62.0       63.0   \n",
       "2       50.0     51.0  ...       45.0       45.0       45.0       45.0   \n",
       "3       47.0     47.0  ...       43.0       43.0       43.0       43.0   \n",
       "4       44.0     46.0  ...       35.0       35.0       35.0       35.0   \n",
       "..       ...      ...  ...        ...        ...        ...        ...   \n",
       "579    113.0    113.0  ...       83.0       84.0       86.0       87.0   \n",
       "580     58.0     59.0  ...       47.0       47.0       48.0       48.0   \n",
       "581     68.0     68.0  ...       55.0       56.0       57.0       58.0   \n",
       "582     50.0     50.0  ...       47.0       46.0       46.0       45.0   \n",
       "583     36.0     37.0  ...       31.0       31.0       30.0       30.0   \n",
       "\n",
       "     RNFLT.765  RNFLT.766  RNFLT.767  RNFLT.768        GRI  Y_GRI  \n",
       "0         48.0       48.0       48.0       47.0  -3.688171      0  \n",
       "1         65.0       66.0       67.0       69.0  -6.827438      1  \n",
       "2         45.0       45.0       45.0       44.0   0.329429      0  \n",
       "3         43.0       43.0       43.0       43.0   0.581343      0  \n",
       "4         35.0       35.0       36.0       36.0   0.000000      0  \n",
       "..         ...        ...        ...        ...        ...    ...  \n",
       "579       89.0       92.0       94.0       97.0 -11.691467      1  \n",
       "580       49.0       49.0       50.0       51.0 -19.908699      1  \n",
       "581       58.0       59.0       60.0       61.0 -10.130481      1  \n",
       "582       45.0       46.0       46.0       46.0 -24.731627      1  \n",
       "583       30.0       30.0       30.0       30.0 -18.674765      1  \n",
       "\n",
       "[580 rows x 771 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.iloc[:, np.r_[1, 28:797, 811]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918a4f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 771)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop missing values\n",
    "df = df.dropna()\n",
    "df.isnull().values.sum()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e27db43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "579    1\n",
       "580    1\n",
       "581    1\n",
       "582    1\n",
       "583    1\n",
       "Name: Y_GRI, Length: 575, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:, 770]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73cadb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/applied-systems-biology/Dynamic_SPHARM/blob/master/SPHARM/classes/stratified_group_shuffle_split.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "class GroupShuffleSplitStratified(StratifiedShuffleSplit):\n",
    "\n",
    "    def __init__(self, n_splits=5, test_size=2, train_size=None, random_state=None):\n",
    "\n",
    "        super(GroupShuffleSplitStratified, self).__init__(\n",
    "            n_splits=n_splits,\n",
    "            test_size=test_size,\n",
    "            train_size=train_size,\n",
    "            random_state=random_state)\n",
    "\n",
    "    def _iter_indices(self, X, y, groups):\n",
    "        if groups is None:\n",
    "            raise ValueError(\"The 'groups' parameter should not be None.\")\n",
    "        groups = check_array(groups, ensure_2d=False, dtype=None)\n",
    "        groups_unique, group_indices = np.unique(groups, return_inverse=True)\n",
    "        classes = []\n",
    "        for gr in groups_unique:\n",
    "            classes.append(y[np.where(groups==gr)[0][0]])\n",
    "\n",
    "        for group_train, group_test in super(\n",
    "                GroupShuffleSplitStratified, self)._iter_indices(X=groups_unique, y=classes):\n",
    "            # these are the indices of classes in the partition\n",
    "            # invert them into data indices\n",
    "\n",
    "            train = np.flatnonzero(np.in1d(group_indices, group_train))\n",
    "            test = np.flatnonzero(np.in1d(group_indices, group_test))\n",
    "\n",
    "            yield train, test\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        return super(GroupShuffleSplitStratified, self).split(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65813442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(523, 771)\n",
      "(52, 771)\n"
     ]
    }
   ],
   "source": [
    "train_i,test_i = next(GroupShuffleSplitStratified(n_splits=2, test_size=0.1,\n",
    "                                        random_state=8).split(df,y, groups=df['PID']))\n",
    "TrainVal = df.iloc[train_i]\n",
    "TestSet = df.iloc[test_i]\n",
    "print(TrainVal.shape)\n",
    "print(TestSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "540f6086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 771)\n",
      "(55, 771)\n"
     ]
    }
   ],
   "source": [
    "train_id,val_id = next(GroupShuffleSplitStratified(n_splits=2, test_size=0.1,\n",
    "                                        random_state=8).split(TrainVal,y.iloc[train_i], groups=TrainVal['PID']))\n",
    "TrainSet = TrainVal.iloc[train_id]\n",
    "ValSet = TrainVal.iloc[val_id]\n",
    "print(TrainSet.shape)\n",
    "print(ValSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c5250c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(52, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNFLT.1</th>\n",
       "      <th>RNFLT.2</th>\n",
       "      <th>RNFLT.3</th>\n",
       "      <th>RNFLT.4</th>\n",
       "      <th>RNFLT.5</th>\n",
       "      <th>RNFLT.6</th>\n",
       "      <th>RNFLT.7</th>\n",
       "      <th>RNFLT.8</th>\n",
       "      <th>RNFLT.9</th>\n",
       "      <th>RNFLT.10</th>\n",
       "      <th>...</th>\n",
       "      <th>RNFLT.759</th>\n",
       "      <th>RNFLT.760</th>\n",
       "      <th>RNFLT.761</th>\n",
       "      <th>RNFLT.762</th>\n",
       "      <th>RNFLT.763</th>\n",
       "      <th>RNFLT.764</th>\n",
       "      <th>RNFLT.765</th>\n",
       "      <th>RNFLT.766</th>\n",
       "      <th>RNFLT.767</th>\n",
       "      <th>RNFLT.768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RNFLT.1  RNFLT.2  RNFLT.3  RNFLT.4  RNFLT.5  RNFLT.6  RNFLT.7  RNFLT.8  \\\n",
       "26     34.0     34.0     35.0     35.0     36.0     36.0     37.0     38.0   \n",
       "27     42.0     43.0     44.0     45.0     46.0     46.0     47.0     47.0   \n",
       "51     34.0     35.0     37.0     40.0     42.0     44.0     46.0     47.0   \n",
       "52     52.0     52.0     52.0     52.0     52.0     52.0     51.0     51.0   \n",
       "62     53.0     53.0     53.0     54.0     54.0     55.0     56.0     56.0   \n",
       "\n",
       "    RNFLT.9  RNFLT.10  ...  RNFLT.759  RNFLT.760  RNFLT.761  RNFLT.762  \\\n",
       "26     39.0      39.0  ...       34.0       33.0       33.0       33.0   \n",
       "27     48.0      48.0  ...       41.0       40.0       40.0       40.0   \n",
       "51     48.0      48.0  ...       29.0       29.0       28.0       28.0   \n",
       "52     51.0      51.0  ...       52.0       53.0       53.0       53.0   \n",
       "62     57.0      58.0  ...       55.0       55.0       55.0       55.0   \n",
       "\n",
       "    RNFLT.763  RNFLT.764  RNFLT.765  RNFLT.766  RNFLT.767  RNFLT.768  \n",
       "26       32.0       32.0       32.0       33.0       33.0       33.0  \n",
       "27       40.0       40.0       40.0       40.0       41.0       41.0  \n",
       "51       28.0       29.0       29.0       30.0       31.0       32.0  \n",
       "52       53.0       53.0       53.0       53.0       52.0       52.0  \n",
       "62       54.0       54.0       54.0       53.0       53.0       53.0  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.iloc[test_i, 1:769]\n",
    "print(x.isnull().values.sum())\n",
    "print(x.shape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7768ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_test = scaled_x\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75b1b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = TrainVal.iloc[train_id, 1:769]\n",
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_train = scaled_x\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a83c4019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = TrainVal.iloc[val_id, 1:769]\n",
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_val = scaled_x\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31123dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1\n",
      "1  0    407\n",
      "0  1    168\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1\n",
       "0    1  0\n",
       "1    0  1\n",
       "2    1  0\n",
       "3    1  0\n",
       "4    1  0\n",
       "..  .. ..\n",
       "579  0  1\n",
       "580  0  1\n",
       "581  0  1\n",
       "582  0  1\n",
       "583  0  1\n",
       "\n",
       "[575 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot-encoding our label\n",
    "y = pd.get_dummies(y)\n",
    "print(y.value_counts())\n",
    "y #The second column is 'progressor', The first column is 'non-progressor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef8002da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "0                 1           0\n",
       "1                 0           1\n",
       "2                 1           0\n",
       "3                 1           0\n",
       "4                 1           0\n",
       "..              ...         ...\n",
       "579               0           1\n",
       "580               0           1\n",
       "581               0           1\n",
       "582               0           1\n",
       "583               0           1\n",
       "\n",
       "[575 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.rename(columns={0: \"Non-Progressor\", 1: \"Progressor\"})\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5529712b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "26                1           0\n",
       "27                1           0\n",
       "51                0           1\n",
       "52                1           0\n",
       "62                0           1\n",
       "63                1           0\n",
       "118               1           0\n",
       "143               0           1\n",
       "144               1           0\n",
       "145               1           0\n",
       "146               1           0\n",
       "196               1           0\n",
       "199               1           0\n",
       "200               1           0\n",
       "201               1           0\n",
       "221               1           0\n",
       "222               1           0\n",
       "249               1           0\n",
       "250               1           0\n",
       "251               1           0\n",
       "252               1           0\n",
       "258               1           0\n",
       "259               1           0\n",
       "260               1           0\n",
       "261               1           0\n",
       "263               0           1\n",
       "264               1           0\n",
       "273               1           0\n",
       "274               1           0\n",
       "277               0           1\n",
       "278               1           0\n",
       "288               0           1\n",
       "312               1           0\n",
       "313               0           1\n",
       "320               1           0\n",
       "321               1           0\n",
       "334               0           1\n",
       "335               0           1\n",
       "339               1           0\n",
       "340               1           0\n",
       "370               1           0\n",
       "437               1           0\n",
       "478               1           0\n",
       "479               0           1\n",
       "482               0           1\n",
       "489               1           0\n",
       "501               1           0\n",
       "519               0           1\n",
       "532               0           1\n",
       "533               0           1\n",
       "544               1           0\n",
       "545               1           0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y.iloc[test_i]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c75f7f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "0                 1           0\n",
       "1                 0           1\n",
       "2                 1           0\n",
       "3                 1           0\n",
       "4                 1           0\n",
       "..              ...         ...\n",
       "579               0           1\n",
       "580               0           1\n",
       "581               0           1\n",
       "582               0           1\n",
       "583               0           1\n",
       "\n",
       "[468 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y.iloc[train_i].iloc[train_id]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ac9ec2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "12                0           1\n",
       "16                0           1\n",
       "17                1           0\n",
       "28                1           0\n",
       "29                1           0\n",
       "49                0           1\n",
       "50                1           0\n",
       "60                0           1\n",
       "88                0           1\n",
       "89                1           0\n",
       "109               0           1\n",
       "110               0           1\n",
       "121               1           0\n",
       "141               0           1\n",
       "142               0           1\n",
       "154               1           0\n",
       "155               0           1\n",
       "156               1           0\n",
       "157               1           0\n",
       "215               1           0\n",
       "216               1           0\n",
       "217               1           0\n",
       "218               1           0\n",
       "219               1           0\n",
       "220               1           0\n",
       "242               1           0\n",
       "243               1           0\n",
       "279               1           0\n",
       "280               1           0\n",
       "281               1           0\n",
       "282               1           0\n",
       "287               1           0\n",
       "289               1           0\n",
       "290               1           0\n",
       "302               1           0\n",
       "303               1           0\n",
       "349               0           1\n",
       "350               0           1\n",
       "358               1           0\n",
       "359               0           1\n",
       "366               1           0\n",
       "367               1           0\n",
       "368               1           0\n",
       "369               0           1\n",
       "391               1           0\n",
       "392               0           1\n",
       "429               1           0\n",
       "472               0           1\n",
       "473               1           0\n",
       "494               1           0\n",
       "495               1           0\n",
       "528               1           0\n",
       "529               0           1\n",
       "540               1           0\n",
       "541               1           0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = y.iloc[train_i].iloc[val_id]\n",
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb41f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 768, 1)\n",
      "(52, 768, 1)\n",
      "(55, 768, 1)\n",
      "Non-Progressor  Progressor\n",
      "1               0             331\n",
      "0               1             137\n",
      "dtype: int64 \n",
      "\n",
      "Non-Progressor  Progressor\n",
      "1               0             38\n",
      "0               1             17\n",
      "dtype: int64 \n",
      "\n",
      "Non-Progressor  Progressor\n",
      "1               0             38\n",
      "0               1             14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.value_counts(), '\\n')\n",
    "print(y_val.value_counts(), '\\n')\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6cea66",
   "metadata": {},
   "source": [
    "### 1.1 CNN model without resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868745e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abc2fe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 766, 64)           256       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 255, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 255, 64)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16320)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1044544   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,045,874\n",
      "Trainable params: 1,045,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 16:05:43.635280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#create model1\n",
    "model_1 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_1.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_1.add(MaxPooling1D(pool_size=3))\n",
    "# model_1.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "# model_1.add(MaxPooling1D(pool_size=2))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dense(16, activation='relu'))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90641e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=100,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af03c403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15/15 [==============================] - 1s 27ms/step - loss: 0.6245 - accuracy: 0.6880 - val_loss: 0.6116 - val_accuracy: 0.6909\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5990 - accuracy: 0.7073 - val_loss: 0.6082 - val_accuracy: 0.6909\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.5976 - accuracy: 0.7073 - val_loss: 0.6051 - val_accuracy: 0.6909\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5952 - accuracy: 0.7073 - val_loss: 0.6035 - val_accuracy: 0.6909\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5942 - accuracy: 0.7073 - val_loss: 0.6027 - val_accuracy: 0.6909\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5930 - accuracy: 0.7073 - val_loss: 0.6030 - val_accuracy: 0.6909\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5934 - accuracy: 0.7073 - val_loss: 0.6000 - val_accuracy: 0.6909\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5876 - accuracy: 0.7073 - val_loss: 0.5995 - val_accuracy: 0.6909\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5867 - accuracy: 0.7073 - val_loss: 0.5978 - val_accuracy: 0.6909\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.5862 - accuracy: 0.7073 - val_loss: 0.5958 - val_accuracy: 0.6909\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5856 - accuracy: 0.7073 - val_loss: 0.5950 - val_accuracy: 0.6909\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.5857 - accuracy: 0.7073 - val_loss: 0.5939 - val_accuracy: 0.6909\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5833 - accuracy: 0.7073 - val_loss: 0.5959 - val_accuracy: 0.6909\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5817 - accuracy: 0.7073 - val_loss: 0.5921 - val_accuracy: 0.6909\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5782 - accuracy: 0.7073 - val_loss: 0.5922 - val_accuracy: 0.6909\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5761 - accuracy: 0.7073 - val_loss: 0.5942 - val_accuracy: 0.6909\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5814 - accuracy: 0.7073 - val_loss: 0.5895 - val_accuracy: 0.6909\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5760 - accuracy: 0.7073 - val_loss: 0.5930 - val_accuracy: 0.6909\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5725 - accuracy: 0.7073 - val_loss: 0.5885 - val_accuracy: 0.6909\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5690 - accuracy: 0.7073 - val_loss: 0.5870 - val_accuracy: 0.6909\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5692 - accuracy: 0.7073 - val_loss: 0.5883 - val_accuracy: 0.6909\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5671 - accuracy: 0.7073 - val_loss: 0.5861 - val_accuracy: 0.6909\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5674 - accuracy: 0.7094 - val_loss: 0.5876 - val_accuracy: 0.6909\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5677 - accuracy: 0.7094 - val_loss: 0.5843 - val_accuracy: 0.6909\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5639 - accuracy: 0.7073 - val_loss: 0.5848 - val_accuracy: 0.6909\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5632 - accuracy: 0.7115 - val_loss: 0.5835 - val_accuracy: 0.6909\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5590 - accuracy: 0.7094 - val_loss: 0.5856 - val_accuracy: 0.6909\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5581 - accuracy: 0.7094 - val_loss: 0.5826 - val_accuracy: 0.6909\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5599 - accuracy: 0.7094 - val_loss: 0.5817 - val_accuracy: 0.6909\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5581 - accuracy: 0.7094 - val_loss: 0.5824 - val_accuracy: 0.6909\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5549 - accuracy: 0.7115 - val_loss: 0.5820 - val_accuracy: 0.6909\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5531 - accuracy: 0.7115 - val_loss: 0.5812 - val_accuracy: 0.6909\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5535 - accuracy: 0.7115 - val_loss: 0.5804 - val_accuracy: 0.6909\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5486 - accuracy: 0.7137 - val_loss: 0.5810 - val_accuracy: 0.6909\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5507 - accuracy: 0.7179 - val_loss: 0.5807 - val_accuracy: 0.6909\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5463 - accuracy: 0.7115 - val_loss: 0.5815 - val_accuracy: 0.6909\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.5465 - accuracy: 0.7179 - val_loss: 0.5798 - val_accuracy: 0.6909\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5447 - accuracy: 0.7158 - val_loss: 0.5805 - val_accuracy: 0.6909\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.5444 - accuracy: 0.7179 - val_loss: 0.5814 - val_accuracy: 0.6909\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.5414 - accuracy: 0.7286 - val_loss: 0.5795 - val_accuracy: 0.6909\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5432 - accuracy: 0.7244 - val_loss: 0.5782 - val_accuracy: 0.7091\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5391 - accuracy: 0.7329 - val_loss: 0.5847 - val_accuracy: 0.6909\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5420 - accuracy: 0.7244 - val_loss: 0.5783 - val_accuracy: 0.6909\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.5310 - accuracy: 0.7415 - val_loss: 0.5801 - val_accuracy: 0.6909\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5279 - accuracy: 0.7244 - val_loss: 0.5779 - val_accuracy: 0.6909\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5292 - accuracy: 0.7286 - val_loss: 0.5783 - val_accuracy: 0.6909\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.5262 - accuracy: 0.7479 - val_loss: 0.5788 - val_accuracy: 0.6909\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5271 - accuracy: 0.7308 - val_loss: 0.5768 - val_accuracy: 0.6909\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5236 - accuracy: 0.7457 - val_loss: 0.5794 - val_accuracy: 0.6909\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5166 - accuracy: 0.7415 - val_loss: 0.5760 - val_accuracy: 0.6727\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5215 - accuracy: 0.7436 - val_loss: 0.5766 - val_accuracy: 0.6909\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5187 - accuracy: 0.7457 - val_loss: 0.5775 - val_accuracy: 0.6909\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5182 - accuracy: 0.7521 - val_loss: 0.5745 - val_accuracy: 0.6727\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5192 - accuracy: 0.7479 - val_loss: 0.5745 - val_accuracy: 0.6909\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5147 - accuracy: 0.7628 - val_loss: 0.5868 - val_accuracy: 0.6909\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.5148 - accuracy: 0.7436 - val_loss: 0.5747 - val_accuracy: 0.6727\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5113 - accuracy: 0.7457 - val_loss: 0.5740 - val_accuracy: 0.6727\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 20ms/step - loss: 0.5065 - accuracy: 0.7607 - val_loss: 0.5806 - val_accuracy: 0.6909\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.5053 - accuracy: 0.7564 - val_loss: 0.5738 - val_accuracy: 0.6909\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5039 - accuracy: 0.7585 - val_loss: 0.5775 - val_accuracy: 0.6909\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.5033 - accuracy: 0.7500 - val_loss: 0.5722 - val_accuracy: 0.7273\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.5057 - accuracy: 0.7564 - val_loss: 0.5746 - val_accuracy: 0.7091\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.5013 - accuracy: 0.7564 - val_loss: 0.5749 - val_accuracy: 0.7091\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4976 - accuracy: 0.7671 - val_loss: 0.5763 - val_accuracy: 0.6909\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4956 - accuracy: 0.7756 - val_loss: 0.5803 - val_accuracy: 0.6909\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4926 - accuracy: 0.7735 - val_loss: 0.5779 - val_accuracy: 0.6909\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4897 - accuracy: 0.7628 - val_loss: 0.5759 - val_accuracy: 0.7091\n",
      "Epoch 68/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4885 - accuracy: 0.7714 - val_loss: 0.5723 - val_accuracy: 0.7273\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4942 - accuracy: 0.7671 - val_loss: 0.5742 - val_accuracy: 0.7091\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4890 - accuracy: 0.7863 - val_loss: 0.5788 - val_accuracy: 0.7091\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4899 - accuracy: 0.7714 - val_loss: 0.5749 - val_accuracy: 0.7273\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4896 - accuracy: 0.7650 - val_loss: 0.5737 - val_accuracy: 0.7273\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4862 - accuracy: 0.7799 - val_loss: 0.5745 - val_accuracy: 0.7273\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4778 - accuracy: 0.7607 - val_loss: 0.5758 - val_accuracy: 0.7091\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4747 - accuracy: 0.7778 - val_loss: 0.5737 - val_accuracy: 0.7273\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4868 - accuracy: 0.7863 - val_loss: 0.5785 - val_accuracy: 0.7091\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4741 - accuracy: 0.7756 - val_loss: 0.5789 - val_accuracy: 0.7273\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4687 - accuracy: 0.7949 - val_loss: 0.5776 - val_accuracy: 0.7273\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4726 - accuracy: 0.7778 - val_loss: 0.5746 - val_accuracy: 0.7273\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4798 - accuracy: 0.7735 - val_loss: 0.5758 - val_accuracy: 0.7091\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4669 - accuracy: 0.7970 - val_loss: 0.5839 - val_accuracy: 0.7273\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4640 - accuracy: 0.7756 - val_loss: 0.5764 - val_accuracy: 0.7273\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4627 - accuracy: 0.7906 - val_loss: 0.5771 - val_accuracy: 0.7091\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4622 - accuracy: 0.7842 - val_loss: 0.5791 - val_accuracy: 0.7273\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4686 - accuracy: 0.8077 - val_loss: 0.5759 - val_accuracy: 0.7091\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4624 - accuracy: 0.7628 - val_loss: 0.5772 - val_accuracy: 0.7091\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4583 - accuracy: 0.8013 - val_loss: 0.5857 - val_accuracy: 0.7273\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4528 - accuracy: 0.7885 - val_loss: 0.5868 - val_accuracy: 0.7273\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4586 - accuracy: 0.7885 - val_loss: 0.5877 - val_accuracy: 0.7273\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4466 - accuracy: 0.8034 - val_loss: 0.5826 - val_accuracy: 0.7273\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4581 - accuracy: 0.7927 - val_loss: 0.5968 - val_accuracy: 0.7273\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4580 - accuracy: 0.7927 - val_loss: 0.5930 - val_accuracy: 0.7273\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4519 - accuracy: 0.7927 - val_loss: 0.5880 - val_accuracy: 0.7091\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4563 - accuracy: 0.7970 - val_loss: 0.5959 - val_accuracy: 0.7273\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4507 - accuracy: 0.7863 - val_loss: 0.5856 - val_accuracy: 0.7091\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4535 - accuracy: 0.7906 - val_loss: 0.5990 - val_accuracy: 0.7273\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4467 - accuracy: 0.7885 - val_loss: 0.5928 - val_accuracy: 0.7273\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4387 - accuracy: 0.8034 - val_loss: 0.5899 - val_accuracy: 0.7091\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4278 - accuracy: 0.8184 - val_loss: 0.5960 - val_accuracy: 0.7273\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4336 - accuracy: 0.8077 - val_loss: 0.5899 - val_accuracy: 0.7091\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4392 - accuracy: 0.8077 - val_loss: 0.6028 - val_accuracy: 0.7273\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4414 - accuracy: 0.8120 - val_loss: 0.6022 - val_accuracy: 0.7273\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4504 - accuracy: 0.7949 - val_loss: 0.5862 - val_accuracy: 0.7273\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4377 - accuracy: 0.8120 - val_loss: 0.5916 - val_accuracy: 0.7091\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4274 - accuracy: 0.8291 - val_loss: 0.5911 - val_accuracy: 0.7091\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4221 - accuracy: 0.8141 - val_loss: 0.5991 - val_accuracy: 0.7091\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4307 - accuracy: 0.8205 - val_loss: 0.5973 - val_accuracy: 0.7091\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4211 - accuracy: 0.8056 - val_loss: 0.5974 - val_accuracy: 0.7091\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4264 - accuracy: 0.8098 - val_loss: 0.6036 - val_accuracy: 0.7091\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4162 - accuracy: 0.8226 - val_loss: 0.5967 - val_accuracy: 0.7273\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4167 - accuracy: 0.8120 - val_loss: 0.6110 - val_accuracy: 0.7273\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4142 - accuracy: 0.8141 - val_loss: 0.6046 - val_accuracy: 0.7091\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4156 - accuracy: 0.8184 - val_loss: 0.6091 - val_accuracy: 0.7091\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4207 - accuracy: 0.8077 - val_loss: 0.6100 - val_accuracy: 0.7091\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4086 - accuracy: 0.8205 - val_loss: 0.6046 - val_accuracy: 0.7091\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4015 - accuracy: 0.8376 - val_loss: 0.6114 - val_accuracy: 0.7091\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4061 - accuracy: 0.8355 - val_loss: 0.6092 - val_accuracy: 0.7091\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3963 - accuracy: 0.8291 - val_loss: 0.6110 - val_accuracy: 0.7091\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4040 - accuracy: 0.8205 - val_loss: 0.6181 - val_accuracy: 0.7091\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4054 - accuracy: 0.8248 - val_loss: 0.6113 - val_accuracy: 0.7091\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4105 - accuracy: 0.8269 - val_loss: 0.6088 - val_accuracy: 0.7273\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4013 - accuracy: 0.8248 - val_loss: 0.6172 - val_accuracy: 0.7091\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3963 - accuracy: 0.8205 - val_loss: 0.6215 - val_accuracy: 0.7091\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3855 - accuracy: 0.8376 - val_loss: 0.6208 - val_accuracy: 0.7091\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3917 - accuracy: 0.8205 - val_loss: 0.6154 - val_accuracy: 0.6545\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3882 - accuracy: 0.8333 - val_loss: 0.6211 - val_accuracy: 0.7091\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3825 - accuracy: 0.8590 - val_loss: 0.6232 - val_accuracy: 0.7091\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3802 - accuracy: 0.8291 - val_loss: 0.6291 - val_accuracy: 0.6909\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3924 - accuracy: 0.8312 - val_loss: 0.6318 - val_accuracy: 0.6727\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3842 - accuracy: 0.8504 - val_loss: 0.6330 - val_accuracy: 0.7091\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3818 - accuracy: 0.8226 - val_loss: 0.6286 - val_accuracy: 0.6545\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3743 - accuracy: 0.8397 - val_loss: 0.6383 - val_accuracy: 0.6909\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3809 - accuracy: 0.8440 - val_loss: 0.6491 - val_accuracy: 0.7091\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3820 - accuracy: 0.8312 - val_loss: 0.6301 - val_accuracy: 0.6727\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3772 - accuracy: 0.8440 - val_loss: 0.6437 - val_accuracy: 0.7091\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3701 - accuracy: 0.8547 - val_loss: 0.6362 - val_accuracy: 0.6545\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3698 - accuracy: 0.8312 - val_loss: 0.6672 - val_accuracy: 0.7091\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3863 - accuracy: 0.8333 - val_loss: 0.6430 - val_accuracy: 0.6545\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3705 - accuracy: 0.8419 - val_loss: 0.6539 - val_accuracy: 0.7091\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3697 - accuracy: 0.8419 - val_loss: 0.6452 - val_accuracy: 0.6364\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3728 - accuracy: 0.8291 - val_loss: 0.6468 - val_accuracy: 0.6727\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3535 - accuracy: 0.8526 - val_loss: 0.6600 - val_accuracy: 0.7091\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3630 - accuracy: 0.8483 - val_loss: 0.6537 - val_accuracy: 0.6545\n",
      "Epoch 144/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3630 - accuracy: 0.8504 - val_loss: 0.6740 - val_accuracy: 0.6909\n",
      "Epoch 145/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3524 - accuracy: 0.8547 - val_loss: 0.6558 - val_accuracy: 0.6364\n",
      "Epoch 146/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3528 - accuracy: 0.8504 - val_loss: 0.6682 - val_accuracy: 0.7091\n",
      "Epoch 147/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3439 - accuracy: 0.8654 - val_loss: 0.6726 - val_accuracy: 0.6909\n",
      "Epoch 148/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3486 - accuracy: 0.8590 - val_loss: 0.6658 - val_accuracy: 0.6545\n",
      "Epoch 149/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3652 - accuracy: 0.8376 - val_loss: 0.6731 - val_accuracy: 0.7091\n",
      "Epoch 150/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3460 - accuracy: 0.8654 - val_loss: 0.6700 - val_accuracy: 0.6727\n",
      "Epoch 151/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3489 - accuracy: 0.8397 - val_loss: 0.6694 - val_accuracy: 0.6545\n",
      "Epoch 152/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3460 - accuracy: 0.8654 - val_loss: 0.6829 - val_accuracy: 0.7091\n",
      "Epoch 153/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3357 - accuracy: 0.8675 - val_loss: 0.6906 - val_accuracy: 0.6909\n",
      "Epoch 154/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3430 - accuracy: 0.8718 - val_loss: 0.6763 - val_accuracy: 0.6364\n",
      "Epoch 155/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3318 - accuracy: 0.8718 - val_loss: 0.6908 - val_accuracy: 0.7091\n",
      "Epoch 156/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3343 - accuracy: 0.8632 - val_loss: 0.6855 - val_accuracy: 0.6727\n",
      "Epoch 157/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3366 - accuracy: 0.8568 - val_loss: 0.6903 - val_accuracy: 0.6909\n",
      "Epoch 158/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3366 - accuracy: 0.8632 - val_loss: 0.6875 - val_accuracy: 0.6364\n",
      "Epoch 159/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3350 - accuracy: 0.8568 - val_loss: 0.6882 - val_accuracy: 0.6364\n",
      "Epoch 160/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3269 - accuracy: 0.8590 - val_loss: 0.6975 - val_accuracy: 0.6727\n",
      "Epoch 161/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3154 - accuracy: 0.8868 - val_loss: 0.7121 - val_accuracy: 0.6909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ec73a3310>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_1.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f78b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5836 - accuracy: 0.6923\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5722 - accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "m1_eval_test = model_1.evaluate(X_test, y_test)\n",
    "m1_eval_val = model_1.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c5bd1d",
   "metadata": {},
   "source": [
    "**Summary statistics and confusion matrix for test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27541cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "roc auc score:  0.618421052631579\n",
      "average precision score:  0.5975977123679015\n"
     ]
    }
   ],
   "source": [
    "pred = model_1.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4040638",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92836149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5836 - accuracy: 0.6923\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAFACAYAAACRGuaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArhklEQVR4nO3dd7wcVd3H8c/33iQkhAQICRgEglSNSIICUqQjIr1IkyaiEYGHrlQVUB8VBOklGCC0UKQjSpSWUIRQQhIIxQdDkUiLkEIoSX7PH3MubC637N67s3eW+33nNa/snJk552y5vz175swZRQRmZlY8DV1dATMza5kDtJlZQTlAm5kVlAO0mVlBOUCbmRWUA7SZWUE5QFeRpJMlXdXV9ciDpJ0lvSJptqS1OpHP05I2rV7Nak/SRpKey7mM2ZJWamP7NElblpnX9yQ9UOa+Hf4Mf5Y//12lWwZoSd+Q9JCkdyXNkPSgpHW6ul6dJWmwpFGSpkuaJelZSadI6luF7H8PHBoRi0XEkx3NJCK+HBH3VaE+C5F0n6SQNKxZ+i0pfdMy8wlJq7S1T0SMj4jVO17b9qXX+cVUp8sl/SrP8qyYul2AltQfuAM4FxgAfB44BfigK+vVnKTGCvcfADwM9AHWj4h+wDeBJYCVq1ClIcDTVcgnT88D+zWtSFoKWA94s1oFSOpRrbzM2tPtAjSwGkBEjImI+RExNyLGRsSkph0kfV/SVEn/lXSXpCEl285OP/VnSnpc0kbN8u8t6brUgn2itEUn6UuppfdO+qm/Q8m2yyVdKOlOSXOAzdLP2GMkTUqt/esk9W7leR0FzAL2iYhp6Tm+EhGHNz03SRtImpDymiBpg5Ly75P0y/RrYpaksZIGSlpE0mygEXhK0v+l/RdqaZa28tJxd6TnOUPSeEkNadvHP81T3mdJei0tZ0laJG3bVNKrko6W9Eb6VXBAO+/t1cAeJV9uewE3Ax+W1HNdSQ+nuk2XdJ6kXmnbuLTbU6mLYY+Sehwr6T/AZU1p6ZiV03P8alpfVtJbLbXYJR0g6faS9X9Kur5k/RVJw0tfX0kjgL2Bn6Y63V6S5fAyPxvN69GZz/Cykm6U9Kakf0k6rJUyeku6StLb6bWeIGmZcupnn+iOAfp5YL6k0ZK+LWnJ0o2SdgJOAHYBBgHjgTElu0wAhpO1vq8Bbmj2h7EjcEPJ9lsk9ZTUE7gdGAssDfwPcLWk0p/K3wV+DfQDmvoMdwe2Br4ArAl8r5XntSVwU0QsaGmjshb2n4FzgKWAM4E/K2tllpZ/QKpfL+CYiPggIhZL24dFRDmt8aOBV8lev2XIXs+W5hQ4kayFOxwYBqwLnFSy/XPA4mS/cg4Ezm/+fjXzGvAMsFVa3w+4otk+84EjgYHA+sAWwMEAEbFx2mdY6mK4rqQeA8h+RYwozSwi/g84luy9XBS4DLi8lW6c+4GNJDVIGgz0BDYEUNbfvBgwqfSAiBhJ9sVzWqrT9iWby/1sNNfRz3AD2Wf4KbL3ZAvgCEnfaqGM/cneu+XJPm8HAXPLrJ8l3S5AR8RM4BtkAeMS4E1Jt5V8u/8I+E1ETI2IecD/krVUhqTjr4qItyNiXkScASwClAbZxyPiTxHxEVkQ7E0WhNYj+wP8bUR8GBH3kHW17FVy7K0R8WBELIiI91PaORHxWkTMIPvjGN7KU1sKmN7GU98WeCEirkx1HwM8C5T+wV8WEc9HxFzg+jbKas9HwGBgSER8lPpsWwrQewOnRsQbEfEmWVfTvs3yOTXlcScwm4Vf65ZcAeyXvviWiIiHSzdGxOMR8Y/0GkwDLgY2aSfPBcAv0pfVp4JMRFwCvAA8kp73iS1lkvqUZ5G9rpsAdwH/lvTFtD6+tS/YVpT72Whej45+htcBBkXEqekz/CLZ39CeLRTzEdlncpX0S/Xx9LdnFeh2ARogBd/vRcRywBrAssBZafMQ4Oz0s+wdYAYgshYD6Sf31PSz8h2yVsLAkuxfKSlnAVlLctm0vNLsD/ClpnybH1viPyWP3yML8i15myw4tGbZVF6p5uWXW1Z7Tgf+CYyV9KKk48qs00sprcnb6UuykjrdBGxO9gvlyuYbJa2Wul/+I2km2RfwwOb7NfNmyRdmay4h+yydGxFtnc+4H9gU2Dg9vo8sOG+S1ivRoferE5/hIcCyTX8b6dgTyH4lNXcl2RfQtan76rT0K9Iq0C0DdKmIeBa4nOyPC7IP548iYomSpU9EPJT66o4l+2m5ZEQsAbxLFsCbLN/0IP0kXI7sp/drwPJNfbHJCsC/S6vTiafyd2DnZvmXeo3sD6xU8/Ir8R6waMn655oeRMSsiDg6IlYia6EfJWmLMuq0QkrrsIh4D/gL8GNaCNDAhWS/HFaNiP5kAUYt7LdQtm1tlLQY2Rf8KODk1J3UmqYAvVF6fD/tB+iqTTnZyc/wK8C/mv1t9IuIbT5V4exXzykRMRTYANiOkhO4Vp5uF6AlfTG1IJZL68uTdTP8I+1yEXC8pC+n7YtL2i1t6wfMIxsV0EPSz4H+zYr4mqRdlJ3tP4JsdMg/yH7+ziE72dMznUTaHri2Sk/tzFSX0U3dMZI+L+lMSWsCdwKrSfqupB6S9gCGknWzdMRE4LuSGiVtTUk3gaTt0gkuATPJ+n3nt5DHGOAkSYMkDQR+DlRjHO0JwCZNJ0ub6ZfqNDt1Lfy42fbXgVbHH7fibLJugR+Q9fNf1Ma+9wObAX0i4lWycxxbk3UHtDZ8sSN1ak1nPsOPAjOVnTDtk977NdTCEFVJm0n6irITtjPJujxa+gxYG7pdgCbrA/w68Iiy0RL/AKaQndgiIm4Gfkf202xm2vbtdOxdZK2z58l+jr/Pp7slbgX2AP5L1p+6S2pNfAjskPJ6C7gA2C+14Dst9UNuQPaH8IikWcDdZK2jf0bE22StmKPJukN+CmwXEW91sMjDyb5g3iHrS76lZNuqZC362WRD/y5o5aTZr4DHyE6MTQaeSGmdkvplW7sw4xiyk6GzyLolrmu2/WSyL7l3JO3eXlmSdiQLsAelpKOAr0rau5W6PU/2uoxP6zOBF4EHI6K1ADYKGJrqdEt7dWpHZz7D88ne8+HAv8g+x38k6yJp7nPAn8iC81SyLyZfxFIhtXzuxszMulp3bEGbmdUFB2gzs4JygDYzKygHaDOzgnKANjMrKAdoM7OCcoA2MysoB2gzs4JygDYzKygHaDOzgnKANjMrKAdoM7OCcoA2MysoB2gzs4JygDYzKygHaDOzgnKANjMrKAdoM7OCcoA2MysoB2gzs4JygDYzKygHaDOzgnKANjMrKAdoM7OCcoA2MysoB2gzs4JygDYzKygHaDOzgnKANjMrKAdoM7OCcoA2MysoB2gzs4JygDYzKygHaDOzgnKANjMrqB5dXYHW9Fnr0OjqOljxvDzurK6ughXQoH491Nk8Kok5c588r9PllaOwAdrMrKYaGru6Bp/iAG1mBqDi9fg6QJuZAagmvRYVcYA2MwO3oM3MCsstaDOzgnIL2sysoDyKw8ysoNzFYWZWUO7iMDMrKLegzcwKyi1oM7OCcoA2MyuoRo/iMDMrJvdBm5kVlLs4zMwKyi1oM7OCKmALOrcaSWqQtEFe+ZuZVVVDY/lLGyT1lvSopKckPS3plJQ+QNLfJL2Q/l+y3SpV6al9SkQsAM7IK38zs6qSyl/a9gGweUQMA4YDW0taDzgOuDsiVgXuTuttyrtNP1bSrlIBO3fMzEqpofylDZGZnVZ7piWAHYHRKX00sFN7Vcq7D/oooC8wX9JcQGT1759zuWZmlaliO1JSI/A4sApwfkQ8ImmZiJgOEBHTJS3dXj65BuiI6Jdn/mZmVVPBSUJJI4ARJUkjI2Jk00pEzAeGS1oCuFnSGh2pUu6jOCTtAGycVu+LiDvyLtPMrGIVBOgUjEeWsd87ku4DtgZelzQ4tZ4HA2+0d3yufdCSfgscDjyTlsNTmplZsVRvFMeg1HJGUh9gS+BZ4DZg/7Tb/sCt7VUp7xb0NsDwNKIDSaOBJynj7KWZWU1Vrw96MDA69UM3ANdHxB2SHgaul3Qg8DKwW3sZ1eJClSWAGenx4jUoz8ysclW6UCUiJgFrtZD+NrBFJXnlHaB/Azwp6V6yERwbA8fnXKaZWeUKOBo471EcY1IH+TpkAfrYiPhPnmWamXVEES/XyPsk4YbAzIi4DegH/FTSkDzLNDPrCDWo7KVW8r6S8ELgPUnDgJ8ALwFX5FymmVnFJJW91EreAXpeRDRd4nhORJxN1pI2MyuUIgbovE8SzpJ0PLAPsHEadtIz5zLNzCrW7fqggT3IZnY6MJ0c/Dxwes5lmplVrFu2oIGzI2K+pNWALwJjci7TzKxyxWtA596CHgcsIunzZPOfHgBcnnOZZmYVa2hoKHupWZ1yzl8R8R6wC3BuROwMfDnnMs3MKtYduzgkaX1gb+DAlNb2TCNmZl2giCcJ8w7QR5Bd2n1zRDwtaSXg3pzLNDOrXPHic+6Xet8P3C+pb1p/ETgszzLNzDqiiC3ovC/1Xl/SM8DUtD5M0gV5lmlm1hFF7IPO+yThWcC3gLcBIuIpPrm7iplZYRRxLo7c54OOiFeafePMz7tMM7NKFbGLI+8A/YqkDYCQ1Ius/3lqzmWamVWsOwbog4CzyS7xfhUYCxySc5lmZhXrVgE6TYx0VkTsnVcZZmbV0q0CdJp/Y5CkXhHxYV7lmJlVQy1P/pUr7y6OacCDkm4D5jQlRsSZOZdrZlaRbtWCTl5LSwOeqN/MCqzbBeiIOCXP/M3MqqZ48TnfAC3pdiCaJb8LPAZcHBHv51l+PVqkVw/+PuoIevXqQY/GRm7++5P86qI7+fnB27LdJmuyIII3Z8xixC+uYvqb73Z1da2LfGf7b7Loon1paGygsbEHo668vqurVPe6XQsaeBEYxCeT9O8BvA6sBlwC7Jtz+XXngw/nsfWIc5gz90N69GjgnkuPYuyDz/CH0Xdz6gV/BuDgvTbh+BHf5rBfX9vFtbWudM7Fl7HEEkt2dTU+M7pjgF4rIkov7b5d0riI2FjS0zmXXbfmzM0GvfTs0UiPHo1EBLPmfPJjY9E+i5Ddi9fMqqWWE/GXK+8APUjSChHxMoCkFYCBaZuH3rWioUE8dM2xrLz8IC6+bhwTprwEwMmHbM/e263Lu7PnsvWIc7q4ltaVJHHUIT8EiR132Y0dd9m9q6tU/4rXgM59sqSjgQck3SvpPmA88JM0/ejo5jtLGiHpMUmPzXur+zawFywI1tvzt6zyrZNYe40hDF15MAAnn387q377Z1z7l8c4aA/POdWdXTjqKi69+k+ccc5F3HTDGCY+8VhXV6nuVWs2O0nLp5g3VdLTkg5P6SdL+rekiWnZpr065RqgI+JOYFWyifuPAFaPiD9HxJyIOKuF/UdGxNoRsXaPgb4z1ruz5zLusRfYaoOhC6Vf/5cJ7LTF8K6plBXCwEFLA7DkgKXYeNMteebpyV1co/pXxelG5wFHR8SXgPWAQyQ1/RH/ISKGp+XO9jLKez7onsCPgJ8BJwE/SGnWioFLLsbii/UBoPciPdn866vz3LTXWXmFQR/vs+0ma/L8tNe7qorWxebOfY/35sz5+PGERx5ipZVX6eJa1T+p/KUtETE9Ip5Ij2eRTRD3+Y7UKe8+6AuBnkDTJP37prQf5Fxu3frcwP5ccuq+NDY00NAgbvzbE/xl/BTG/P4HrDpkaRYsCF6ePsMjOLqxGW+/zQk/yW5MNH/+fL75rW1Zb4ONurhW9S+PURySVgTWAh4BNgQOlbQf2VDjoyPiv20en+doAElPRcSw9tJa0metQz1MwT7l5XFndXUVrIAG9evR6ei6+rF3lR1znj9t6x8BI0qSRkbEyNJ9JC0G3A/8OiJukrQM8BbZtSG/BAZHxPfbKifvFvR8SStHxP+lCq+EJ+w3swKqpAGdgvHI1ranrtwbgasj4qZ0zOsl2y8B7mivnLwD9DHAvZJeJBvEMgQ4IOcyzcwq1lCl2eyU9ZWMAqaWTgwnaXBETE+rOwNT2ssr7/mgh5GN4lidLEA/GxEf5FWmmVlHVbELekOy822TJU1MaScAe0kaTtbFMY1sAEWb8p4PeoeI+AMwKa9yzMyqoVonCSPiAVq+7KXdYXXN5d3F8ZCk84DrWHg+6CdyLtfMrCLV6uKoprwD9Abp/1NL0gLYPOdyzcwq0h0nS9otIt7KuQwzs04rYHzO50pCSdtLehOYJOlVSRu0e5CZWReq4qXeVZPXpd6/BjaKiGWBXYHf5FSOmVlVVOtS72rKq4tjXkQ8CxARj0jy/QjNrNC6Ux/00pKOam3dd/U2s6LpTqM4LmHhu3g3XzczK5QCNqDzCdC+m7eZ1ZsidnHU7CZcknxxipkVVnc6SdiS4n09mZklRWxB1zJA/7mGZZmZVaSA8bl2AToiTqpVWWZmlSriKI6870m4i6QXJL0raaakWZJm5lmmmVlHFPFKwrxb0KcB20fE1JzLMTPrlCL2QbfbgpZ0mqT+knpKulvSW5L2KTP/1x2czawe1Osojq0i4qeSdgZeBXYD7gWuKuPYxyRdB9wCfHwnlaZ7dJmZFUURW9DlBOie6f9tgDERMaOCJ9IfeA/YqiQtAAdoMyuUIp4kLCdA3y7pWWAucLCkQcD75WQeEb5BrJnVhQI2oNvvg46I44D1gbUj4iOyFvGO5WQuaTlJN0t6Q9Lrkm6UtFznqmxmVn0NUtlLzerU3g6SFgUOAS5MScsCa5eZ/2XAbemYzwO3pzQzs0Ip4knCcsZBXwZ8yCf3F3wV+FWZ+Q+KiMsiYl5aLgcGVV5NM7N8FXEcdDkBeuWIOA34CCAi5lL+vBpvSdpHUmNa9gHe7mBdzcxy06Dyl5rVqYx9PpTUh2z0BZJWpmTIXDu+D+wO/AeYDnwnpZmZFUpDg8peaqWcURy/AP4KLC/pamBD4HvlZB4RLwM7dLh2ZmY1ogJOuNlugI6Iv6W5nNcj69o4PCLeausYST9vO8v4ZWXVNDPLVwGHQbcfoCVtnB7OSv8PlUREjGvjsDktpPUFDgSWAhygzaxQ6vVKwp+UPO4NrAs8Dmze2gERcUbT43RH78OBA4BrgTNaO87MrKtUKz5LWh64AvgcsAAYGRFnSxoAXAesCEwDdo+I/7aVVzldHNu3UPhpZVRyAHAUsDcwGvhqe5UxM+sqjdXr45gHHB0RT6QG6uOS/kZ27u7uiPitpOOA44Bj28qoI9ONvgqs0dYOkk4HdgFGAl+JiNkdKMfMrGaq1cUREdPJRq0REbMkTSW7UG9HYNO022jgPjoboCWdSxpiRzYsbzjwVDuHHU02FO8k4MSSJ66sztG/vXLNzGopjy5oSSsCawGPAMuk4E1ETJe0dHvHl9OCfqzk8TyyGe0ebOuAiKjZ3cLNzKqhkjk2JI0ARpQkjYyIkc32WQy4ETgiImZ2pIVeTh/06IpzNTOrM5WEzxSMR7a2XVJPsuB8dcn8969LGpxaz4OBN9orp9UALWkyn3RtLLQpq1+s2V7mZmb1olp90MoyGgVMjYgzSzbdBuwP/Db9f2t7ebXVgt6uM5U0M6snVRzFsSGwLzBZ0sSUdgJZYL5e0oHAy2R3p2pTqwE6Il7qfD3NzOpDtU4SRsQDtN5jskUleZUzH/R6kiZImi3pQ0nzJc2spBAzs6Ir4nSj5YziOA/YE7iBbKL+/YBV8qyUmVmt1eVcHAAR8U9JjRExH7hM0kM518vMrKbqdS6O9yT1AiZKOo3sCpm++VbLzKy2ihee2+iDltR038F9036Hks1Stzywa/5VMzOrncYGlb3USlst6EvSlTBjgGsj4hnglNpUy8ystorYxdFqCzoi1iIbCz0f+JOkiZKOlTSkZrUzM6uRururd0Q8FxGnRMRQsitflgDukdTmXBxmZvWmQSp7qZWyRnFIagCWBpYhO0H4Zp6VMjOrtQL2cLQdoCVtBOwF7ARMIbsjypER8W7eFbvrulPzLsLqUL8+HZnC3Kx9jQWM0G1NlvQK2fXi1wKnRMTrNauVmVmNFfEkYVvNkW94Pg4z6y7q6kpCB2cz607qKkCbmXUn9dbFYWbWbdRVC7rZzWI/JSIOy6VGZmZdoJaXcJerrRb0Y21sMzP7TCnina7bOknom8WaWbdRwC7o9vugJQ0CjgWGAr2b0iNi8xzrZWZWU7W8hLtc5bTqrwamAl8gm81uGjAhxzqZmdVc3U2WlCwVEaOAjyLi/oj4PrBezvUyM6upBpW/1Eo5w+w+Sv9Pl7Qt8BqwXH5VMjOrvXobxdHkV5IWB44GzgX6A0fmWiszsxorYHxuP0BHxB3p4bvAZvlWx8ysa6iAdyUsZxTHZbRwwUrqizYz+0yoyxY0cEfJ497AzmT90GZmnxl1GaAj4sbSdUljgL/nViMzsy5QrycJm1sVWKHaFTEz60oFvE6l/XHQkmZJmtm0ALeTXVloZvaZUc2bxkq6VNIbkqaUpJ0s6d+SJqZlm/byKaeLo1+7tTEzq3NV7uG4HDgPuKJZ+h8i4vflZlJOC/ructLMzOpZNS/1johxwIzO1qnVAC2pt6QBwEBJS0oakJYVgWU7W7CZWZE0oLIXSSMkPVayjCizmEMlTUpdIEu2t3NbXRw/Ao4gC8aPw8ejuGcC55dZGTOzutBYwYTQETESGFlhERcCvyS7ruSXwBlAm9eTtDUf9NnA2ZL+JyLOrbAiZmZ1Je/pRiPi9abHki5h4WtMWq5TGfkukLREScZLSjq4QzU0MyuovKcblTS4ZHVnYEpr+zYpJ0D/MCLeaVqJiP8CP6y4dmZmBVblYXZjgIeB1SW9KulA4DRJkyVNIpvXqN1J58q5UKVBkiIiUsGNQK8yjjMzqxvV7OGIiL1aSB5VaT7lBOi7gOslXUTWuX0Q8NdKCzIzK7K6umlsiWOBEcCPyUZyjAUuybNSZma1Vpf3JIyIBRFxUUR8JyJ2BZ4mm7jfzOwzo5p90FWrUzk7SRou6XeSppGN33u2jGMaJV3VyfqZmdWEKlhqpdUuDkmrAXsCewFvA9cBioiy7qoSEfMlDZLUKyI+rEptzcxyUsAejjb7oJ8FxgPbR8Q/ASRVei/CacCDkm4D5jQlRsSZFeZjZpYrFTBCtxWgdyVrQd8r6a/AtVTeun8tLQ2AZ8Uzs8JqrKcAHRE3AzdL6gvsRDaoehlJFwI3R8TY9jKPiFMAJPXLVmN2VWptZlZlxQvP5Y3imBMRV0fEdsBywETguHIyl7SGpCfJLml8WtLjkr7cmQqbmeVBUtlLrVQ0NjsiZkTExRGxeZmHjASOioghETEEOBqPoTazAmqoYKmVjtyTsBJ9I+LeppWIuC91mZiZFUq9nSSshhcl/Qy4Mq3vA/wr5zLNzCpWvPCcf2v9+8Ag4CbgZmAgcEDOZZqZVaxRKnuplVxb0Glq0sPg41nw+kbEzDzLNDPriAL2cOTbgpZ0jaT+qd/5aeA5ST/Js0wzs45QBf9qJe8ujqGpxbwTcCewArBvzmWamVUs7zuqdETeAbqnpJ5kAfrWiPiIbE5pM7NCqeSu3rWS9yiOi8nm43gKGCdpCNldwc3MCqWhgDP2532S8BzgnJKklySVNRuemVkt1bJvuVx5nyQ8PJ0klKRRkp4Ayr0K0cysZhpU/lKzOuWc//fTScKtyMZDHwD8NucyzcwqVsRRHHn3QTc9k22AyyLiKRXxekoz6/aKGJnyDtCPSxoLfAE4Pk07uiDnMuva5Wf/ikkTHqLf4ktyyvlXA/DYA3dz2zWj+M+r0zjhjFGsuOqXuriW1pU++OADDthvbz768EPmzZ/PN7f6FgcfelhXV6vudbs+aOBAsqlJ14mI94Be+FLvNm2wxbYcfvIfFkr7/JCVOfiE37Dql4d3TaWsUHr16sUfLx3NDTffxvU33sKDD4xn0lMTu7pada+Il3rnHaADGEq63BvoC/TOucy6ttoaa9G3X/+F0gYvvyKfW25IF9XIikYSi/bNJoWcN28e8+bNK+bv8zrTHS9UuQBYn+zGswCzgPNzLtPsM2/+/PnsvsuObLbRBqy3/gasueawrq5S3SviXb3zDtBfj4hDgPfh48mTeuVcptlnXmNjI9ffdCtj77mfKZMn8cILz3d1lepeg1T2UrM65Zz/R2kWuwCQNIg2ThJKGiHpMUmP3Xbd6JyrZlb/+vfvzzrrfp2HHhjf1VWpe9VsQUu6VNIbkqaUpA2Q9DdJL6T/l2wvn7wD9Dlk80AvLenXwAPA/7a2c0SMjIi1I2LtHfbYP+eqmdWnGTNmMHNmNmPC+++/zz8efogVv7BSF9fqM6C6fRyXA1s3SzsOuDsiVgXupox7uyoin7mLJDUA6wEzgC3IntbdETG1nOPHPT+jW06qNPL0n/P85CeYPfMd+i0xgB2++wP69uvPmIvPZPa779BnscVY/gurceSpZ3V1VbvEuisN6OoqdLnnn3uWk044jgUL5rNgQbDVt7bmoIMP7epqdanePTrfNfzoi++WHXPWXWnxdsuTtCJwR0SskdafAzaNiOmSBgP3RcTqbeaRV4BOFXo4ItbvyLHdNUBb2xygrSXVCNATKgnQKy/xI2BESdLIiBhZuk8LAfqdiFiiZPt/I6LNbo68L1QZK2lX4KbI85vAzKyzKgjxKRiPbHfHTso7QB9FNvZ5nqT3yV6CiIj+bR9mZlZbNbiS8HVJg0u6ON5o74BcTxJGRL+IaIiIXhHRP607OJtZ4dTgQpXbgKbRD/sDt7Z3QK4taElfbSH5XeCliJiXZ9lmZpWo5vBmSWOATYGBkl4FfkE2k+f1kg4EXgZ2ay+fvLs4LgC+CkxO618hu7vKUpIOioixOZdvZlaWanZxRMRerWzaopJ88h4HPQ1YKyK+FhFfA4YDU4AtgdNyLtvMrGxFnIsj7xb0FyPi6aaViHhG0loR8aKnhTazIiliRMo7QD8n6ULg2rS+B/C8pEWAj3Iu28ysfAWM0HkH6O8BBwNHkD39B4BjyIKzbx5rZoVRxAn7876r91xJ5wJjySZMei4imlrOs/Ms28ysErW8GWy58h5mtykwmuxkoYDlJe0fEePyLNfMrGLdLUADZwBbRcRzAJJWA8YAX8u5XDOzinS7Lg6gZ1NwBoiI5yX1zLlMM7OKFXFgWS3u6j0KuDKt7w08nnOZZmYVK2B8zj1AHwQcQnbTWAHjyK4uNDMrlgJG6NwCdJqw//E0F+qZeZVjZlYNtbzXYLlyu9Q7IhYAT0laIa8yzMyqpYh39c67i2Mw8LSkR4E5TYkRsUPO5ZqZVaZ4DejcA/QpOedvZlYV3WaYnaTeZCcIVyGbanSU5382syIrYBd0bi3o0WTzbYwHvg0MBQ7PqSwzs07rTgF6aER8BSCNg340p3LMzKqi23RxUDKVaETM89zPZlZ0RQxTeQXoYZJmpscC+qR139XbzAqpgPE5nwAdEY155GtmlpsCRui8h9mZmdWF7tQHbWZWV7rdhP1mZvWiO50kNDOrM8WL0A7QZma4BW1mVlgFjM8O0GZm4Ba0mVlhVfOKZ0nTgFnAfGBeRKzdkXwcoM3MyKWLY7OIeKszGThAm5lRzC6O3G55ZWZWT1TBvzIEMFbS45JGdLRObkGbmUFFfRwp6JYG3pERMbJkfcOIeE3S0sDfJD0bEeMqrZIDtJkZlV3qnYLxyDa2v5b+f0PSzcC6QMUB2l0cZmZUr4tDUl9J/ZoeA1sBUzpSJ7egzcyo6knCZYCb07C9HsA1EfHXjmTkAG1mVkUR8SIwrBp5OUCbmVHMYXYO0GZmeMJ+M7PC8oT9ZmZF5QBtZlZM7uIwMysonyQ0MyuoAsZnB2gzM6CQEdoB2swMaChgH4cioqvrYO2QNKLZTFlm/lx0A54sqT50eD5Z+0zz5+IzzgHazKygHKDNzArKAbo+uJ/RWuLPxWecTxKamRWUW9BmZgXlAG1mVlAO0M1ICklnlKwfI+nkKuV9sqR/S5ooaYqkHaqRrxWPpPkl7/MNkhbt6jpZ/XGA/rQPgF0kDcwp/z9ExHBgN+BSSQu9B5I6dXVnZ4+vsKzGWpVVh+ZGxPCIWAP4EDiodGM1Xrtavf61/EzZwhygP20e2dnxI5tvkDRE0t2SJqX/V0jpl0s6R9JDkl6U9J32ComIqamsgZLuk/S/ku4HDpe0haQnJU2WdKmkRVI520h6VtIDqbw7UvrJkkZKGgtcIWmQpBslTUjLhmm/TVKrbmLKv5+kwZLGlbT2Nkr77pXKnyLpdyWvwWxJp0p6BFi/k691dzEeWEXSppLulXQNMFlSb0mXpdf5SUmbAUhaVNL16XN2naRHJK2dti30+kvaR9Kj6f27WFJjWi5P791kSUemYw+T9EzK99qUNkDSLSntH5LWTOkLfaa64kUzICK8lCzAbKA/MA1YHDgGODltux3YPz3+PnBLenw5cAPZF95Q4J+t5H0ycEx6/HXgNbIpWu4DLkjpvYFXgNXS+hXAESXpX0jpY4A7SvJ9HOiT1q8BvpEerwBMLan/hunxYmRzsRwNnJjSGoF+wLLAy8CgtM89wE5pnwB27+r3qegLMDv93wO4FfgxsCkwp+Q9PBq4LD3+YnrNe6fP3MUpfQ2yL/K1m7/+wJfSe9ozrV8A7Ad8DfhbSV2WSP+/BizSLO1c4Bfp8ebAxJY+U166ZnELugURMZMsMB7WbNP6ZMEP4ErgGyXbbomIBRHxDNlt11tzpKSJwO+BPSL9NQDXpf9XB/4VEc+n9dHAxmR/wC9GxL9S+phm+d4WEXPT4y2B81I5twH9JfUDHgTOlHQY2R/oPGACcEDqZ/9KRMwC1gHui4g30z5XpzoAzAdubOP5WaZPev0fIwu8o1L6oyXv4TfIPkdExLPAS8BqKf3alD4FmFSSb+nrvwVZMJ6QytoCWAl4EVhJ0rmStgZmpv0nAVdL2ocs6Devwz3AUpIWT9tKP1PWBdy31LqzgCeAy9rYp3QQ+QcljwUg6dfAtgCR9TtD1gf9+xbymlN6bAvam2prTsnjBmD9Fv64fivpz8A2wD8kbRkR4yRtnOp5paTT+eQPuiXvR8T8dupiqQ+6NEHZbGml71NH3uvS11/A6Ig4/lMZSMOAbwGHALuT/eLbluyLdgfgZ5K+3EpZTZ/rOS1ssxpyC7oVETEDuB44sCT5IWDP9Hhv4IF28jgxshNFwyso+llgRUmrpPV9gftT+kqSVkzpe7SRx1jg0KYVScPT/ytHxOSI+B1Zy+6LkoYAb0TEJWStvK8CjwCbSBqYTkTtlepg1TWO7HOEpNXIuqOeI/tc7Z7ShwJfaeX4u4HvSFo67TsgnScZCDRExI3Az4CvppPRy0fEvcBPgSXIurlK67Ap8Fb6BWkF4BZ0286gJNCRdXlcKuknwJvAAdUuMCLel3QAcEM6ez4BuCgiPpB0MPBXSW8Bj7aRzWHA+ZImkb3H48hGERyRTkTNB54B/kL2hfMTSR+R9b/vFxHTJR0P3EvWwrozIm6t9nM1LgAukjSZrMvhe+l9vgAYnd6/J8m6Jt5tfnBEPCPpJGBsCsAfkbWY5wKX6ZMRQseTnV+4KnVfiOyX3Dupa+uyVNZ7wP45Pl+rkC/1riOSFouI2cp+K58PvBARf+jqell1pV8tPdOX9cpkLeXVIuLDLq6a1Zhb0PXlh5L2B3qRtawu7uL6WD4WBe6V1JOstftjB+fuyS1oM7OC8klCM7OCcoA2MysoB2gzs4JygDYzKygHaDOzgnKANjMrKAdoM7OCcoA2MysoB2gzs4JygDYzKygHaDOzgnKANjMrKAdoM7OCcoA2MysoB2hbiKT5kiZKmiLpBkmLdiKvyyV9Jz3+Y7p9U2v7bippgw6UMS3d4ql5uT9qlraTpDvLqatZUThAW3Nz030U1wA+JLtV1sfS3T4qFhE/SHc8b82mQMUBuhVj+OTekU325NN3QjcrNAdoa8t4YJXUur1X0jXAZEmNkk6XNEHSpKbWqjLnSXom3T186aaMJN0nae30eGtJT0h6StLd6Ua4BwFHptb7RpIGSboxlTFB0obp2KUkjZX0pKSLafmu1H8nuyHu4HTMosCWwC2Sfp7ymyJpZLp92EJKW+WS1pZ0X3rcV9Kl6fgnJe2Y0r8s6dFU90mSVq3Gi2/mAG0tSjes/TYwOSWtC5wYEUPJ7nT+bkSsA6xDdiuuLwA7A6uT3YX6h7TQIpY0CLgE2DUihgG7RcQ04CKyG5kOj4jxwNlpfR1gV+CPKYtfAA9ExFrAbWR3wl5IRMwHbiLdGRvYAbg3ImYB50XEOukXQh9guwpelhOBe1KdNgNOl9SX7Mvl7HT39rWBVyvI06xVviehNddH0sT0eDwwiizQPhoR/0rpWwFrlvTZLg6sCmwMjEkB8jVJ97SQ/3rAuKa8ImJGK/XYEhha0sDtL6lfKmOXdOyfJf23lePHAKeTBfo9gStS+maSfkp2378BwNPA7a3k0dxWwA6Sjknrvcm+IB4GTpS0HHBTRLxQZn5mbXKAtubmppbgx1KQnFOaBPxPRNzVbL9tgPZucqky9oHs1936ETG3hbqUc/yDwGBJw8i+YPaU1Bu4AFg7Il6RdDJZkG1uHp/8uizdLrKW/3PN9p8q6RFgW+AuST+IiJa+nMwq4i4O64i7gB+nu04jabX0U38cWSBsTP2/m7Vw7MPAJqlLBEkDUvosoF/JfmOBQ5tWJA1PD8cBe6e0bwNLtlTByO6GfD0wGrgzIt7nk2D7lqTFgNZGbUwDvpYe79rsef9PU7+1pLXS/ysBL0bEOWTdLmu2kq9ZRRygrSP+CDwDPCFpCnAx2a+xm4EXyPqtLwTub35gRLwJjABukvQUcF3adDuwc9NJQuAwYO100u0ZPhlNcgqwsaQnyLocXm6jnmOAYcC1qex3yPq/JwO3ABNaOe4U4GxJ44H5Jem/BHoCk9Lz/mVK3wOYkrqGvsgn3SlmnaKsoWFmZkXjFrSZWUE5QJuZFZQDtJlZQTlAm5kVlAO0mVlBOUCbmRWUA7SZWUE5QJuZFdT/A/AEN+t+aHo+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_1.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea5cfb9",
   "metadata": {},
   "source": [
    "**Summary statistics and confusion matrix for validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df712689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "roc auc score:  0.6811145510835913\n",
      "average precision score:  0.6596416235922022\n"
     ]
    }
   ],
   "source": [
    "pred = model_1.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a8e5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "373c1df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5722 - accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels (validation set)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_1.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835223b6",
   "metadata": {},
   "source": [
    "### 1.2 CNN model with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d35c3248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_progressor = np.array(y_train)[:,1]\n",
    "y_progressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6f24785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 768)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2d = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]))\n",
    "X_train_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32ecf159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(662, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy = 'minority')\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train_2d, y_progressor)\n",
    "print(X_train_over.shape)\n",
    "y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6964304a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>662 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1\n",
       "0    1  0\n",
       "1    0  1\n",
       "2    1  0\n",
       "3    1  0\n",
       "4    1  0\n",
       "..  .. ..\n",
       "657  0  1\n",
       "658  0  1\n",
       "659  0  1\n",
       "660  0  1\n",
       "661  0  1\n",
       "\n",
       "[662 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_over = pd.get_dummies(y_train_over)\n",
    "y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6ad614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Progressor  Progressor\n",
      "0               1             331\n",
      "1               0             331\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_over=y_train_over.rename(columns={0: \"Non-Progressor\", 1: \"Progressor\"})\n",
    "print(y_train_over.value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eed5ab14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Progressor  Progressor\n",
      "1               0             331\n",
      "0               1             137\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71c5af9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.12335958],\n",
       "        [0.12335958],\n",
       "        [0.12073491],\n",
       "        ...,\n",
       "        [0.12598425],\n",
       "        [0.12598425],\n",
       "        [0.12335958]],\n",
       "\n",
       "       [[0.18372703],\n",
       "        [0.18635171],\n",
       "        [0.18897638],\n",
       "        ...,\n",
       "        [0.17322835],\n",
       "        [0.17585302],\n",
       "        [0.18110236]],\n",
       "\n",
       "       [[0.11548556],\n",
       "        [0.11811024],\n",
       "        [0.11811024],\n",
       "        ...,\n",
       "        [0.11811024],\n",
       "        [0.11811024],\n",
       "        [0.11548556]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.14435696],\n",
       "        [0.14698163],\n",
       "        [0.14698163],\n",
       "        ...,\n",
       "        [0.14698163],\n",
       "        [0.14698163],\n",
       "        [0.14435696]],\n",
       "\n",
       "       [[0.16272966],\n",
       "        [0.16535433],\n",
       "        [0.167979  ],\n",
       "        ...,\n",
       "        [0.15485564],\n",
       "        [0.15748031],\n",
       "        [0.16010499]],\n",
       "\n",
       "       [[0.16010499],\n",
       "        [0.15748031],\n",
       "        [0.15485564],\n",
       "        ...,\n",
       "        [0.16535433],\n",
       "        [0.16272966],\n",
       "        [0.16272966]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over = np.reshape(X_train_over, (X_train_over.shape[0], X_train_over.shape[1], 1))\n",
    "X_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca28a69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 766, 64)           256       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 255, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 255, 64)           0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 16320)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                1044544   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,045,874\n",
      "Trainable params: 1,045,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model2\n",
    "model_2 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_2.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_2.add(MaxPooling1D(pool_size=3))\n",
    "# model_1.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "# model_1.add(MaxPooling1D(pool_size=2))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(64, activation='relu'))\n",
    "model_2.add(Dense(16, activation='relu'))\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12e49a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=100,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09e532e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 32ms/step - loss: 0.6938 - accuracy: 0.4804 - val_loss: 0.6723 - val_accuracy: 0.6909\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6922 - accuracy: 0.5257 - val_loss: 0.6751 - val_accuracy: 0.6909\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.6892 - accuracy: 0.5060 - val_loss: 0.6705 - val_accuracy: 0.7091\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6876 - accuracy: 0.5211 - val_loss: 0.6630 - val_accuracy: 0.7273\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.6807 - accuracy: 0.6178 - val_loss: 0.7131 - val_accuracy: 0.3636\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6848 - accuracy: 0.5498 - val_loss: 0.7113 - val_accuracy: 0.4182\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.6766 - accuracy: 0.5906 - val_loss: 0.6755 - val_accuracy: 0.6000\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6690 - accuracy: 0.6073 - val_loss: 0.6586 - val_accuracy: 0.6364\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6672 - accuracy: 0.6208 - val_loss: 0.6489 - val_accuracy: 0.6545\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6570 - accuracy: 0.6224 - val_loss: 0.6421 - val_accuracy: 0.6545\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6605 - accuracy: 0.6239 - val_loss: 0.6170 - val_accuracy: 0.6909\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.6546 - accuracy: 0.6344 - val_loss: 0.6252 - val_accuracy: 0.6545\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6482 - accuracy: 0.6450 - val_loss: 0.6317 - val_accuracy: 0.6545\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6449 - accuracy: 0.6269 - val_loss: 0.6570 - val_accuracy: 0.6182\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6383 - accuracy: 0.6541 - val_loss: 0.5910 - val_accuracy: 0.7091\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6472 - accuracy: 0.6269 - val_loss: 0.6308 - val_accuracy: 0.6545\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.6348 - accuracy: 0.6495 - val_loss: 0.6312 - val_accuracy: 0.6545\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6341 - accuracy: 0.6526 - val_loss: 0.6579 - val_accuracy: 0.6000\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6328 - accuracy: 0.6586 - val_loss: 0.6384 - val_accuracy: 0.6182\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6250 - accuracy: 0.6631 - val_loss: 0.6332 - val_accuracy: 0.6182\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6295 - accuracy: 0.6586 - val_loss: 0.6456 - val_accuracy: 0.6182\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6323 - accuracy: 0.6556 - val_loss: 0.6729 - val_accuracy: 0.5818\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6182 - accuracy: 0.6737 - val_loss: 0.6332 - val_accuracy: 0.6182\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6149 - accuracy: 0.6918 - val_loss: 0.7023 - val_accuracy: 0.5273\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6140 - accuracy: 0.6737 - val_loss: 0.5832 - val_accuracy: 0.6545\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6131 - accuracy: 0.6782 - val_loss: 0.6494 - val_accuracy: 0.6182\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6049 - accuracy: 0.6843 - val_loss: 0.6110 - val_accuracy: 0.6727\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6029 - accuracy: 0.6813 - val_loss: 0.6132 - val_accuracy: 0.6909\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5973 - accuracy: 0.7024 - val_loss: 0.6086 - val_accuracy: 0.6727\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5914 - accuracy: 0.7009 - val_loss: 0.6138 - val_accuracy: 0.6727\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5951 - accuracy: 0.6903 - val_loss: 0.6597 - val_accuracy: 0.6000\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5921 - accuracy: 0.6888 - val_loss: 0.6446 - val_accuracy: 0.6182\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5852 - accuracy: 0.7160 - val_loss: 0.5996 - val_accuracy: 0.6909\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5796 - accuracy: 0.7160 - val_loss: 0.6198 - val_accuracy: 0.6545\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5769 - accuracy: 0.7205 - val_loss: 0.6285 - val_accuracy: 0.6545\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5759 - accuracy: 0.7190 - val_loss: 0.6359 - val_accuracy: 0.6545\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5827 - accuracy: 0.7115 - val_loss: 0.6779 - val_accuracy: 0.5636\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.5783 - accuracy: 0.7009 - val_loss: 0.6500 - val_accuracy: 0.6182\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5670 - accuracy: 0.7356 - val_loss: 0.5891 - val_accuracy: 0.7273\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5628 - accuracy: 0.7341 - val_loss: 0.6416 - val_accuracy: 0.6545\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5646 - accuracy: 0.7266 - val_loss: 0.6607 - val_accuracy: 0.6182\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5522 - accuracy: 0.7341 - val_loss: 0.5985 - val_accuracy: 0.6545\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5560 - accuracy: 0.7387 - val_loss: 0.6088 - val_accuracy: 0.6364\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5576 - accuracy: 0.7387 - val_loss: 0.6299 - val_accuracy: 0.6364\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5447 - accuracy: 0.7644 - val_loss: 0.6454 - val_accuracy: 0.6182\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5401 - accuracy: 0.7508 - val_loss: 0.6089 - val_accuracy: 0.6545\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5335 - accuracy: 0.7613 - val_loss: 0.6452 - val_accuracy: 0.6364\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5353 - accuracy: 0.7613 - val_loss: 0.6412 - val_accuracy: 0.6364\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5315 - accuracy: 0.7538 - val_loss: 0.6201 - val_accuracy: 0.6909\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5244 - accuracy: 0.7704 - val_loss: 0.6189 - val_accuracy: 0.6909\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5252 - accuracy: 0.7628 - val_loss: 0.6071 - val_accuracy: 0.6909\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5189 - accuracy: 0.7719 - val_loss: 0.6375 - val_accuracy: 0.6727\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5117 - accuracy: 0.7644 - val_loss: 0.6105 - val_accuracy: 0.6909\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.5080 - accuracy: 0.7704 - val_loss: 0.6312 - val_accuracy: 0.6909\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5109 - accuracy: 0.7704 - val_loss: 0.6352 - val_accuracy: 0.6909\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5168 - accuracy: 0.7628 - val_loss: 0.6309 - val_accuracy: 0.6909\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5056 - accuracy: 0.7915 - val_loss: 0.6186 - val_accuracy: 0.6909\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5071 - accuracy: 0.7704 - val_loss: 0.6440 - val_accuracy: 0.6909\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4946 - accuracy: 0.7795 - val_loss: 0.6157 - val_accuracy: 0.6909\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4966 - accuracy: 0.7734 - val_loss: 0.6396 - val_accuracy: 0.6909\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4865 - accuracy: 0.7900 - val_loss: 0.6634 - val_accuracy: 0.6364\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4894 - accuracy: 0.7779 - val_loss: 0.6226 - val_accuracy: 0.6909\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4888 - accuracy: 0.7764 - val_loss: 0.6895 - val_accuracy: 0.6364\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4798 - accuracy: 0.8021 - val_loss: 0.6285 - val_accuracy: 0.6909\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4796 - accuracy: 0.7931 - val_loss: 0.6293 - val_accuracy: 0.6909\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4730 - accuracy: 0.7961 - val_loss: 0.6377 - val_accuracy: 0.6909\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.4670 - accuracy: 0.8006 - val_loss: 0.6492 - val_accuracy: 0.6909\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4673 - accuracy: 0.8066 - val_loss: 0.6339 - val_accuracy: 0.6909\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4667 - accuracy: 0.7900 - val_loss: 0.6320 - val_accuracy: 0.6909\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4622 - accuracy: 0.8036 - val_loss: 0.6435 - val_accuracy: 0.6909\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4588 - accuracy: 0.8202 - val_loss: 0.6432 - val_accuracy: 0.6909\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4554 - accuracy: 0.8097 - val_loss: 0.6268 - val_accuracy: 0.6364\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4544 - accuracy: 0.8021 - val_loss: 0.6492 - val_accuracy: 0.6909\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4451 - accuracy: 0.8082 - val_loss: 0.6716 - val_accuracy: 0.6364\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4433 - accuracy: 0.8097 - val_loss: 0.6759 - val_accuracy: 0.6364\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4507 - accuracy: 0.7976 - val_loss: 0.6962 - val_accuracy: 0.6364\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4453 - accuracy: 0.8066 - val_loss: 0.6988 - val_accuracy: 0.6364\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4327 - accuracy: 0.8157 - val_loss: 0.6695 - val_accuracy: 0.6727\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4359 - accuracy: 0.8202 - val_loss: 0.6539 - val_accuracy: 0.6727\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4360 - accuracy: 0.8157 - val_loss: 0.7098 - val_accuracy: 0.6364\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4353 - accuracy: 0.8172 - val_loss: 0.6880 - val_accuracy: 0.6364\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4314 - accuracy: 0.8248 - val_loss: 0.6708 - val_accuracy: 0.6727\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.4153 - accuracy: 0.8233 - val_loss: 0.6863 - val_accuracy: 0.6545\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4254 - accuracy: 0.8218 - val_loss: 0.6789 - val_accuracy: 0.6545\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4201 - accuracy: 0.8308 - val_loss: 0.6819 - val_accuracy: 0.6545\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4096 - accuracy: 0.8369 - val_loss: 0.6840 - val_accuracy: 0.6545\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4181 - accuracy: 0.8414 - val_loss: 0.6681 - val_accuracy: 0.6545\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4083 - accuracy: 0.8263 - val_loss: 0.6683 - val_accuracy: 0.6727\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4121 - accuracy: 0.8278 - val_loss: 0.6945 - val_accuracy: 0.6364\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3973 - accuracy: 0.8474 - val_loss: 0.6883 - val_accuracy: 0.6727\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4011 - accuracy: 0.8384 - val_loss: 0.6823 - val_accuracy: 0.6727\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3919 - accuracy: 0.8474 - val_loss: 0.6838 - val_accuracy: 0.6727\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3938 - accuracy: 0.8489 - val_loss: 0.6768 - val_accuracy: 0.6545\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4077 - accuracy: 0.8248 - val_loss: 0.6748 - val_accuracy: 0.6364\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3930 - accuracy: 0.8414 - val_loss: 0.7236 - val_accuracy: 0.6364\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3873 - accuracy: 0.8474 - val_loss: 0.6749 - val_accuracy: 0.6364\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3728 - accuracy: 0.8489 - val_loss: 0.7222 - val_accuracy: 0.6364\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3625 - accuracy: 0.8640 - val_loss: 0.6890 - val_accuracy: 0.6545\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3766 - accuracy: 0.8565 - val_loss: 0.6919 - val_accuracy: 0.6545\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3681 - accuracy: 0.8595 - val_loss: 0.6838 - val_accuracy: 0.6364\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3715 - accuracy: 0.8580 - val_loss: 0.7056 - val_accuracy: 0.6727\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3539 - accuracy: 0.8640 - val_loss: 0.6958 - val_accuracy: 0.6364\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3626 - accuracy: 0.8671 - val_loss: 0.7105 - val_accuracy: 0.6727\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3530 - accuracy: 0.8746 - val_loss: 0.7149 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e61677bb0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_2.fit(X_train_over, y_train_over, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ead56a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6628 - accuracy: 0.7500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6630 - accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "m2_eval_test = model_2.evaluate(X_test, y_test)\n",
    "m2_eval_val = model_2.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f9d3cf",
   "metadata": {},
   "source": [
    "**Summary statistics and confusion matrix for test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "960ac6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n",
      "roc auc score:  0.6447368421052632\n",
      "average precision score:  0.609380695316379\n"
     ]
    }
   ],
   "source": [
    "pred = model_2.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d093e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30200d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m2_eval_test = model_2.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d329b1",
   "metadata": {},
   "source": [
    "**Summary statistics and confusion matrix for validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "727aabe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n",
      "roc auc score:  0.6842105263157894\n",
      "average precision score:  0.701835874577447\n"
     ]
    }
   ],
   "source": [
    "pred = model_2.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a757c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "535b4e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels (validation set)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_2.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b576e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b011ad",
   "metadata": {},
   "source": [
    "## 2. GRI and MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b03c8543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>RNFLT.1</th>\n",
       "      <th>RNFLT.2</th>\n",
       "      <th>RNFLT.3</th>\n",
       "      <th>RNFLT.4</th>\n",
       "      <th>RNFLT.5</th>\n",
       "      <th>RNFLT.6</th>\n",
       "      <th>RNFLT.7</th>\n",
       "      <th>RNFLT.8</th>\n",
       "      <th>RNFLT.9</th>\n",
       "      <th>...</th>\n",
       "      <th>RNFLT.762</th>\n",
       "      <th>RNFLT.763</th>\n",
       "      <th>RNFLT.764</th>\n",
       "      <th>RNFLT.765</th>\n",
       "      <th>RNFLT.766</th>\n",
       "      <th>RNFLT.767</th>\n",
       "      <th>RNFLT.768</th>\n",
       "      <th>GRI</th>\n",
       "      <th>Y_GRI</th>\n",
       "      <th>Y_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-3.688171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-6.827438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.329429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.581343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>329</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>-11.691467</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>330</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-19.908699</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>330</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-10.130481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>331</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>-24.731627</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>331</td>\n",
       "      <td>31.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-18.674765</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PID  RNFLT.1  RNFLT.2  RNFLT.3  RNFLT.4  RNFLT.5  RNFLT.6  RNFLT.7  \\\n",
       "0      1     47.0     47.0     46.0     46.0     45.0     45.0     45.0   \n",
       "1      1     70.0     71.0     72.0     72.0     73.0     73.0     73.0   \n",
       "2      2     44.0     45.0     45.0     45.0     46.0     47.0     48.0   \n",
       "3      2     44.0     44.0     44.0     45.0     45.0     46.0     46.0   \n",
       "4      3     37.0     38.0     39.0     40.0     41.0     42.0     43.0   \n",
       "..   ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "579  329    100.0    103.0    106.0    108.0    111.0    112.0    113.0   \n",
       "580  330     52.0     52.0     53.0     54.0     55.0     56.0     57.0   \n",
       "581  330     62.0     63.0     64.0     65.0     66.0     67.0     68.0   \n",
       "582  331     47.0     47.0     48.0     48.0     49.0     49.0     50.0   \n",
       "583  331     31.0     31.0     32.0     33.0     33.0     34.0     35.0   \n",
       "\n",
       "     RNFLT.8  RNFLT.9  ...  RNFLT.762  RNFLT.763  RNFLT.764  RNFLT.765  \\\n",
       "0       45.0     45.0  ...       48.0       48.0       48.0       48.0   \n",
       "1       73.0     74.0  ...       61.0       62.0       63.0       65.0   \n",
       "2       50.0     51.0  ...       45.0       45.0       45.0       45.0   \n",
       "3       47.0     47.0  ...       43.0       43.0       43.0       43.0   \n",
       "4       44.0     46.0  ...       35.0       35.0       35.0       35.0   \n",
       "..       ...      ...  ...        ...        ...        ...        ...   \n",
       "579    113.0    113.0  ...       84.0       86.0       87.0       89.0   \n",
       "580     58.0     59.0  ...       47.0       48.0       48.0       49.0   \n",
       "581     68.0     68.0  ...       56.0       57.0       58.0       58.0   \n",
       "582     50.0     50.0  ...       46.0       46.0       45.0       45.0   \n",
       "583     36.0     37.0  ...       31.0       30.0       30.0       30.0   \n",
       "\n",
       "     RNFLT.766  RNFLT.767  RNFLT.768        GRI  Y_GRI  Y_MD  \n",
       "0         48.0       48.0       47.0  -3.688171      0     0  \n",
       "1         66.0       67.0       69.0  -6.827438      1     0  \n",
       "2         45.0       45.0       44.0   0.329429      0     0  \n",
       "3         43.0       43.0       43.0   0.581343      0     0  \n",
       "4         35.0       36.0       36.0   0.000000      0     0  \n",
       "..         ...        ...        ...        ...    ...   ...  \n",
       "579       92.0       94.0       97.0 -11.691467      1     0  \n",
       "580       49.0       50.0       51.0 -19.908699      1     1  \n",
       "581       59.0       60.0       61.0 -10.130481      1     0  \n",
       "582       46.0       46.0       46.0 -24.731627      1     1  \n",
       "583       30.0       30.0       30.0 -18.674765      1     1  \n",
       "\n",
       "[580 rows x 772 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.iloc[:, np.r_[1, 28:797, 811, 812]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9393b030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 772)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop missing values\n",
    "df = df.dropna()\n",
    "df.isnull().values.sum()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fa3fa0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "570    1\n",
       "571    1\n",
       "572    1\n",
       "573    1\n",
       "574    1\n",
       "Name: Y_GRIMD, Length: 575, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:, 770] + df.iloc[:, 771]\n",
    "y = np.array(y)\n",
    "y = y//2 + y%2\n",
    "y = pd.DataFrame(y)\n",
    "y = y.rename(columns = {0:'Y_GRIMD'})\n",
    "y = y.iloc[:, 0]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bad4f1",
   "metadata": {},
   "source": [
    "Using the same training, validation, and testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603140d0",
   "metadata": {},
   "source": [
    "train_i,test_i = next(GroupShuffleSplitStratified(n_splits=2, test_size=0.1,\n",
    "                                        random_state=8).split(df,y, groups=df['PID']))\n",
    "TrainVal = df.iloc[train_i]\n",
    "TestSet = df.iloc[test_i]\n",
    "print(TrainVal.shape)\n",
    "print(TestSet.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d1a9e3",
   "metadata": {},
   "source": [
    "train_id,val_id = next(GroupShuffleSplitStratified(n_splits=2, test_size=0.1,\n",
    "                                        random_state=10).split(TrainVal,y.iloc[train_i], groups=TrainVal['PID']))\n",
    "TrainSet = TrainVal.iloc[train_id]\n",
    "ValSet = TrainVal.iloc[val_id]\n",
    "print(TrainSet.shape)\n",
    "print(ValSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1b5c73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(52, 768)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNFLT.1</th>\n",
       "      <th>RNFLT.2</th>\n",
       "      <th>RNFLT.3</th>\n",
       "      <th>RNFLT.4</th>\n",
       "      <th>RNFLT.5</th>\n",
       "      <th>RNFLT.6</th>\n",
       "      <th>RNFLT.7</th>\n",
       "      <th>RNFLT.8</th>\n",
       "      <th>RNFLT.9</th>\n",
       "      <th>RNFLT.10</th>\n",
       "      <th>...</th>\n",
       "      <th>RNFLT.759</th>\n",
       "      <th>RNFLT.760</th>\n",
       "      <th>RNFLT.761</th>\n",
       "      <th>RNFLT.762</th>\n",
       "      <th>RNFLT.763</th>\n",
       "      <th>RNFLT.764</th>\n",
       "      <th>RNFLT.765</th>\n",
       "      <th>RNFLT.766</th>\n",
       "      <th>RNFLT.767</th>\n",
       "      <th>RNFLT.768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RNFLT.1  RNFLT.2  RNFLT.3  RNFLT.4  RNFLT.5  RNFLT.6  RNFLT.7  RNFLT.8  \\\n",
       "26     34.0     34.0     35.0     35.0     36.0     36.0     37.0     38.0   \n",
       "27     42.0     43.0     44.0     45.0     46.0     46.0     47.0     47.0   \n",
       "51     34.0     35.0     37.0     40.0     42.0     44.0     46.0     47.0   \n",
       "52     52.0     52.0     52.0     52.0     52.0     52.0     51.0     51.0   \n",
       "62     53.0     53.0     53.0     54.0     54.0     55.0     56.0     56.0   \n",
       "\n",
       "    RNFLT.9  RNFLT.10  ...  RNFLT.759  RNFLT.760  RNFLT.761  RNFLT.762  \\\n",
       "26     39.0      39.0  ...       34.0       33.0       33.0       33.0   \n",
       "27     48.0      48.0  ...       41.0       40.0       40.0       40.0   \n",
       "51     48.0      48.0  ...       29.0       29.0       28.0       28.0   \n",
       "52     51.0      51.0  ...       52.0       53.0       53.0       53.0   \n",
       "62     57.0      58.0  ...       55.0       55.0       55.0       55.0   \n",
       "\n",
       "    RNFLT.763  RNFLT.764  RNFLT.765  RNFLT.766  RNFLT.767  RNFLT.768  \n",
       "26       32.0       32.0       32.0       33.0       33.0       33.0  \n",
       "27       40.0       40.0       40.0       40.0       41.0       41.0  \n",
       "51       28.0       29.0       29.0       30.0       31.0       32.0  \n",
       "52       53.0       53.0       53.0       53.0       52.0       52.0  \n",
       "62       54.0       54.0       54.0       53.0       53.0       53.0  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.iloc[test_i, 1:769]\n",
    "print(x.isnull().values.sum())\n",
    "print(x.shape)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "252a8071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_test = scaled_x\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "481298f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = TrainVal.iloc[train_id, 1:769]\n",
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_train = scaled_x\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8670fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "x = TrainVal.iloc[val_id, 1:769]\n",
    "x = np.asarray(x)\n",
    "scaled_x = x/381\n",
    "scaled_x = scaled_x.reshape(scaled_x.shape[0],scaled_x.shape[1],1)\n",
    "X_val = scaled_x\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ac0aa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  1\n",
      "1  0    400\n",
      "0  1    175\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1\n",
       "0    1  0\n",
       "1    0  1\n",
       "2    1  0\n",
       "3    1  0\n",
       "4    1  0\n",
       "..  .. ..\n",
       "570  0  1\n",
       "571  0  1\n",
       "572  0  1\n",
       "573  0  1\n",
       "574  0  1\n",
       "\n",
       "[575 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot-encoding our label\n",
    "y = pd.get_dummies(y)\n",
    "print(y.value_counts())\n",
    "y #The second column is 'progressor', The first column is 'non-progressor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47720cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "0                 1           0\n",
       "1                 0           1\n",
       "2                 1           0\n",
       "3                 1           0\n",
       "4                 1           0\n",
       "..              ...         ...\n",
       "570               0           1\n",
       "571               0           1\n",
       "572               0           1\n",
       "573               0           1\n",
       "574               0           1\n",
       "\n",
       "[575 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.rename(columns={0: \"Non-Progressor\", 1: \"Progressor\"})\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af8b6078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "26                1           0\n",
       "27                1           0\n",
       "51                0           1\n",
       "52                1           0\n",
       "60                0           1\n",
       "61                0           1\n",
       "116               1           0\n",
       "141               0           1\n",
       "142               1           0\n",
       "143               1           0\n",
       "144               1           0\n",
       "193               1           0\n",
       "196               1           0\n",
       "197               1           0\n",
       "198               1           0\n",
       "218               1           0\n",
       "219               1           0\n",
       "246               1           0\n",
       "247               1           0\n",
       "248               1           0\n",
       "249               1           0\n",
       "255               1           0\n",
       "256               1           0\n",
       "257               1           0\n",
       "258               1           0\n",
       "260               0           1\n",
       "261               1           0\n",
       "270               1           0\n",
       "271               1           0\n",
       "274               0           1\n",
       "275               1           0\n",
       "285               0           1\n",
       "309               1           0\n",
       "310               0           1\n",
       "316               1           0\n",
       "317               1           0\n",
       "330               0           1\n",
       "331               0           1\n",
       "335               1           0\n",
       "336               1           0\n",
       "366               1           0\n",
       "432               1           0\n",
       "472               1           0\n",
       "473               0           1\n",
       "476               0           1\n",
       "483               1           0\n",
       "495               1           0\n",
       "512               0           1\n",
       "524               0           1\n",
       "525               0           1\n",
       "536               1           0\n",
       "537               1           0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y.iloc[test_i]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50792406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "0                 1           0\n",
       "1                 0           1\n",
       "2                 1           0\n",
       "3                 1           0\n",
       "4                 1           0\n",
       "..              ...         ...\n",
       "570               0           1\n",
       "571               0           1\n",
       "572               0           1\n",
       "573               0           1\n",
       "574               0           1\n",
       "\n",
       "[468 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y.iloc[train_i].iloc[train_id]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7253491c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non-Progressor</th>\n",
       "      <th>Progressor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Non-Progressor  Progressor\n",
       "12                0           1\n",
       "16                0           1\n",
       "17                1           0\n",
       "28                1           0\n",
       "29                1           0\n",
       "49                0           1\n",
       "50                1           0\n",
       "59                0           1\n",
       "86                0           1\n",
       "87                1           0\n",
       "107               0           1\n",
       "108               0           1\n",
       "119               1           0\n",
       "139               0           1\n",
       "140               0           1\n",
       "151               1           0\n",
       "152               0           1\n",
       "153               1           0\n",
       "154               1           0\n",
       "212               1           0\n",
       "213               1           0\n",
       "214               1           0\n",
       "215               1           0\n",
       "216               1           0\n",
       "217               1           0\n",
       "239               1           0\n",
       "240               1           0\n",
       "276               1           0\n",
       "277               1           0\n",
       "278               1           0\n",
       "279               1           0\n",
       "284               1           0\n",
       "286               1           0\n",
       "287               1           0\n",
       "299               1           0\n",
       "300               1           0\n",
       "345               0           1\n",
       "346               0           1\n",
       "354               1           0\n",
       "355               0           1\n",
       "362               1           0\n",
       "363               1           0\n",
       "364               1           0\n",
       "365               0           1\n",
       "387               1           0\n",
       "388               0           1\n",
       "424               1           0\n",
       "466               0           1\n",
       "467               1           0\n",
       "488               1           0\n",
       "489               1           0\n",
       "520               1           0\n",
       "521               0           1\n",
       "532               1           0\n",
       "533               1           0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = y.iloc[train_i].iloc[val_id]\n",
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "560b6227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 768, 1)\n",
      "(52, 768, 1)\n",
      "(55, 768, 1)\n",
      "Non-Progressor  Progressor\n",
      "1               0             325\n",
      "0               1             143\n",
      "dtype: int64 \n",
      "\n",
      "Non-Progressor  Progressor\n",
      "1               0             38\n",
      "0               1             17\n",
      "dtype: int64 \n",
      "\n",
      "Non-Progressor  Progressor\n",
      "1               0             37\n",
      "0               1             15\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.value_counts(), '\\n')\n",
    "print(y_val.value_counts(), '\\n')\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623675b0",
   "metadata": {},
   "source": [
    "### 2.1 CNN model without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c791c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 766, 64)           256       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 255, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 255, 64)           0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 16320)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                1044544   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,045,874\n",
      "Trainable params: 1,045,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model1\n",
    "model_1 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_1.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_1.add(MaxPooling1D(pool_size=3))\n",
    "# model_1.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "# model_1.add(MaxPooling1D(pool_size=2))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dense(16, activation='relu'))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ace8c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=100,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e552a8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "15/15 [==============================] - 1s 32ms/step - loss: 0.6616 - accuracy: 0.6581 - val_loss: 0.6239 - val_accuracy: 0.6909\n",
      "Epoch 2/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.6078 - accuracy: 0.6944 - val_loss: 0.6072 - val_accuracy: 0.6909\n",
      "Epoch 3/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.6066 - accuracy: 0.6944 - val_loss: 0.6083 - val_accuracy: 0.6909\n",
      "Epoch 4/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.6067 - accuracy: 0.6944 - val_loss: 0.6058 - val_accuracy: 0.6909\n",
      "Epoch 5/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6040 - accuracy: 0.6944 - val_loss: 0.6052 - val_accuracy: 0.6909\n",
      "Epoch 6/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.6040 - accuracy: 0.6944 - val_loss: 0.6043 - val_accuracy: 0.6909\n",
      "Epoch 7/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.6089 - accuracy: 0.6944 - val_loss: 0.6042 - val_accuracy: 0.6909\n",
      "Epoch 8/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.6020 - accuracy: 0.6944 - val_loss: 0.6029 - val_accuracy: 0.6909\n",
      "Epoch 9/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6018 - accuracy: 0.6944 - val_loss: 0.6017 - val_accuracy: 0.6909\n",
      "Epoch 10/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.6010 - accuracy: 0.6944 - val_loss: 0.6011 - val_accuracy: 0.6909\n",
      "Epoch 11/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.6000 - accuracy: 0.6944 - val_loss: 0.6003 - val_accuracy: 0.6909\n",
      "Epoch 12/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5980 - accuracy: 0.6944 - val_loss: 0.5993 - val_accuracy: 0.6909\n",
      "Epoch 13/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5963 - accuracy: 0.6944 - val_loss: 0.5985 - val_accuracy: 0.6909\n",
      "Epoch 14/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5945 - accuracy: 0.6944 - val_loss: 0.5981 - val_accuracy: 0.6909\n",
      "Epoch 15/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5945 - accuracy: 0.6944 - val_loss: 0.5960 - val_accuracy: 0.6909\n",
      "Epoch 16/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5940 - accuracy: 0.6944 - val_loss: 0.5956 - val_accuracy: 0.6909\n",
      "Epoch 17/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5910 - accuracy: 0.6944 - val_loss: 0.5940 - val_accuracy: 0.6909\n",
      "Epoch 18/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5892 - accuracy: 0.6944 - val_loss: 0.5926 - val_accuracy: 0.6909\n",
      "Epoch 19/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5862 - accuracy: 0.6966 - val_loss: 0.5921 - val_accuracy: 0.6909\n",
      "Epoch 20/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5879 - accuracy: 0.6966 - val_loss: 0.5904 - val_accuracy: 0.6909\n",
      "Epoch 21/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5839 - accuracy: 0.6966 - val_loss: 0.5888 - val_accuracy: 0.6909\n",
      "Epoch 22/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5828 - accuracy: 0.6966 - val_loss: 0.5874 - val_accuracy: 0.6909\n",
      "Epoch 23/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5837 - accuracy: 0.6966 - val_loss: 0.5866 - val_accuracy: 0.6909\n",
      "Epoch 24/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5807 - accuracy: 0.6966 - val_loss: 0.5858 - val_accuracy: 0.6909\n",
      "Epoch 25/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5769 - accuracy: 0.6966 - val_loss: 0.5864 - val_accuracy: 0.6909\n",
      "Epoch 26/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5776 - accuracy: 0.6987 - val_loss: 0.5857 - val_accuracy: 0.6909\n",
      "Epoch 27/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5720 - accuracy: 0.7030 - val_loss: 0.5830 - val_accuracy: 0.6909\n",
      "Epoch 28/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5754 - accuracy: 0.7073 - val_loss: 0.5829 - val_accuracy: 0.6909\n",
      "Epoch 29/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5735 - accuracy: 0.7051 - val_loss: 0.5823 - val_accuracy: 0.6909\n",
      "Epoch 30/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5725 - accuracy: 0.7073 - val_loss: 0.5817 - val_accuracy: 0.6909\n",
      "Epoch 31/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5694 - accuracy: 0.7030 - val_loss: 0.5822 - val_accuracy: 0.6909\n",
      "Epoch 32/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5666 - accuracy: 0.7094 - val_loss: 0.5809 - val_accuracy: 0.6909\n",
      "Epoch 33/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5661 - accuracy: 0.7073 - val_loss: 0.5804 - val_accuracy: 0.6909\n",
      "Epoch 34/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5628 - accuracy: 0.7073 - val_loss: 0.5785 - val_accuracy: 0.6909\n",
      "Epoch 35/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5588 - accuracy: 0.7051 - val_loss: 0.5803 - val_accuracy: 0.6909\n",
      "Epoch 36/500\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.5618 - accuracy: 0.7073 - val_loss: 0.5772 - val_accuracy: 0.6909\n",
      "Epoch 37/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5603 - accuracy: 0.7179 - val_loss: 0.5773 - val_accuracy: 0.6909\n",
      "Epoch 38/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5608 - accuracy: 0.7094 - val_loss: 0.5798 - val_accuracy: 0.6909\n",
      "Epoch 39/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5554 - accuracy: 0.7115 - val_loss: 0.5773 - val_accuracy: 0.6909\n",
      "Epoch 40/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5620 - accuracy: 0.7137 - val_loss: 0.5810 - val_accuracy: 0.6909\n",
      "Epoch 41/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5604 - accuracy: 0.7372 - val_loss: 0.5758 - val_accuracy: 0.6909\n",
      "Epoch 42/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5513 - accuracy: 0.7158 - val_loss: 0.5769 - val_accuracy: 0.6909\n",
      "Epoch 43/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5490 - accuracy: 0.7137 - val_loss: 0.5764 - val_accuracy: 0.6909\n",
      "Epoch 44/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5472 - accuracy: 0.7222 - val_loss: 0.5774 - val_accuracy: 0.6909\n",
      "Epoch 45/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5481 - accuracy: 0.7244 - val_loss: 0.5746 - val_accuracy: 0.6909\n",
      "Epoch 46/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5460 - accuracy: 0.7158 - val_loss: 0.5764 - val_accuracy: 0.6909\n",
      "Epoch 47/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5410 - accuracy: 0.7244 - val_loss: 0.5738 - val_accuracy: 0.6909\n",
      "Epoch 48/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5424 - accuracy: 0.7222 - val_loss: 0.5745 - val_accuracy: 0.6909\n",
      "Epoch 49/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5376 - accuracy: 0.7222 - val_loss: 0.5724 - val_accuracy: 0.7091\n",
      "Epoch 50/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5370 - accuracy: 0.7244 - val_loss: 0.5734 - val_accuracy: 0.7091\n",
      "Epoch 51/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5348 - accuracy: 0.7265 - val_loss: 0.5741 - val_accuracy: 0.6909\n",
      "Epoch 52/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5384 - accuracy: 0.7244 - val_loss: 0.5719 - val_accuracy: 0.7091\n",
      "Epoch 53/500\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.5399 - accuracy: 0.7585 - val_loss: 0.5749 - val_accuracy: 0.6909\n",
      "Epoch 54/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5322 - accuracy: 0.7137 - val_loss: 0.5730 - val_accuracy: 0.7091\n",
      "Epoch 55/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5254 - accuracy: 0.7350 - val_loss: 0.5750 - val_accuracy: 0.6909\n",
      "Epoch 56/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5317 - accuracy: 0.7244 - val_loss: 0.5716 - val_accuracy: 0.6909\n",
      "Epoch 57/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5254 - accuracy: 0.7415 - val_loss: 0.5722 - val_accuracy: 0.7091\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5257 - accuracy: 0.7372 - val_loss: 0.5728 - val_accuracy: 0.6909\n",
      "Epoch 59/500\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5168 - accuracy: 0.7607 - val_loss: 0.5745 - val_accuracy: 0.7091\n",
      "Epoch 60/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5244 - accuracy: 0.7393 - val_loss: 0.5742 - val_accuracy: 0.7091\n",
      "Epoch 61/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5248 - accuracy: 0.7692 - val_loss: 0.5724 - val_accuracy: 0.7091\n",
      "Epoch 62/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5186 - accuracy: 0.7543 - val_loss: 0.5762 - val_accuracy: 0.7091\n",
      "Epoch 63/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5154 - accuracy: 0.7436 - val_loss: 0.5733 - val_accuracy: 0.6727\n",
      "Epoch 64/500\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.5144 - accuracy: 0.7436 - val_loss: 0.5725 - val_accuracy: 0.7091\n",
      "Epoch 65/500\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.5092 - accuracy: 0.7692 - val_loss: 0.5726 - val_accuracy: 0.6909\n",
      "Epoch 66/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5102 - accuracy: 0.7521 - val_loss: 0.5728 - val_accuracy: 0.6909\n",
      "Epoch 67/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5111 - accuracy: 0.7799 - val_loss: 0.5760 - val_accuracy: 0.6909\n",
      "Epoch 68/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5160 - accuracy: 0.7350 - val_loss: 0.5733 - val_accuracy: 0.7273\n",
      "Epoch 69/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5020 - accuracy: 0.7756 - val_loss: 0.5747 - val_accuracy: 0.6727\n",
      "Epoch 70/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5044 - accuracy: 0.7735 - val_loss: 0.5769 - val_accuracy: 0.6727\n",
      "Epoch 71/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5069 - accuracy: 0.7735 - val_loss: 0.5752 - val_accuracy: 0.7091\n",
      "Epoch 72/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4987 - accuracy: 0.7863 - val_loss: 0.5753 - val_accuracy: 0.6909\n",
      "Epoch 73/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4984 - accuracy: 0.7756 - val_loss: 0.5745 - val_accuracy: 0.6727\n",
      "Epoch 74/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.5002 - accuracy: 0.7650 - val_loss: 0.5746 - val_accuracy: 0.6727\n",
      "Epoch 75/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4949 - accuracy: 0.7799 - val_loss: 0.5784 - val_accuracy: 0.6909\n",
      "Epoch 76/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4895 - accuracy: 0.7842 - val_loss: 0.5753 - val_accuracy: 0.6909\n",
      "Epoch 77/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4900 - accuracy: 0.7756 - val_loss: 0.5810 - val_accuracy: 0.7091\n",
      "Epoch 78/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4894 - accuracy: 0.7756 - val_loss: 0.5755 - val_accuracy: 0.7273\n",
      "Epoch 79/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4853 - accuracy: 0.7906 - val_loss: 0.5796 - val_accuracy: 0.6727\n",
      "Epoch 80/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4873 - accuracy: 0.7692 - val_loss: 0.5792 - val_accuracy: 0.6727\n",
      "Epoch 81/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4838 - accuracy: 0.7842 - val_loss: 0.5819 - val_accuracy: 0.6909\n",
      "Epoch 82/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4804 - accuracy: 0.7778 - val_loss: 0.5825 - val_accuracy: 0.6909\n",
      "Epoch 83/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4785 - accuracy: 0.7885 - val_loss: 0.5791 - val_accuracy: 0.7091\n",
      "Epoch 84/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4788 - accuracy: 0.7885 - val_loss: 0.5843 - val_accuracy: 0.6727\n",
      "Epoch 85/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4749 - accuracy: 0.7842 - val_loss: 0.5803 - val_accuracy: 0.7273\n",
      "Epoch 86/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4730 - accuracy: 0.7991 - val_loss: 0.5872 - val_accuracy: 0.6909\n",
      "Epoch 87/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4717 - accuracy: 0.7927 - val_loss: 0.5813 - val_accuracy: 0.7091\n",
      "Epoch 88/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4732 - accuracy: 0.7799 - val_loss: 0.5843 - val_accuracy: 0.6727\n",
      "Epoch 89/500\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4658 - accuracy: 0.7885 - val_loss: 0.5811 - val_accuracy: 0.7273\n",
      "Epoch 90/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4708 - accuracy: 0.7991 - val_loss: 0.5863 - val_accuracy: 0.6909\n",
      "Epoch 91/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4695 - accuracy: 0.7863 - val_loss: 0.5859 - val_accuracy: 0.6727\n",
      "Epoch 92/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4665 - accuracy: 0.7863 - val_loss: 0.5843 - val_accuracy: 0.7091\n",
      "Epoch 93/500\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.4669 - accuracy: 0.7927 - val_loss: 0.5936 - val_accuracy: 0.6909\n",
      "Epoch 94/500\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.4734 - accuracy: 0.7799 - val_loss: 0.5855 - val_accuracy: 0.7273\n",
      "Epoch 95/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4519 - accuracy: 0.7970 - val_loss: 0.5901 - val_accuracy: 0.6909\n",
      "Epoch 96/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4555 - accuracy: 0.8034 - val_loss: 0.5936 - val_accuracy: 0.6909\n",
      "Epoch 97/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4555 - accuracy: 0.7991 - val_loss: 0.5880 - val_accuracy: 0.7091\n",
      "Epoch 98/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4658 - accuracy: 0.8056 - val_loss: 0.5934 - val_accuracy: 0.6909\n",
      "Epoch 99/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4546 - accuracy: 0.8077 - val_loss: 0.5889 - val_accuracy: 0.7091\n",
      "Epoch 100/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4480 - accuracy: 0.8056 - val_loss: 0.5952 - val_accuracy: 0.6909\n",
      "Epoch 101/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4512 - accuracy: 0.8034 - val_loss: 0.5911 - val_accuracy: 0.7091\n",
      "Epoch 102/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4493 - accuracy: 0.8098 - val_loss: 0.5966 - val_accuracy: 0.6727\n",
      "Epoch 103/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4489 - accuracy: 0.7842 - val_loss: 0.5937 - val_accuracy: 0.6909\n",
      "Epoch 104/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4469 - accuracy: 0.8098 - val_loss: 0.5932 - val_accuracy: 0.7273\n",
      "Epoch 105/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4521 - accuracy: 0.7799 - val_loss: 0.5966 - val_accuracy: 0.7273\n",
      "Epoch 106/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4511 - accuracy: 0.7949 - val_loss: 0.5934 - val_accuracy: 0.7091\n",
      "Epoch 107/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4451 - accuracy: 0.7927 - val_loss: 0.6028 - val_accuracy: 0.6909\n",
      "Epoch 108/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4566 - accuracy: 0.7842 - val_loss: 0.5986 - val_accuracy: 0.7273\n",
      "Epoch 109/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4570 - accuracy: 0.8013 - val_loss: 0.5998 - val_accuracy: 0.6909\n",
      "Epoch 110/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4516 - accuracy: 0.7863 - val_loss: 0.5940 - val_accuracy: 0.7091\n",
      "Epoch 111/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4357 - accuracy: 0.8184 - val_loss: 0.5996 - val_accuracy: 0.7273\n",
      "Epoch 112/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4340 - accuracy: 0.7949 - val_loss: 0.6001 - val_accuracy: 0.7273\n",
      "Epoch 113/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4410 - accuracy: 0.8184 - val_loss: 0.6034 - val_accuracy: 0.7091\n",
      "Epoch 114/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4265 - accuracy: 0.8162 - val_loss: 0.6021 - val_accuracy: 0.7091\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4298 - accuracy: 0.8077 - val_loss: 0.6069 - val_accuracy: 0.7091\n",
      "Epoch 116/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4249 - accuracy: 0.8184 - val_loss: 0.6027 - val_accuracy: 0.7273\n",
      "Epoch 117/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4233 - accuracy: 0.8120 - val_loss: 0.6120 - val_accuracy: 0.7091\n",
      "Epoch 118/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4243 - accuracy: 0.8184 - val_loss: 0.6069 - val_accuracy: 0.7091\n",
      "Epoch 119/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4268 - accuracy: 0.8248 - val_loss: 0.6113 - val_accuracy: 0.7273\n",
      "Epoch 120/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4139 - accuracy: 0.8205 - val_loss: 0.6098 - val_accuracy: 0.7273\n",
      "Epoch 121/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4159 - accuracy: 0.8312 - val_loss: 0.6103 - val_accuracy: 0.7273\n",
      "Epoch 122/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4230 - accuracy: 0.8205 - val_loss: 0.6147 - val_accuracy: 0.7273\n",
      "Epoch 123/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4261 - accuracy: 0.8120 - val_loss: 0.6155 - val_accuracy: 0.6909\n",
      "Epoch 124/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4169 - accuracy: 0.8141 - val_loss: 0.6167 - val_accuracy: 0.7091\n",
      "Epoch 125/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4153 - accuracy: 0.8291 - val_loss: 0.6138 - val_accuracy: 0.7091\n",
      "Epoch 126/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4147 - accuracy: 0.8226 - val_loss: 0.6171 - val_accuracy: 0.7091\n",
      "Epoch 127/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4080 - accuracy: 0.8269 - val_loss: 0.6194 - val_accuracy: 0.7091\n",
      "Epoch 128/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4075 - accuracy: 0.8269 - val_loss: 0.6231 - val_accuracy: 0.7091\n",
      "Epoch 129/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4095 - accuracy: 0.8269 - val_loss: 0.6213 - val_accuracy: 0.7091\n",
      "Epoch 130/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4063 - accuracy: 0.8120 - val_loss: 0.6221 - val_accuracy: 0.7091\n",
      "Epoch 131/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4052 - accuracy: 0.8333 - val_loss: 0.6211 - val_accuracy: 0.7273\n",
      "Epoch 132/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4109 - accuracy: 0.8226 - val_loss: 0.6370 - val_accuracy: 0.6909\n",
      "Epoch 133/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4127 - accuracy: 0.8248 - val_loss: 0.6253 - val_accuracy: 0.7273\n",
      "Epoch 134/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3910 - accuracy: 0.8333 - val_loss: 0.6264 - val_accuracy: 0.7091\n",
      "Epoch 135/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4033 - accuracy: 0.8226 - val_loss: 0.6293 - val_accuracy: 0.7091\n",
      "Epoch 136/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3922 - accuracy: 0.8312 - val_loss: 0.6324 - val_accuracy: 0.7273\n",
      "Epoch 137/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3995 - accuracy: 0.8162 - val_loss: 0.6279 - val_accuracy: 0.7091\n",
      "Epoch 138/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3967 - accuracy: 0.8333 - val_loss: 0.6338 - val_accuracy: 0.7273\n",
      "Epoch 139/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3987 - accuracy: 0.8419 - val_loss: 0.6313 - val_accuracy: 0.7273\n",
      "Epoch 140/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3951 - accuracy: 0.8462 - val_loss: 0.6512 - val_accuracy: 0.6909\n",
      "Epoch 141/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3982 - accuracy: 0.8269 - val_loss: 0.6377 - val_accuracy: 0.7091\n",
      "Epoch 142/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3859 - accuracy: 0.8355 - val_loss: 0.6417 - val_accuracy: 0.7091\n",
      "Epoch 143/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3850 - accuracy: 0.8419 - val_loss: 0.6409 - val_accuracy: 0.7091\n",
      "Epoch 144/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3935 - accuracy: 0.8269 - val_loss: 0.6465 - val_accuracy: 0.7091\n",
      "Epoch 145/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3867 - accuracy: 0.8269 - val_loss: 0.6391 - val_accuracy: 0.7091\n",
      "Epoch 146/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3842 - accuracy: 0.8547 - val_loss: 0.6461 - val_accuracy: 0.7273\n",
      "Epoch 147/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3749 - accuracy: 0.8397 - val_loss: 0.6513 - val_accuracy: 0.7091\n",
      "Epoch 148/500\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3882 - accuracy: 0.8355 - val_loss: 0.6500 - val_accuracy: 0.7273\n",
      "Epoch 149/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3860 - accuracy: 0.8355 - val_loss: 0.6522 - val_accuracy: 0.7273\n",
      "Epoch 150/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3794 - accuracy: 0.8440 - val_loss: 0.6477 - val_accuracy: 0.7091\n",
      "Epoch 151/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3793 - accuracy: 0.8376 - val_loss: 0.6512 - val_accuracy: 0.7091\n",
      "Epoch 152/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3947 - accuracy: 0.8291 - val_loss: 0.6480 - val_accuracy: 0.7091\n",
      "Epoch 153/500\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3712 - accuracy: 0.8504 - val_loss: 0.6527 - val_accuracy: 0.6909\n",
      "Epoch 154/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3678 - accuracy: 0.8590 - val_loss: 0.6583 - val_accuracy: 0.7091\n",
      "Epoch 155/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3659 - accuracy: 0.8504 - val_loss: 0.6565 - val_accuracy: 0.7091\n",
      "Epoch 156/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3644 - accuracy: 0.8355 - val_loss: 0.6566 - val_accuracy: 0.7091\n",
      "Epoch 157/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3693 - accuracy: 0.8376 - val_loss: 0.6583 - val_accuracy: 0.6909\n",
      "Epoch 158/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3695 - accuracy: 0.8376 - val_loss: 0.6618 - val_accuracy: 0.6909\n",
      "Epoch 159/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3590 - accuracy: 0.8590 - val_loss: 0.6653 - val_accuracy: 0.7091\n",
      "Epoch 160/500\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3670 - accuracy: 0.8483 - val_loss: 0.6621 - val_accuracy: 0.6909\n",
      "Epoch 161/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3602 - accuracy: 0.8419 - val_loss: 0.6624 - val_accuracy: 0.6909\n",
      "Epoch 162/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3566 - accuracy: 0.8483 - val_loss: 0.6707 - val_accuracy: 0.6909\n",
      "Epoch 163/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3630 - accuracy: 0.8590 - val_loss: 0.6680 - val_accuracy: 0.7091\n",
      "Epoch 164/500\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3600 - accuracy: 0.8547 - val_loss: 0.6670 - val_accuracy: 0.6727\n",
      "Epoch 165/500\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.3630 - accuracy: 0.8504 - val_loss: 0.6711 - val_accuracy: 0.6909\n",
      "Epoch 166/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3534 - accuracy: 0.8462 - val_loss: 0.6712 - val_accuracy: 0.6909\n",
      "Epoch 167/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3530 - accuracy: 0.8654 - val_loss: 0.6735 - val_accuracy: 0.6909\n",
      "Epoch 168/500\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3645 - accuracy: 0.8590 - val_loss: 0.6811 - val_accuracy: 0.7091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e18567730>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_1.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8bba16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5943 - accuracy: 0.7115\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5733 - accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "m1_eval_test = model_1.evaluate(X_test, y_test)\n",
    "m1_eval_val = model_1.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6f18b7",
   "metadata": {},
   "source": [
    "**Summary statistics and confusion matrix for test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57eae648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n",
      "roc auc score:  0.6486486486486487\n",
      "average precision score:  0.6204275556828782\n"
     ]
    }
   ],
   "source": [
    "pred = model_1.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a43f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c692ffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5943 - accuracy: 0.7115\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_1.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c31f3",
   "metadata": {},
   "source": [
    "**Summary statistics and confusion matrix for validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58188fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n",
      "roc auc score:  0.676470588235294\n",
      "average precision score:  0.65812383903241\n"
     ]
    }
   ],
   "source": [
    "pred = model_1.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d7f2371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e338819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels (validation set)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_1.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91670e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b34f904",
   "metadata": {},
   "source": [
    "### 2.2 CNN model with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8561df57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_progressor = np.array(y_train)[:,1]\n",
    "y_progressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eee90561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 768)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2d = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]))\n",
    "X_train_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f413b124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy = 'minority')\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train_2d, y_progressor)\n",
    "print(X_train_over.shape)\n",
    "y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bd58e966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1\n",
       "0    1  0\n",
       "1    0  1\n",
       "2    1  0\n",
       "3    1  0\n",
       "4    1  0\n",
       "..  .. ..\n",
       "645  0  1\n",
       "646  0  1\n",
       "647  0  1\n",
       "648  0  1\n",
       "649  0  1\n",
       "\n",
       "[650 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_over = pd.get_dummies(y_train_over)\n",
    "y_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e16530d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Progressor  Progressor\n",
      "0               1             325\n",
      "1               0             325\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_over=y_train_over.rename(columns={0: \"Non-Progressor\", 1: \"Progressor\"})\n",
    "print(y_train_over.value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0d308a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Progressor  Progressor\n",
      "1               0             325\n",
      "0               1             143\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "feba99d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.12335958],\n",
       "        [0.12335958],\n",
       "        [0.12073491],\n",
       "        ...,\n",
       "        [0.12598425],\n",
       "        [0.12598425],\n",
       "        [0.12335958]],\n",
       "\n",
       "       [[0.18372703],\n",
       "        [0.18635171],\n",
       "        [0.18897638],\n",
       "        ...,\n",
       "        [0.17322835],\n",
       "        [0.17585302],\n",
       "        [0.18110236]],\n",
       "\n",
       "       [[0.11548556],\n",
       "        [0.11811024],\n",
       "        [0.11811024],\n",
       "        ...,\n",
       "        [0.11811024],\n",
       "        [0.11811024],\n",
       "        [0.11548556]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.23884514],\n",
       "        [0.24146982],\n",
       "        [0.24146982],\n",
       "        ...,\n",
       "        [0.23884514],\n",
       "        [0.23884514],\n",
       "        [0.23884514]],\n",
       "\n",
       "       [[0.07874016],\n",
       "        [0.07349081],\n",
       "        [0.07086614],\n",
       "        ...,\n",
       "        [0.09186352],\n",
       "        [0.08661417],\n",
       "        [0.08136483]],\n",
       "\n",
       "       [[0.11811024],\n",
       "        [0.12073491],\n",
       "        [0.12335958],\n",
       "        ...,\n",
       "        [0.11811024],\n",
       "        [0.11811024],\n",
       "        [0.11811024]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over = np.reshape(X_train_over, (X_train_over.shape[0], X_train_over.shape[1], 1))\n",
    "X_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "89f34d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 766, 64)           256       \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 255, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 255, 64)           0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 16320)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                1044544   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,045,874\n",
      "Trainable params: 1,045,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create model2\n",
    "model_2 = Sequential()\n",
    "\n",
    "#add layers\n",
    "model_2.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(768,1)))\n",
    "model_2.add(MaxPooling1D(pool_size=3))\n",
    "# model_1.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "# model_1.add(MaxPooling1D(pool_size=2))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(64, activation='relu'))\n",
    "model_2.add(Dense(16, activation='relu'))\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "31866ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0,\n",
    "    patience=200,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "opt1 = keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c6e46892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.6938 - accuracy: 0.5046 - val_loss: 0.6562 - val_accuracy: 0.6909\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6892 - accuracy: 0.5262 - val_loss: 0.6697 - val_accuracy: 0.7091\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6847 - accuracy: 0.5477 - val_loss: 0.6817 - val_accuracy: 0.5818\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.6779 - accuracy: 0.5985 - val_loss: 0.6630 - val_accuracy: 0.6727\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6766 - accuracy: 0.6031 - val_loss: 0.6377 - val_accuracy: 0.6909\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6709 - accuracy: 0.5892 - val_loss: 0.6773 - val_accuracy: 0.5818\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.6657 - accuracy: 0.6185 - val_loss: 0.6474 - val_accuracy: 0.6545\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6620 - accuracy: 0.6385 - val_loss: 0.6336 - val_accuracy: 0.6727\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.6518 - accuracy: 0.6477 - val_loss: 0.6611 - val_accuracy: 0.6000\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6507 - accuracy: 0.6385 - val_loss: 0.7020 - val_accuracy: 0.6000\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.6489 - accuracy: 0.6277 - val_loss: 0.6181 - val_accuracy: 0.6545\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6417 - accuracy: 0.6538 - val_loss: 0.6312 - val_accuracy: 0.6182\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.6369 - accuracy: 0.6508 - val_loss: 0.6488 - val_accuracy: 0.6000\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6319 - accuracy: 0.6692 - val_loss: 0.6139 - val_accuracy: 0.6909\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.6276 - accuracy: 0.6600 - val_loss: 0.6625 - val_accuracy: 0.5636\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6326 - accuracy: 0.6554 - val_loss: 0.6422 - val_accuracy: 0.5818\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.6219 - accuracy: 0.6662 - val_loss: 0.5835 - val_accuracy: 0.6727\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.6289 - accuracy: 0.6646 - val_loss: 0.6115 - val_accuracy: 0.6727\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6152 - accuracy: 0.6631 - val_loss: 0.6522 - val_accuracy: 0.5636\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.6083 - accuracy: 0.6877 - val_loss: 0.6165 - val_accuracy: 0.6727\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.6077 - accuracy: 0.6938 - val_loss: 0.6575 - val_accuracy: 0.5273\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5985 - accuracy: 0.7031 - val_loss: 0.5924 - val_accuracy: 0.7455\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5962 - accuracy: 0.6938 - val_loss: 0.6283 - val_accuracy: 0.6182\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5903 - accuracy: 0.7046 - val_loss: 0.5895 - val_accuracy: 0.7455\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5899 - accuracy: 0.7062 - val_loss: 0.6078 - val_accuracy: 0.6545\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5845 - accuracy: 0.7046 - val_loss: 0.6101 - val_accuracy: 0.6727\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5787 - accuracy: 0.7108 - val_loss: 0.6424 - val_accuracy: 0.5455\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5690 - accuracy: 0.7415 - val_loss: 0.6031 - val_accuracy: 0.6909\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.5686 - accuracy: 0.7338 - val_loss: 0.5972 - val_accuracy: 0.7091\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5677 - accuracy: 0.7354 - val_loss: 0.6175 - val_accuracy: 0.6545\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5626 - accuracy: 0.7354 - val_loss: 0.6357 - val_accuracy: 0.6000\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.5632 - accuracy: 0.7323 - val_loss: 0.5868 - val_accuracy: 0.7455\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.5748 - accuracy: 0.7154 - val_loss: 0.5937 - val_accuracy: 0.7091\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.5604 - accuracy: 0.7338 - val_loss: 0.5834 - val_accuracy: 0.7273\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.5506 - accuracy: 0.7477 - val_loss: 0.5892 - val_accuracy: 0.7636\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5463 - accuracy: 0.7600 - val_loss: 0.6634 - val_accuracy: 0.6000\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5464 - accuracy: 0.7415 - val_loss: 0.5950 - val_accuracy: 0.7273\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.5397 - accuracy: 0.7462 - val_loss: 0.5945 - val_accuracy: 0.7273\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5330 - accuracy: 0.7738 - val_loss: 0.6233 - val_accuracy: 0.6364\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5399 - accuracy: 0.7554 - val_loss: 0.6017 - val_accuracy: 0.7091\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.5348 - accuracy: 0.7662 - val_loss: 0.6133 - val_accuracy: 0.6727\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5256 - accuracy: 0.7723 - val_loss: 0.6011 - val_accuracy: 0.6909\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.5151 - accuracy: 0.7754 - val_loss: 0.6110 - val_accuracy: 0.6727\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.5229 - accuracy: 0.7692 - val_loss: 0.6365 - val_accuracy: 0.6182\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5172 - accuracy: 0.7831 - val_loss: 0.6408 - val_accuracy: 0.6364\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5156 - accuracy: 0.7846 - val_loss: 0.6019 - val_accuracy: 0.6909\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.5139 - accuracy: 0.7800 - val_loss: 0.6306 - val_accuracy: 0.6727\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.5194 - accuracy: 0.7738 - val_loss: 0.6297 - val_accuracy: 0.6727\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.5058 - accuracy: 0.7862 - val_loss: 0.5959 - val_accuracy: 0.7273\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4954 - accuracy: 0.7831 - val_loss: 0.6163 - val_accuracy: 0.6727\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4941 - accuracy: 0.7862 - val_loss: 0.6195 - val_accuracy: 0.6727\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4983 - accuracy: 0.7908 - val_loss: 0.6078 - val_accuracy: 0.6909\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4951 - accuracy: 0.7923 - val_loss: 0.6539 - val_accuracy: 0.6364\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 0.4876 - accuracy: 0.7908 - val_loss: 0.6073 - val_accuracy: 0.6909\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4805 - accuracy: 0.8077 - val_loss: 0.6386 - val_accuracy: 0.6727\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4820 - accuracy: 0.7985 - val_loss: 0.6482 - val_accuracy: 0.6545\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4792 - accuracy: 0.7877 - val_loss: 0.6174 - val_accuracy: 0.6727\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 25ms/step - loss: 0.4770 - accuracy: 0.8031 - val_loss: 0.6318 - val_accuracy: 0.6727\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4746 - accuracy: 0.8015 - val_loss: 0.6207 - val_accuracy: 0.6727\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4762 - accuracy: 0.8015 - val_loss: 0.6198 - val_accuracy: 0.6727\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4709 - accuracy: 0.8138 - val_loss: 0.6413 - val_accuracy: 0.6727\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4592 - accuracy: 0.8000 - val_loss: 0.6683 - val_accuracy: 0.6364\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4698 - accuracy: 0.7908 - val_loss: 0.6952 - val_accuracy: 0.6545\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4632 - accuracy: 0.7969 - val_loss: 0.6334 - val_accuracy: 0.6727\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4535 - accuracy: 0.8108 - val_loss: 0.6371 - val_accuracy: 0.6727\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4565 - accuracy: 0.7985 - val_loss: 0.6385 - val_accuracy: 0.6727\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4501 - accuracy: 0.8031 - val_loss: 0.6313 - val_accuracy: 0.6909\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4415 - accuracy: 0.8092 - val_loss: 0.6495 - val_accuracy: 0.6727\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4378 - accuracy: 0.8262 - val_loss: 0.6391 - val_accuracy: 0.7091\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4416 - accuracy: 0.8046 - val_loss: 0.6674 - val_accuracy: 0.6727\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4419 - accuracy: 0.8077 - val_loss: 0.6515 - val_accuracy: 0.6727\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.4341 - accuracy: 0.8200 - val_loss: 0.6500 - val_accuracy: 0.6727\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4376 - accuracy: 0.8169 - val_loss: 0.6530 - val_accuracy: 0.6727\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4333 - accuracy: 0.8138 - val_loss: 0.6496 - val_accuracy: 0.6909\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4308 - accuracy: 0.8246 - val_loss: 0.6426 - val_accuracy: 0.7091\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4220 - accuracy: 0.8262 - val_loss: 0.6738 - val_accuracy: 0.6545\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4260 - accuracy: 0.8292 - val_loss: 0.6643 - val_accuracy: 0.6727\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4153 - accuracy: 0.8292 - val_loss: 0.6664 - val_accuracy: 0.6727\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4191 - accuracy: 0.8185 - val_loss: 0.6656 - val_accuracy: 0.6909\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4185 - accuracy: 0.8277 - val_loss: 0.6525 - val_accuracy: 0.7273\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4207 - accuracy: 0.8231 - val_loss: 0.6647 - val_accuracy: 0.7091\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4113 - accuracy: 0.8246 - val_loss: 0.6712 - val_accuracy: 0.6909\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.4108 - accuracy: 0.8323 - val_loss: 0.6700 - val_accuracy: 0.7091\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.4099 - accuracy: 0.8400 - val_loss: 0.7000 - val_accuracy: 0.6545\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.4130 - accuracy: 0.8308 - val_loss: 0.7069 - val_accuracy: 0.6545\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.4129 - accuracy: 0.8354 - val_loss: 0.7090 - val_accuracy: 0.6545\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3974 - accuracy: 0.8354 - val_loss: 0.6737 - val_accuracy: 0.7091\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3936 - accuracy: 0.8415 - val_loss: 0.7031 - val_accuracy: 0.6545\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3915 - accuracy: 0.8231 - val_loss: 0.6861 - val_accuracy: 0.6727\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3906 - accuracy: 0.8338 - val_loss: 0.6808 - val_accuracy: 0.7091\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3835 - accuracy: 0.8369 - val_loss: 0.7052 - val_accuracy: 0.6727\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3783 - accuracy: 0.8400 - val_loss: 0.7183 - val_accuracy: 0.6545\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3910 - accuracy: 0.8538 - val_loss: 0.7072 - val_accuracy: 0.6545\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3890 - accuracy: 0.8492 - val_loss: 0.7088 - val_accuracy: 0.6545\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3827 - accuracy: 0.8400 - val_loss: 0.7222 - val_accuracy: 0.6545\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.3673 - accuracy: 0.8523 - val_loss: 0.6857 - val_accuracy: 0.7273\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3797 - accuracy: 0.8415 - val_loss: 0.7116 - val_accuracy: 0.6727\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3730 - accuracy: 0.8492 - val_loss: 0.7267 - val_accuracy: 0.6545\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3655 - accuracy: 0.8492 - val_loss: 0.7224 - val_accuracy: 0.6727\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3655 - accuracy: 0.8462 - val_loss: 0.7530 - val_accuracy: 0.6545\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3746 - accuracy: 0.8600 - val_loss: 0.6945 - val_accuracy: 0.7273\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3560 - accuracy: 0.8615 - val_loss: 0.7124 - val_accuracy: 0.6909\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3575 - accuracy: 0.8508 - val_loss: 0.7383 - val_accuracy: 0.6545\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3579 - accuracy: 0.8492 - val_loss: 0.6958 - val_accuracy: 0.7273\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3552 - accuracy: 0.8615 - val_loss: 0.7090 - val_accuracy: 0.7091\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3509 - accuracy: 0.8662 - val_loss: 0.7481 - val_accuracy: 0.6364\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3582 - accuracy: 0.8538 - val_loss: 0.7384 - val_accuracy: 0.6545\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3621 - accuracy: 0.8538 - val_loss: 0.7286 - val_accuracy: 0.6545\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3446 - accuracy: 0.8708 - val_loss: 0.7280 - val_accuracy: 0.6727\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3595 - accuracy: 0.8631 - val_loss: 0.7679 - val_accuracy: 0.6364\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3456 - accuracy: 0.8631 - val_loss: 0.7205 - val_accuracy: 0.6909\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3309 - accuracy: 0.8738 - val_loss: 0.7321 - val_accuracy: 0.7091\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.3371 - accuracy: 0.8538 - val_loss: 0.7291 - val_accuracy: 0.7091\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3293 - accuracy: 0.8662 - val_loss: 0.7096 - val_accuracy: 0.7091\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 19ms/step - loss: 0.3261 - accuracy: 0.8708 - val_loss: 0.7397 - val_accuracy: 0.6909\n",
      "Epoch 116/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3236 - accuracy: 0.8785 - val_loss: 0.7534 - val_accuracy: 0.6364\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3155 - accuracy: 0.8800 - val_loss: 0.7275 - val_accuracy: 0.7273\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3192 - accuracy: 0.8646 - val_loss: 0.7265 - val_accuracy: 0.7091\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.3183 - accuracy: 0.8785 - val_loss: 0.7645 - val_accuracy: 0.6545\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3188 - accuracy: 0.8815 - val_loss: 0.7397 - val_accuracy: 0.7091\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.3130 - accuracy: 0.8846 - val_loss: 0.7456 - val_accuracy: 0.7091\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.3053 - accuracy: 0.8831 - val_loss: 0.7542 - val_accuracy: 0.6909\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.3106 - accuracy: 0.8800 - val_loss: 0.7432 - val_accuracy: 0.7091\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2947 - accuracy: 0.8831 - val_loss: 0.7422 - val_accuracy: 0.7091\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.3087 - accuracy: 0.8785 - val_loss: 0.7388 - val_accuracy: 0.7091\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2944 - accuracy: 0.8908 - val_loss: 0.7567 - val_accuracy: 0.7091\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2845 - accuracy: 0.9015 - val_loss: 0.7553 - val_accuracy: 0.7091\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2882 - accuracy: 0.8908 - val_loss: 0.7576 - val_accuracy: 0.7091\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2927 - accuracy: 0.8892 - val_loss: 0.7557 - val_accuracy: 0.7091\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2909 - accuracy: 0.8908 - val_loss: 0.7539 - val_accuracy: 0.7091\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.2880 - accuracy: 0.8923 - val_loss: 0.7422 - val_accuracy: 0.7091\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2731 - accuracy: 0.9077 - val_loss: 0.7659 - val_accuracy: 0.7091\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2709 - accuracy: 0.9000 - val_loss: 0.7666 - val_accuracy: 0.7091\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2853 - accuracy: 0.8969 - val_loss: 0.7708 - val_accuracy: 0.6909\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2819 - accuracy: 0.9000 - val_loss: 0.7770 - val_accuracy: 0.6909\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2739 - accuracy: 0.9031 - val_loss: 0.7665 - val_accuracy: 0.7091\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2681 - accuracy: 0.9015 - val_loss: 0.7672 - val_accuracy: 0.6909\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2700 - accuracy: 0.9015 - val_loss: 0.7593 - val_accuracy: 0.7091\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2701 - accuracy: 0.9046 - val_loss: 0.7482 - val_accuracy: 0.6909\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2523 - accuracy: 0.9062 - val_loss: 0.7732 - val_accuracy: 0.6909\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2538 - accuracy: 0.9108 - val_loss: 0.7758 - val_accuracy: 0.6909\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2516 - accuracy: 0.9123 - val_loss: 0.7711 - val_accuracy: 0.7091\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.2490 - accuracy: 0.9154 - val_loss: 0.7809 - val_accuracy: 0.6909\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2451 - accuracy: 0.9031 - val_loss: 0.7662 - val_accuracy: 0.7091\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2514 - accuracy: 0.9046 - val_loss: 0.8053 - val_accuracy: 0.6909\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2539 - accuracy: 0.9108 - val_loss: 0.7748 - val_accuracy: 0.6909\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2328 - accuracy: 0.9169 - val_loss: 0.7727 - val_accuracy: 0.7091\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2357 - accuracy: 0.9138 - val_loss: 0.7780 - val_accuracy: 0.7091\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2327 - accuracy: 0.9138 - val_loss: 0.7955 - val_accuracy: 0.6909\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.2299 - accuracy: 0.9123 - val_loss: 0.7835 - val_accuracy: 0.7091\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2217 - accuracy: 0.9185 - val_loss: 0.7984 - val_accuracy: 0.6909\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.2316 - accuracy: 0.9169 - val_loss: 0.8024 - val_accuracy: 0.6909\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.2152 - accuracy: 0.9292 - val_loss: 0.8002 - val_accuracy: 0.7091\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.2137 - accuracy: 0.9123 - val_loss: 0.7935 - val_accuracy: 0.7091\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.2190 - accuracy: 0.9138 - val_loss: 0.7916 - val_accuracy: 0.7273\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 1s 33ms/step - loss: 0.2234 - accuracy: 0.9169 - val_loss: 0.8019 - val_accuracy: 0.7273\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 1s 29ms/step - loss: 0.2215 - accuracy: 0.9200 - val_loss: 0.7963 - val_accuracy: 0.7273\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.2002 - accuracy: 0.9338 - val_loss: 0.8154 - val_accuracy: 0.6545\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.2058 - accuracy: 0.9338 - val_loss: 0.8078 - val_accuracy: 0.7091\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.2003 - accuracy: 0.9323 - val_loss: 0.8202 - val_accuracy: 0.6909\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.1950 - accuracy: 0.9431 - val_loss: 0.8202 - val_accuracy: 0.6909\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2049 - accuracy: 0.9277 - val_loss: 0.8515 - val_accuracy: 0.6364\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.2009 - accuracy: 0.9292 - val_loss: 0.8257 - val_accuracy: 0.7091\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.2000 - accuracy: 0.9262 - val_loss: 0.8190 - val_accuracy: 0.7091\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1912 - accuracy: 0.9415 - val_loss: 0.8328 - val_accuracy: 0.6909\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1913 - accuracy: 0.9354 - val_loss: 0.8249 - val_accuracy: 0.6909\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.2009 - accuracy: 0.9262 - val_loss: 0.8177 - val_accuracy: 0.7091\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1787 - accuracy: 0.9538 - val_loss: 0.8429 - val_accuracy: 0.6909\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1715 - accuracy: 0.9569 - val_loss: 0.8589 - val_accuracy: 0.6545\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.1918 - accuracy: 0.9323 - val_loss: 0.8673 - val_accuracy: 0.6727\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1773 - accuracy: 0.9508 - val_loss: 0.8546 - val_accuracy: 0.6909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1781 - accuracy: 0.9385 - val_loss: 0.8455 - val_accuracy: 0.6909\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1728 - accuracy: 0.9415 - val_loss: 0.8468 - val_accuracy: 0.7091\n",
      "Epoch 174/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1656 - accuracy: 0.9508 - val_loss: 0.8734 - val_accuracy: 0.6909\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.1708 - accuracy: 0.9600 - val_loss: 0.8615 - val_accuracy: 0.6909\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.1662 - accuracy: 0.9600 - val_loss: 0.8563 - val_accuracy: 0.6909\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 0.1658 - accuracy: 0.9554 - val_loss: 0.8968 - val_accuracy: 0.6727\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1624 - accuracy: 0.9462 - val_loss: 0.8640 - val_accuracy: 0.6909\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.1564 - accuracy: 0.9538 - val_loss: 0.8873 - val_accuracy: 0.6909\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1590 - accuracy: 0.9492 - val_loss: 0.8656 - val_accuracy: 0.7273\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.1661 - accuracy: 0.9477 - val_loss: 0.8741 - val_accuracy: 0.6909\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1586 - accuracy: 0.9554 - val_loss: 0.8940 - val_accuracy: 0.6727\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 1s 30ms/step - loss: 0.1472 - accuracy: 0.9600 - val_loss: 0.8903 - val_accuracy: 0.6727\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1539 - accuracy: 0.9492 - val_loss: 0.9211 - val_accuracy: 0.6727\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.1425 - accuracy: 0.9662 - val_loss: 0.9010 - val_accuracy: 0.6727\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1435 - accuracy: 0.9646 - val_loss: 0.8804 - val_accuracy: 0.7091\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.1394 - accuracy: 0.9600 - val_loss: 0.8865 - val_accuracy: 0.7091\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.1422 - accuracy: 0.9646 - val_loss: 0.8930 - val_accuracy: 0.7273\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1502 - accuracy: 0.9585 - val_loss: 0.8855 - val_accuracy: 0.7091\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1396 - accuracy: 0.9569 - val_loss: 0.8974 - val_accuracy: 0.7091\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1313 - accuracy: 0.9615 - val_loss: 0.9042 - val_accuracy: 0.6909\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1302 - accuracy: 0.9723 - val_loss: 0.9266 - val_accuracy: 0.6364\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 0.1274 - accuracy: 0.9662 - val_loss: 0.9526 - val_accuracy: 0.6727\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1467 - accuracy: 0.9538 - val_loss: 0.9249 - val_accuracy: 0.6545\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1408 - accuracy: 0.9600 - val_loss: 0.9218 - val_accuracy: 0.6727\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1307 - accuracy: 0.9662 - val_loss: 0.9258 - val_accuracy: 0.7091\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1224 - accuracy: 0.9708 - val_loss: 0.9317 - val_accuracy: 0.6909\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 0.1209 - accuracy: 0.9708 - val_loss: 0.9214 - val_accuracy: 0.6909\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1181 - accuracy: 0.9692 - val_loss: 0.9670 - val_accuracy: 0.6909\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1321 - accuracy: 0.9646 - val_loss: 0.9255 - val_accuracy: 0.7091\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1199 - accuracy: 0.9708 - val_loss: 0.9369 - val_accuracy: 0.7273\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1281 - accuracy: 0.9662 - val_loss: 0.9364 - val_accuracy: 0.7273\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1290 - accuracy: 0.9723 - val_loss: 0.9074 - val_accuracy: 0.7091\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1253 - accuracy: 0.9692 - val_loss: 0.9435 - val_accuracy: 0.6909\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1091 - accuracy: 0.9769 - val_loss: 0.9353 - val_accuracy: 0.7091\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1236 - accuracy: 0.9692 - val_loss: 0.9401 - val_accuracy: 0.7455\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1187 - accuracy: 0.9754 - val_loss: 0.9254 - val_accuracy: 0.7273\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1094 - accuracy: 0.9815 - val_loss: 0.9517 - val_accuracy: 0.6909\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1013 - accuracy: 0.9723 - val_loss: 0.9769 - val_accuracy: 0.6909\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1088 - accuracy: 0.9662 - val_loss: 0.9459 - val_accuracy: 0.7091\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1096 - accuracy: 0.9723 - val_loss: 1.0000 - val_accuracy: 0.6727\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1150 - accuracy: 0.9646 - val_loss: 0.9383 - val_accuracy: 0.7091\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 0.1054 - accuracy: 0.9677 - val_loss: 0.9836 - val_accuracy: 0.6727\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.1043 - accuracy: 0.9754 - val_loss: 0.9777 - val_accuracy: 0.6909\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1000 - accuracy: 0.9769 - val_loss: 0.9854 - val_accuracy: 0.6909\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.1096 - accuracy: 0.9723 - val_loss: 0.9893 - val_accuracy: 0.6909\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.1093 - accuracy: 0.9708 - val_loss: 0.9706 - val_accuracy: 0.7091\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1024 - accuracy: 0.9738 - val_loss: 0.9798 - val_accuracy: 0.7091\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.1003 - accuracy: 0.9769 - val_loss: 0.9953 - val_accuracy: 0.7091\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 1s 27ms/step - loss: 0.1034 - accuracy: 0.9800 - val_loss: 0.9928 - val_accuracy: 0.6909\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0960 - accuracy: 0.9815 - val_loss: 0.9904 - val_accuracy: 0.6909\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0926 - accuracy: 0.9785 - val_loss: 1.0333 - val_accuracy: 0.6545\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 1s 26ms/step - loss: 0.0947 - accuracy: 0.9754 - val_loss: 1.0119 - val_accuracy: 0.6727\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0886 - accuracy: 0.9800 - val_loss: 0.9793 - val_accuracy: 0.6909\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0877 - accuracy: 0.9785 - val_loss: 0.9799 - val_accuracy: 0.7091\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0925 - accuracy: 0.9769 - val_loss: 0.9851 - val_accuracy: 0.7091\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0859 - accuracy: 0.9815 - val_loss: 1.0053 - val_accuracy: 0.7091\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 0.0846 - accuracy: 0.9815 - val_loss: 0.9923 - val_accuracy: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0810 - accuracy: 0.9877 - val_loss: 1.0318 - val_accuracy: 0.6909\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 0.0801 - accuracy: 0.9877 - val_loss: 1.0666 - val_accuracy: 0.6727\n",
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0933 - accuracy: 0.9769 - val_loss: 1.0267 - val_accuracy: 0.6909\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0737 - accuracy: 0.9892 - val_loss: 1.0392 - val_accuracy: 0.6909\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0890 - accuracy: 0.9785 - val_loss: 1.0281 - val_accuracy: 0.7091\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 0.0762 - accuracy: 0.9846 - val_loss: 1.0553 - val_accuracy: 0.6727\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 0.0780 - accuracy: 0.9846 - val_loss: 1.0267 - val_accuracy: 0.6909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e90f3a6a0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.compile(optimizer=opt1, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "#Here we use cross-entropy as the criteria for loss.\n",
    "model_2.fit(X_train_over, y_train_over, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=500, verbose=True, \n",
    "            callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cdf43697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.6923\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5892 - accuracy: 0.7636\n"
     ]
    }
   ],
   "source": [
    "m2_eval_test = model_2.evaluate(X_test, y_test)\n",
    "m2_eval_val = model_2.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984d924",
   "metadata": {},
   "source": [
    "**Summary statistics and confusion matrix for test set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a8ff7854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "roc auc score:  0.6468468468468469\n",
      "average precision score:  0.6112475181100518\n"
     ]
    }
   ],
   "source": [
    "pred = model_2.predict(X_test)\n",
    "roc_value = roc_auc_score(y_test, pred)\n",
    "ap_score = average_precision_score(y_test, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea8b3814",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_np = y_test_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5c019ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6923\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_test_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m2_eval_test = model_2.evaluate(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e208cf0",
   "metadata": {},
   "source": [
    "**Summary statistics and confusion matrix for validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b4f07e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step\n",
      "roc auc score:  0.6965944272445821\n",
      "average precision score:  0.6692762107821091\n"
     ]
    }
   ],
   "source": [
    "pred = model_2.predict(X_val)\n",
    "roc_value = roc_auc_score(y_val, pred)\n",
    "ap_score = average_precision_score(y_val, pred)\n",
    "print('roc auc score: ', roc_value)\n",
    "print('average precision score: ', ap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8a3b98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred\n",
    "y_c = (y_pred > 0.5).astype(\"int32\")\n",
    "y_val_np = y_val.to_numpy()\n",
    "y_val_np = y_val_np.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "11ce4059",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5892 - accuracy: 0.7636\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_val_np.argmax(axis=1), y_c.argmax(axis=1)) \n",
    "#cf_matrix = confusion_matrix(y_test_np[:, 1], y_c[:, 1]) \n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels (validation set)\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "ax.yaxis.set_ticklabels(['Non-Progressor','Progressor'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.savefig('M1_GRI_test.png')\n",
    "m1_eval_test = model_2.evaluate(X_val, y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4323033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77d60c93",
   "metadata": {},
   "source": [
    "Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a492b412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "import os\n",
    "# serialize model to JSON\n",
    "model_1_json = model_1.to_json()\n",
    "with open(\"model_1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_1_json)\n",
    "# serialize weights to HDF5\n",
    "model_1.save_weights(\"model_1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1ac7ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_2_json = model_2.to_json()\n",
    "with open(\"model_2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_2_json)\n",
    "# serialize weights to HDF5\n",
    "model_2.save_weights(\"model_2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb14e2f",
   "metadata": {},
   "source": [
    "Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model_1.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
