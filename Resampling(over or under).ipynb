{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e449ad",
   "metadata": {},
   "source": [
    "# Random Oversampling Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a456951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.1\n"
     ]
    }
   ],
   "source": [
    "# check version number\n",
    "\n",
    "import imblearn\n",
    "\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d59a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf072db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define oversampling strategy 1\n",
    "oversample = RandomOverSampler(sampling_strategy = 'minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b833ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define oversampling strategy 2\n",
    "oversample = RandomOverSampler(sampling_strategy = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1897a6b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomOverSampler in module imblearn.over_sampling._random_over_sampler:\n",
      "\n",
      "class RandomOverSampler(imblearn.over_sampling.base.BaseOverSampler)\n",
      " |  RandomOverSampler(*, sampling_strategy='auto', random_state=None, shrinkage=None)\n",
      " |  \n",
      " |  Class to perform random over-sampling.\n",
      " |  \n",
      " |  Object to over-sample the minority class(es) by picking samples at random\n",
      " |  with replacement. The bootstrap can be generated in a smoothed manner.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <random_over_sampler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  sampling_strategy : float, str, dict or callable, default='auto'\n",
      " |      Sampling information to resample the data set.\n",
      " |  \n",
      " |      - When ``float``, it corresponds to the desired ratio of the number of\n",
      " |        samples in the minority class over the number of samples in the\n",
      " |        majority class after resampling. Therefore, the ratio is expressed as\n",
      " |        :math:`\\alpha_{os} = N_{rm} / N_{M}` where :math:`N_{rm}` is the\n",
      " |        number of samples in the minority class after resampling and\n",
      " |        :math:`N_{M}` is the number of samples in the majority class.\n",
      " |  \n",
      " |          .. warning::\n",
      " |             ``float`` is only available for **binary** classification. An\n",
      " |             error is raised for multi-class classification.\n",
      " |  \n",
      " |      - When ``str``, specify the class targeted by the resampling. The\n",
      " |        number of samples in the different classes will be equalized.\n",
      " |        Possible choices are:\n",
      " |  \n",
      " |          ``'minority'``: resample only the minority class;\n",
      " |  \n",
      " |          ``'not minority'``: resample all classes but the minority class;\n",
      " |  \n",
      " |          ``'not majority'``: resample all classes but the majority class;\n",
      " |  \n",
      " |          ``'all'``: resample all classes;\n",
      " |  \n",
      " |          ``'auto'``: equivalent to ``'not majority'``.\n",
      " |  \n",
      " |      - When ``dict``, the keys correspond to the targeted classes. The\n",
      " |        values correspond to the desired number of samples for each targeted\n",
      " |        class.\n",
      " |  \n",
      " |      - When callable, function taking ``y`` and returns a ``dict``. The keys\n",
      " |        correspond to the targeted classes. The values correspond to the\n",
      " |        desired number of samples for each class.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Control the randomization of the algorithm.\n",
      " |  \n",
      " |      - If int, ``random_state`` is the seed used by the random number\n",
      " |        generator;\n",
      " |      - If ``RandomState`` instance, random_state is the random number\n",
      " |        generator;\n",
      " |      - If ``None``, the random number generator is the ``RandomState``\n",
      " |        instance used by ``np.random``.\n",
      " |  \n",
      " |  shrinkage : float or dict, default=None\n",
      " |      Parameter controlling the shrinkage applied to the covariance matrix.\n",
      " |      when a smoothed bootstrap is generated. The options are:\n",
      " |  \n",
      " |      - if `None`, a normal bootstrap will be generated without perturbation.\n",
      " |        It is equivalent to `shrinkage=0` as well;\n",
      " |      - if a `float` is given, the shrinkage factor will be used for all\n",
      " |        classes to generate the smoothed bootstrap;\n",
      " |      - if a `dict` is given, the shrinkage factor will specific for each\n",
      " |        class. The key correspond to the targeted class and the value is\n",
      " |        the shrinkage factor.\n",
      " |  \n",
      " |      The value needs of the shrinkage parameter needs to be higher or equal\n",
      " |      to 0.\n",
      " |  \n",
      " |      .. versionadded:: 0.8\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  sampling_strategy_ : dict\n",
      " |      Dictionary containing the information to sample the dataset. The keys\n",
      " |      corresponds to the class labels from which to sample and the values\n",
      " |      are the number of samples to sample.\n",
      " |  \n",
      " |  sample_indices_ : ndarray of shape (n_new_samples,)\n",
      " |      Indices of the samples selected.\n",
      " |  \n",
      " |      .. versionadded:: 0.4\n",
      " |  \n",
      " |  shrinkage_ : dict or None\n",
      " |      The per-class shrinkage factor used to generate the smoothed bootstrap\n",
      " |      sample. When `shrinkage=None` a normal bootstrap will be generated.\n",
      " |  \n",
      " |      .. versionadded:: 0.8\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features in the input dataset.\n",
      " |  \n",
      " |      .. versionadded:: 0.9\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  BorderlineSMOTE : Over-sample using the borderline-SMOTE variant.\n",
      " |  \n",
      " |  SMOTE : Over-sample using SMOTE.\n",
      " |  \n",
      " |  SMOTENC : Over-sample using SMOTE for continuous and categorical features.\n",
      " |  \n",
      " |  SMOTEN : Over-sample using the SMOTE variant specifically for categorical\n",
      " |      features only.\n",
      " |  \n",
      " |  SVMSMOTE : Over-sample using SVM-SMOTE variant.\n",
      " |  \n",
      " |  ADASYN : Over-sample using ADASYN.\n",
      " |  \n",
      " |  KMeansSMOTE : Over-sample applying a clustering before to oversample using\n",
      " |      SMOTE.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Supports multi-class resampling by sampling each class independently.\n",
      " |  Supports heterogeneous data as object array containing string and numeric\n",
      " |  data.\n",
      " |  \n",
      " |  When generating a smoothed bootstrap, this method is also known as Random\n",
      " |  Over-Sampling Examples (ROSE) [1]_.\n",
      " |  \n",
      " |  .. warning::\n",
      " |     Since smoothed bootstrap are generated by adding a small perturbation\n",
      " |     to the drawn samples, this method is not adequate when working with\n",
      " |     sparse matrices.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] G Menardi, N. Torelli, \"Training and assessing classification\n",
      " |     rules with imbalanced data,\" Data Mining and Knowledge\n",
      " |     Discovery, 28(1), pp.92-122, 2014.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from collections import Counter\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> from imblearn.over_sampling import RandomOverSampler # doctest: +NORMALIZE_WHITESPACE\n",
      " |  >>> X, y = make_classification(n_classes=2, class_sep=2,\n",
      " |  ... weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
      " |  ... n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
      " |  >>> print('Original dataset shape %s' % Counter(y))\n",
      " |  Original dataset shape Counter({1: 900, 0: 100})\n",
      " |  >>> ros = RandomOverSampler(random_state=42)\n",
      " |  >>> X_res, y_res = ros.fit_resample(X, y)\n",
      " |  >>> print('Resampled dataset shape %s' % Counter(y_res))\n",
      " |  Resampled dataset shape Counter({0: 900, 1: 900})\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomOverSampler\n",
      " |      imblearn.over_sampling.base.BaseOverSampler\n",
      " |      imblearn.base.BaseSampler\n",
      " |      imblearn.base.SamplerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, sampling_strategy='auto', random_state=None, shrinkage=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from imblearn.base.SamplerMixin:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Check inputs and statistics of the sampler.\n",
      " |      \n",
      " |      You should use ``fit_resample`` in all cases.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, dataframe, sparse matrix} of shape                 (n_samples, n_features)\n",
      " |          Data array.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Return the instance itself.\n",
      " |  \n",
      " |  fit_resample(self, X, y)\n",
      " |      Resample the dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, dataframe, sparse matrix} of shape                 (n_samples, n_features)\n",
      " |          Matrix containing the data which have to be sampled.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Corresponding label for each sample in X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_resampled : {array-like, dataframe, sparse matrix} of shape                 (n_samples_new, n_features)\n",
      " |          The array containing the resampled data.\n",
      " |      \n",
      " |      y_resampled : array-like of shape (n_samples_new,)\n",
      " |          The corresponding label of `X_resampled`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomOverSampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14c34429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71881d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a pair of dataset.\n",
    "X, y = make_classification(n_samples = 10000, weights = [0.99], flip_y = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be74c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 100})\n"
     ]
    }
   ],
   "source": [
    "#Summarize class distribution.\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbefd1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy = 'minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2dbebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and apply the transform.\n",
    "X_over, y_over = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8adbfb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 9900})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aab92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf3aae09",
   "metadata": {},
   "source": [
    "## Pipeline with oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581c9b5",
   "metadata": {},
   "source": [
    "This is used when we are applying the k-fold evaluation, we want to only have the oversampling on the evaluation dataset and make sure that the validation set won't be oversampled, which means the data in validation set won't be duplicated in training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88778dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of evaluating a decision tree with random oversampling\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\n",
    "# define pipeline\n",
    "steps = [('over', RandomOverSampler()), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44ccea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b68a1844",
   "metadata": {},
   "source": [
    "# Random Undersampling Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define undersample strategy 1\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define undersample strategy 2\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f7ec4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of random undersampling to balance the class distribution\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87e79822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c23f58ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 100})\n"
     ]
    }
   ],
   "source": [
    "# Summarize class distribution\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfa5d1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 100, 1: 100})\n"
     ]
    }
   ],
   "source": [
    "# Define undersample strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "# Fit and apply the transform\n",
    "X_over, y_over = undersample.fit_resample(X, y)\n",
    "# Summarize class distribution\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed0785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2b3b9dd",
   "metadata": {},
   "source": [
    "## Pipeline with undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc77ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of evaluating a decision tree with random undersampling\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\n",
    "# define pipeline\n",
    "steps = [('under', RandomUnderSampler()), ('model', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862cb62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d220eed",
   "metadata": {},
   "source": [
    "# Combining Random Oversampling and Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76a0eefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 9900, 1: 100})\n",
      "Counter({0: 9900, 1: 990})\n",
      "Counter({0: 1980, 1: 990})\n"
     ]
    }
   ],
   "source": [
    "# example of combining random oversampling and undersampling for imbalanced data\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\n",
    "# summarize class distribution\n",
    "print(Counter(y))\n",
    "# define oversampling strategy\n",
    "over = RandomOverSampler(sampling_strategy=0.1)\n",
    "# fit and apply the transform\n",
    "X, y = over.fit_resample(X, y)\n",
    "# summarize class distribution\n",
    "print(Counter(y))\n",
    "# define undersampling strategy\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# fit and apply the transform\n",
    "X, y = under.fit_resample(X, y)\n",
    "# summarize class distribution\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde41b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d91aca3f",
   "metadata": {},
   "source": [
    "## Pipeline with combination of undersampling and oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e762c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of evaluating a model with random oversampling and undersampling\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\n",
    "# define pipeline\n",
    "over = RandomOverSampler(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under), ('m', DecisionTreeClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f36c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
